2025-03-22 17:31:23,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 17:31:23,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 17:31:23,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 17:31:23,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 17:41:52,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 17:41:52,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 17:41:52,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 17:41:52,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 17:45:33,331:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\huggingface_hub\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\jeiso\.cache\huggingface\hub\models--pysentimiento--robertuito-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)

2025-03-22 17:48:29,328:INFO:PyCaret ClassificationExperiment
2025-03-22 17:48:29,328:INFO:Logging name: Mentalrisk_task2
2025-03-22 17:48:29,328:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-22 17:48:29,328:INFO:version 3.3.2
2025-03-22 17:48:29,328:INFO:Initializing setup()
2025-03-22 17:48:29,328:INFO:self.USI: f443
2025-03-22 17:48:29,328:INFO:self._variable_keys: {'fold_generator', 'X', 'fix_imbalance', '_available_plots', 'log_plots_param', 'pipeline', 'exp_id', 'y', 'X_test', 'USI', 'exp_name_log', 'seed', 'y_test', 'is_multiclass', 'n_jobs_param', 'X_train', 'idx', 'logging_param', '_ml_usecase', 'html_param', 'gpu_param', 'fold_groups_param', 'memory', 'gpu_n_jobs_param', 'target_param', 'data', 'y_train', 'fold_shuffle_param'}
2025-03-22 17:48:29,328:INFO:Checking environment
2025-03-22 17:48:29,328:INFO:python_version: 3.10.11
2025-03-22 17:48:29,328:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-03-22 17:48:29,328:INFO:machine: AMD64
2025-03-22 17:48:29,328:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-22 17:48:29,332:INFO:Memory: svmem(total=34188517376, available=17551040512, percent=48.7, used=16637476864, free=17551040512)
2025-03-22 17:48:29,332:INFO:Physical Core: 12
2025-03-22 17:48:29,332:INFO:Logical Core: 20
2025-03-22 17:48:29,332:INFO:Checking libraries
2025-03-22 17:48:29,332:INFO:System:
2025-03-22 17:48:29,332:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-03-22 17:48:29,332:INFO:executable: C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\Scripts\python.exe
2025-03-22 17:48:29,332:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-22 17:48:29,332:INFO:PyCaret required dependencies:
2025-03-22 17:48:29,539:INFO:                 pip: 24.2
2025-03-22 17:48:29,539:INFO:          setuptools: 73.0.1
2025-03-22 17:48:29,539:INFO:             pycaret: 3.3.2
2025-03-22 17:48:29,540:INFO:             IPython: 8.34.0
2025-03-22 17:48:29,540:INFO:          ipywidgets: 8.1.5
2025-03-22 17:48:29,540:INFO:                tqdm: 4.67.1
2025-03-22 17:48:29,540:INFO:               numpy: 1.26.4
2025-03-22 17:48:29,540:INFO:              pandas: 2.1.4
2025-03-22 17:48:29,540:INFO:              jinja2: 3.1.6
2025-03-22 17:48:29,540:INFO:               scipy: 1.11.4
2025-03-22 17:48:29,540:INFO:              joblib: 1.3.2
2025-03-22 17:48:29,540:INFO:             sklearn: 1.4.2
2025-03-22 17:48:29,540:INFO:                pyod: 2.0.3
2025-03-22 17:48:29,540:INFO:            imblearn: 0.13.0
2025-03-22 17:48:29,540:INFO:   category_encoders: 2.7.0
2025-03-22 17:48:29,540:INFO:            lightgbm: 4.6.0
2025-03-22 17:48:29,540:INFO:               numba: 0.61.0
2025-03-22 17:48:29,540:INFO:            requests: 2.32.3
2025-03-22 17:48:29,540:INFO:          matplotlib: 3.7.5
2025-03-22 17:48:29,540:INFO:          scikitplot: 0.3.7
2025-03-22 17:48:29,540:INFO:         yellowbrick: 1.5
2025-03-22 17:48:29,540:INFO:              plotly: 5.24.1
2025-03-22 17:48:29,540:INFO:    plotly-resampler: Not installed
2025-03-22 17:48:29,540:INFO:             kaleido: 0.2.1
2025-03-22 17:48:29,540:INFO:           schemdraw: 0.15
2025-03-22 17:48:29,540:INFO:         statsmodels: 0.14.4
2025-03-22 17:48:29,540:INFO:              sktime: 0.26.0
2025-03-22 17:48:29,540:INFO:               tbats: 1.1.3
2025-03-22 17:48:29,540:INFO:            pmdarima: 2.0.4
2025-03-22 17:48:29,540:INFO:              psutil: 7.0.0
2025-03-22 17:48:29,540:INFO:          markupsafe: 3.0.2
2025-03-22 17:48:29,540:INFO:             pickle5: Not installed
2025-03-22 17:48:29,540:INFO:         cloudpickle: 3.1.1
2025-03-22 17:48:29,540:INFO:         deprecation: 2.1.0
2025-03-22 17:48:29,540:INFO:              xxhash: 3.5.0
2025-03-22 17:48:29,540:INFO:           wurlitzer: Not installed
2025-03-22 17:48:29,540:INFO:PyCaret optional dependencies:
2025-03-22 17:48:29,552:INFO:                shap: Not installed
2025-03-22 17:48:29,552:INFO:           interpret: Not installed
2025-03-22 17:48:29,552:INFO:                umap: Not installed
2025-03-22 17:48:29,552:INFO:     ydata_profiling: Not installed
2025-03-22 17:48:29,552:INFO:  explainerdashboard: Not installed
2025-03-22 17:48:29,552:INFO:             autoviz: Not installed
2025-03-22 17:48:29,552:INFO:           fairlearn: Not installed
2025-03-22 17:48:29,552:INFO:          deepchecks: Not installed
2025-03-22 17:48:29,552:INFO:             xgboost: Not installed
2025-03-22 17:48:29,552:INFO:            catboost: Not installed
2025-03-22 17:48:29,552:INFO:              kmodes: Not installed
2025-03-22 17:48:29,552:INFO:             mlxtend: Not installed
2025-03-22 17:48:29,552:INFO:       statsforecast: Not installed
2025-03-22 17:48:29,552:INFO:        tune_sklearn: Not installed
2025-03-22 17:48:29,552:INFO:                 ray: Not installed
2025-03-22 17:48:29,552:INFO:            hyperopt: Not installed
2025-03-22 17:48:29,552:INFO:              optuna: Not installed
2025-03-22 17:48:29,552:INFO:               skopt: Not installed
2025-03-22 17:48:29,552:INFO:              mlflow: 2.16.0
2025-03-22 17:48:29,552:INFO:              gradio: Not installed
2025-03-22 17:48:29,552:INFO:             fastapi: Not installed
2025-03-22 17:48:29,552:INFO:             uvicorn: Not installed
2025-03-22 17:48:29,552:INFO:              m2cgen: Not installed
2025-03-22 17:48:29,552:INFO:           evidently: Not installed
2025-03-22 17:48:29,552:INFO:               fugue: Not installed
2025-03-22 17:48:29,552:INFO:           streamlit: Not installed
2025-03-22 17:48:29,552:INFO:             prophet: Not installed
2025-03-22 17:48:29,552:INFO:None
2025-03-22 17:48:29,552:INFO:Set up data.
2025-03-22 17:48:29,613:INFO:Set up folding strategy.
2025-03-22 17:48:29,613:INFO:Set up train/test split.
2025-03-22 17:48:29,649:INFO:Set up index.
2025-03-22 17:48:29,649:INFO:Assigning column types.
2025-03-22 17:48:29,688:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-22 17:48:29,711:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 17:48:29,718:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 17:48:29,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,778:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 17:48:29,779:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 17:48:29,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,793:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-22 17:48:29,815:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 17:48:29,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,854:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 17:48:29,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,872:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-22 17:48:29,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,951:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:29,960:INFO:Preparing preprocessing pipeline...
2025-03-22 17:48:29,968:INFO:Set up simple imputation.
2025-03-22 17:48:30,257:INFO:Finished creating preprocessing pipeline.
2025-03-22 17:48:30,261:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 17:48:30,261:INFO:Creating final display dataframe.
2025-03-22 17:48:30,853:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type        Multiclass
3           Original data shape        (540, 769)
4        Transformed data shape        (540, 769)
5   Transformed train set shape        (432, 769)
6    Transformed test set shape        (108, 769)
7              Numeric features               768
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment      MlflowLogger
17              Experiment Name  Mentalrisk_task2
18                          USI              f443
2025-03-22 17:48:30,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:30,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:30,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:30,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 17:48:30,931:INFO:Logging experiment in loggers
2025-03-22 17:48:31,357:INFO:SubProcess save_model() called ==================================
2025-03-22 17:48:31,364:INFO:Initializing save_model()
2025-03-22 17:48:31,364:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\jeiso\AppData\Local\Temp\tmpikvc3q3v\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 17:48:31,364:INFO:Adding model into prep_pipe
2025-03-22 17:48:31,364:WARNING:Only Model saved as it was a pipeline.
2025-03-22 17:48:31,370:INFO:C:\Users\jeiso\AppData\Local\Temp\tmpikvc3q3v\Transformation Pipeline.pkl saved in current working directory
2025-03-22 17:48:31,373:INFO:Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 17:48:31,374:INFO:save_model() successfully completed......................................
2025-03-22 17:48:31,485:INFO:SubProcess save_model() end ==================================
2025-03-22 17:48:31,534:INFO:setup() successfully completed in 1.61s...............
2025-03-22 17:48:35,843:INFO:Initializing compare_models()
2025-03-22 17:48:35,843:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, include=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-22 17:48:35,843:INFO:Checking exceptions
2025-03-22 17:48:35,873:INFO:Preparing display monitor
2025-03-22 17:48:35,887:INFO:Initializing Logistic Regression
2025-03-22 17:48:35,887:INFO:Total runtime is 0.0 minutes
2025-03-22 17:48:35,890:INFO:SubProcess create_model() called ==================================
2025-03-22 17:48:35,890:INFO:Initializing create_model()
2025-03-22 17:48:35,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:48:35,890:INFO:Checking exceptions
2025-03-22 17:48:35,890:INFO:Importing libraries
2025-03-22 17:48:35,890:INFO:Copying training dataset
2025-03-22 17:48:35,934:INFO:Defining folds
2025-03-22 17:48:35,934:INFO:Declaring metric variables
2025-03-22 17:48:35,937:INFO:Importing untrained model
2025-03-22 17:48:35,939:INFO:Logistic Regression Imported successfully
2025-03-22 17:48:35,943:INFO:Starting cross validation
2025-03-22 17:48:35,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:48:38,564:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:38,564:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:38,564:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:38,564:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:38,566:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:38,572:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:38,598:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:38,608:INFO:Calculating mean and std
2025-03-22 17:48:38,610:INFO:Creating metrics dataframe
2025-03-22 17:48:38,612:INFO:Uploading results into container
2025-03-22 17:48:38,613:INFO:Uploading model into container now
2025-03-22 17:48:38,614:INFO:_master_model_container: 1
2025-03-22 17:48:38,614:INFO:_display_container: 2
2025-03-22 17:48:38,615:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 17:48:38,615:INFO:create_model() successfully completed......................................
2025-03-22 17:48:38,729:INFO:SubProcess create_model() end ==================================
2025-03-22 17:48:38,729:INFO:Creating metrics dataframe
2025-03-22 17:48:38,732:INFO:Initializing K Neighbors Classifier
2025-03-22 17:48:38,732:INFO:Total runtime is 0.047432585557301836 minutes
2025-03-22 17:48:38,734:INFO:SubProcess create_model() called ==================================
2025-03-22 17:48:38,734:INFO:Initializing create_model()
2025-03-22 17:48:38,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:48:38,735:INFO:Checking exceptions
2025-03-22 17:48:38,735:INFO:Importing libraries
2025-03-22 17:48:38,735:INFO:Copying training dataset
2025-03-22 17:48:38,786:INFO:Defining folds
2025-03-22 17:48:38,786:INFO:Declaring metric variables
2025-03-22 17:48:38,788:INFO:Importing untrained model
2025-03-22 17:48:38,790:INFO:K Neighbors Classifier Imported successfully
2025-03-22 17:48:38,794:INFO:Starting cross validation
2025-03-22 17:48:38,796:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:48:40,753:INFO:Calculating mean and std
2025-03-22 17:48:40,755:INFO:Creating metrics dataframe
2025-03-22 17:48:40,756:INFO:Uploading results into container
2025-03-22 17:48:40,757:INFO:Uploading model into container now
2025-03-22 17:48:40,758:INFO:_master_model_container: 2
2025-03-22 17:48:40,758:INFO:_display_container: 2
2025-03-22 17:48:40,758:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-22 17:48:40,758:INFO:create_model() successfully completed......................................
2025-03-22 17:48:40,877:INFO:SubProcess create_model() end ==================================
2025-03-22 17:48:40,877:INFO:Creating metrics dataframe
2025-03-22 17:48:40,881:INFO:Initializing Naive Bayes
2025-03-22 17:48:40,882:INFO:Total runtime is 0.08326295614242554 minutes
2025-03-22 17:48:40,884:INFO:SubProcess create_model() called ==================================
2025-03-22 17:48:40,884:INFO:Initializing create_model()
2025-03-22 17:48:40,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:48:40,884:INFO:Checking exceptions
2025-03-22 17:48:40,885:INFO:Importing libraries
2025-03-22 17:48:40,885:INFO:Copying training dataset
2025-03-22 17:48:40,936:INFO:Defining folds
2025-03-22 17:48:40,936:INFO:Declaring metric variables
2025-03-22 17:48:40,939:INFO:Importing untrained model
2025-03-22 17:48:40,941:INFO:Naive Bayes Imported successfully
2025-03-22 17:48:40,946:INFO:Starting cross validation
2025-03-22 17:48:40,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:48:41,161:INFO:Calculating mean and std
2025-03-22 17:48:41,162:INFO:Creating metrics dataframe
2025-03-22 17:48:41,163:INFO:Uploading results into container
2025-03-22 17:48:41,164:INFO:Uploading model into container now
2025-03-22 17:48:41,164:INFO:_master_model_container: 3
2025-03-22 17:48:41,164:INFO:_display_container: 2
2025-03-22 17:48:41,164:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-22 17:48:41,164:INFO:create_model() successfully completed......................................
2025-03-22 17:48:41,277:INFO:SubProcess create_model() end ==================================
2025-03-22 17:48:41,278:INFO:Creating metrics dataframe
2025-03-22 17:48:41,282:INFO:Initializing Decision Tree Classifier
2025-03-22 17:48:41,282:INFO:Total runtime is 0.08993048270543418 minutes
2025-03-22 17:48:41,284:INFO:SubProcess create_model() called ==================================
2025-03-22 17:48:41,284:INFO:Initializing create_model()
2025-03-22 17:48:41,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:48:41,285:INFO:Checking exceptions
2025-03-22 17:48:41,285:INFO:Importing libraries
2025-03-22 17:48:41,285:INFO:Copying training dataset
2025-03-22 17:48:41,336:INFO:Defining folds
2025-03-22 17:48:41,336:INFO:Declaring metric variables
2025-03-22 17:48:41,338:INFO:Importing untrained model
2025-03-22 17:48:41,340:INFO:Decision Tree Classifier Imported successfully
2025-03-22 17:48:41,344:INFO:Starting cross validation
2025-03-22 17:48:41,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:48:41,587:INFO:Calculating mean and std
2025-03-22 17:48:41,588:INFO:Creating metrics dataframe
2025-03-22 17:48:41,589:INFO:Uploading results into container
2025-03-22 17:48:41,590:INFO:Uploading model into container now
2025-03-22 17:48:41,590:INFO:_master_model_container: 4
2025-03-22 17:48:41,590:INFO:_display_container: 2
2025-03-22 17:48:41,590:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-03-22 17:48:41,590:INFO:create_model() successfully completed......................................
2025-03-22 17:48:41,704:INFO:SubProcess create_model() end ==================================
2025-03-22 17:48:41,704:INFO:Creating metrics dataframe
2025-03-22 17:48:41,708:INFO:Initializing SVM - Linear Kernel
2025-03-22 17:48:41,708:INFO:Total runtime is 0.09702942371368409 minutes
2025-03-22 17:48:41,710:INFO:SubProcess create_model() called ==================================
2025-03-22 17:48:41,711:INFO:Initializing create_model()
2025-03-22 17:48:41,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:48:41,711:INFO:Checking exceptions
2025-03-22 17:48:41,711:INFO:Importing libraries
2025-03-22 17:48:41,711:INFO:Copying training dataset
2025-03-22 17:48:41,761:INFO:Defining folds
2025-03-22 17:48:41,762:INFO:Declaring metric variables
2025-03-22 17:48:41,764:INFO:Importing untrained model
2025-03-22 17:48:41,767:INFO:SVM - Linear Kernel Imported successfully
2025-03-22 17:48:41,770:INFO:Starting cross validation
2025-03-22 17:48:41,772:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:48:41,904:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:41,907:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:41,907:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:41,919:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:41,923:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:41,946:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:41,946:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:41,949:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:41,962:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:41,962:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:41,977:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:41,978:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:41,996:INFO:Calculating mean and std
2025-03-22 17:48:41,997:INFO:Creating metrics dataframe
2025-03-22 17:48:41,998:INFO:Uploading results into container
2025-03-22 17:48:41,999:INFO:Uploading model into container now
2025-03-22 17:48:41,999:INFO:_master_model_container: 5
2025-03-22 17:48:41,999:INFO:_display_container: 2
2025-03-22 17:48:41,999:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-22 17:48:41,999:INFO:create_model() successfully completed......................................
2025-03-22 17:48:42,116:INFO:SubProcess create_model() end ==================================
2025-03-22 17:48:42,116:INFO:Creating metrics dataframe
2025-03-22 17:48:42,121:INFO:Initializing Ridge Classifier
2025-03-22 17:48:42,121:INFO:Total runtime is 0.103901473681132 minutes
2025-03-22 17:48:42,122:INFO:SubProcess create_model() called ==================================
2025-03-22 17:48:42,122:INFO:Initializing create_model()
2025-03-22 17:48:42,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:48:42,123:INFO:Checking exceptions
2025-03-22 17:48:42,123:INFO:Importing libraries
2025-03-22 17:48:42,123:INFO:Copying training dataset
2025-03-22 17:48:42,171:INFO:Defining folds
2025-03-22 17:48:42,171:INFO:Declaring metric variables
2025-03-22 17:48:42,173:INFO:Importing untrained model
2025-03-22 17:48:42,175:INFO:Ridge Classifier Imported successfully
2025-03-22 17:48:42,179:INFO:Starting cross validation
2025-03-22 17:48:42,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:48:42,281:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:42,284:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:42,304:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:42,310:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:42,315:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:42,322:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:42,336:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:42,346:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:42,355:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:42,362:INFO:Calculating mean and std
2025-03-22 17:48:42,363:INFO:Creating metrics dataframe
2025-03-22 17:48:42,364:INFO:Uploading results into container
2025-03-22 17:48:42,365:INFO:Uploading model into container now
2025-03-22 17:48:42,365:INFO:_master_model_container: 6
2025-03-22 17:48:42,365:INFO:_display_container: 2
2025-03-22 17:48:42,366:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-03-22 17:48:42,366:INFO:create_model() successfully completed......................................
2025-03-22 17:48:42,484:INFO:SubProcess create_model() end ==================================
2025-03-22 17:48:42,484:INFO:Creating metrics dataframe
2025-03-22 17:48:42,488:INFO:Initializing Random Forest Classifier
2025-03-22 17:48:42,488:INFO:Total runtime is 0.11001890103022258 minutes
2025-03-22 17:48:42,491:INFO:SubProcess create_model() called ==================================
2025-03-22 17:48:42,491:INFO:Initializing create_model()
2025-03-22 17:48:42,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:48:42,491:INFO:Checking exceptions
2025-03-22 17:48:42,491:INFO:Importing libraries
2025-03-22 17:48:42,491:INFO:Copying training dataset
2025-03-22 17:48:42,541:INFO:Defining folds
2025-03-22 17:48:42,541:INFO:Declaring metric variables
2025-03-22 17:48:42,543:INFO:Importing untrained model
2025-03-22 17:48:42,547:INFO:Random Forest Classifier Imported successfully
2025-03-22 17:48:42,551:INFO:Starting cross validation
2025-03-22 17:48:42,553:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:48:43,072:INFO:Calculating mean and std
2025-03-22 17:48:43,073:INFO:Creating metrics dataframe
2025-03-22 17:48:43,074:INFO:Uploading results into container
2025-03-22 17:48:43,075:INFO:Uploading model into container now
2025-03-22 17:48:43,075:INFO:_master_model_container: 7
2025-03-22 17:48:43,075:INFO:_display_container: 2
2025-03-22 17:48:43,075:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 17:48:43,075:INFO:create_model() successfully completed......................................
2025-03-22 17:48:43,190:INFO:SubProcess create_model() end ==================================
2025-03-22 17:48:43,190:INFO:Creating metrics dataframe
2025-03-22 17:48:43,195:INFO:Initializing Quadratic Discriminant Analysis
2025-03-22 17:48:43,195:INFO:Total runtime is 0.12180104653040569 minutes
2025-03-22 17:48:43,197:INFO:SubProcess create_model() called ==================================
2025-03-22 17:48:43,197:INFO:Initializing create_model()
2025-03-22 17:48:43,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:48:43,198:INFO:Checking exceptions
2025-03-22 17:48:43,198:INFO:Importing libraries
2025-03-22 17:48:43,198:INFO:Copying training dataset
2025-03-22 17:48:43,246:INFO:Defining folds
2025-03-22 17:48:43,246:INFO:Declaring metric variables
2025-03-22 17:48:43,248:INFO:Importing untrained model
2025-03-22 17:48:43,250:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-22 17:48:43,255:INFO:Starting cross validation
2025-03-22 17:48:43,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:48:43,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 17:48:43,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 17:48:43,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 17:48:43,422:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 17:48:43,424:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 17:48:43,432:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 17:48:43,434:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:43,437:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:43,438:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:43,438:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:43,441:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:43,442:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:43,453:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 17:48:43,454:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 17:48:43,456:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:43,457:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 17:48:43,458:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:43,461:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:43,463:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 17:48:43,465:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:43,473:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:43,476:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:43,482:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:43,483:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:43,485:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:43,486:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:43,486:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:43,489:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:43,491:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:43,500:INFO:Calculating mean and std
2025-03-22 17:48:43,501:INFO:Creating metrics dataframe
2025-03-22 17:48:43,502:INFO:Uploading results into container
2025-03-22 17:48:43,502:INFO:Uploading model into container now
2025-03-22 17:48:43,503:INFO:_master_model_container: 8
2025-03-22 17:48:43,503:INFO:_display_container: 2
2025-03-22 17:48:43,503:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-22 17:48:43,503:INFO:create_model() successfully completed......................................
2025-03-22 17:48:43,612:INFO:SubProcess create_model() end ==================================
2025-03-22 17:48:43,612:INFO:Creating metrics dataframe
2025-03-22 17:48:43,617:INFO:Initializing Ada Boost Classifier
2025-03-22 17:48:43,617:INFO:Total runtime is 0.12884384393692017 minutes
2025-03-22 17:48:43,619:INFO:SubProcess create_model() called ==================================
2025-03-22 17:48:43,619:INFO:Initializing create_model()
2025-03-22 17:48:43,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:48:43,620:INFO:Checking exceptions
2025-03-22 17:48:43,620:INFO:Importing libraries
2025-03-22 17:48:43,620:INFO:Copying training dataset
2025-03-22 17:48:43,667:INFO:Defining folds
2025-03-22 17:48:43,667:INFO:Declaring metric variables
2025-03-22 17:48:43,669:INFO:Importing untrained model
2025-03-22 17:48:43,671:INFO:Ada Boost Classifier Imported successfully
2025-03-22 17:48:43,675:INFO:Starting cross validation
2025-03-22 17:48:43,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:48:43,757:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 17:48:43,762:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 17:48:43,772:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 17:48:43,785:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 17:48:43,798:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 17:48:43,807:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 17:48:43,818:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 17:48:43,819:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 17:48:43,845:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 17:48:45,017:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:45,030:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:45,032:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:45,034:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:45,038:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:45,040:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:45,046:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:45,061:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:45,068:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:45,070:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:45,073:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:45,079:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:45,123:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:48:45,126:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:48:45,132:INFO:Calculating mean and std
2025-03-22 17:48:45,133:INFO:Creating metrics dataframe
2025-03-22 17:48:45,134:INFO:Uploading results into container
2025-03-22 17:48:45,134:INFO:Uploading model into container now
2025-03-22 17:48:45,135:INFO:_master_model_container: 9
2025-03-22 17:48:45,135:INFO:_display_container: 2
2025-03-22 17:48:45,135:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-03-22 17:48:45,135:INFO:create_model() successfully completed......................................
2025-03-22 17:48:45,244:INFO:SubProcess create_model() end ==================================
2025-03-22 17:48:45,244:INFO:Creating metrics dataframe
2025-03-22 17:48:45,249:INFO:Initializing Gradient Boosting Classifier
2025-03-22 17:48:45,249:INFO:Total runtime is 0.15603415568669637 minutes
2025-03-22 17:48:45,251:INFO:SubProcess create_model() called ==================================
2025-03-22 17:48:45,251:INFO:Initializing create_model()
2025-03-22 17:48:45,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:48:45,251:INFO:Checking exceptions
2025-03-22 17:48:45,251:INFO:Importing libraries
2025-03-22 17:48:45,251:INFO:Copying training dataset
2025-03-22 17:48:45,300:INFO:Defining folds
2025-03-22 17:48:45,300:INFO:Declaring metric variables
2025-03-22 17:48:45,303:INFO:Importing untrained model
2025-03-22 17:48:45,305:INFO:Gradient Boosting Classifier Imported successfully
2025-03-22 17:48:45,309:INFO:Starting cross validation
2025-03-22 17:48:45,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:49:10,194:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,345:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,362:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,393:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,419:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,445:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,469:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,492:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,514:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,526:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,539:INFO:Calculating mean and std
2025-03-22 17:49:10,540:INFO:Creating metrics dataframe
2025-03-22 17:49:10,541:INFO:Uploading results into container
2025-03-22 17:49:10,542:INFO:Uploading model into container now
2025-03-22 17:49:10,542:INFO:_master_model_container: 10
2025-03-22 17:49:10,542:INFO:_display_container: 2
2025-03-22 17:49:10,542:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-22 17:49:10,542:INFO:create_model() successfully completed......................................
2025-03-22 17:49:10,652:INFO:SubProcess create_model() end ==================================
2025-03-22 17:49:10,652:INFO:Creating metrics dataframe
2025-03-22 17:49:10,657:INFO:Initializing Linear Discriminant Analysis
2025-03-22 17:49:10,657:INFO:Total runtime is 0.5795109589894613 minutes
2025-03-22 17:49:10,659:INFO:SubProcess create_model() called ==================================
2025-03-22 17:49:10,659:INFO:Initializing create_model()
2025-03-22 17:49:10,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:49:10,659:INFO:Checking exceptions
2025-03-22 17:49:10,659:INFO:Importing libraries
2025-03-22 17:49:10,660:INFO:Copying training dataset
2025-03-22 17:49:10,709:INFO:Defining folds
2025-03-22 17:49:10,709:INFO:Declaring metric variables
2025-03-22 17:49:10,711:INFO:Importing untrained model
2025-03-22 17:49:10,714:INFO:Linear Discriminant Analysis Imported successfully
2025-03-22 17:49:10,717:INFO:Starting cross validation
2025-03-22 17:49:10,720:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:49:10,847:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,849:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,857:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,863:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,880:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,883:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,884:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,901:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,914:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,916:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 17:49:10,935:INFO:Calculating mean and std
2025-03-22 17:49:10,936:INFO:Creating metrics dataframe
2025-03-22 17:49:10,937:INFO:Uploading results into container
2025-03-22 17:49:10,937:INFO:Uploading model into container now
2025-03-22 17:49:10,938:INFO:_master_model_container: 11
2025-03-22 17:49:10,938:INFO:_display_container: 2
2025-03-22 17:49:10,938:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-22 17:49:10,938:INFO:create_model() successfully completed......................................
2025-03-22 17:49:11,048:INFO:SubProcess create_model() end ==================================
2025-03-22 17:49:11,048:INFO:Creating metrics dataframe
2025-03-22 17:49:11,053:INFO:Initializing Extra Trees Classifier
2025-03-22 17:49:11,053:INFO:Total runtime is 0.5861158808072408 minutes
2025-03-22 17:49:11,055:INFO:SubProcess create_model() called ==================================
2025-03-22 17:49:11,055:INFO:Initializing create_model()
2025-03-22 17:49:11,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:49:11,055:INFO:Checking exceptions
2025-03-22 17:49:11,056:INFO:Importing libraries
2025-03-22 17:49:11,056:INFO:Copying training dataset
2025-03-22 17:49:11,103:INFO:Defining folds
2025-03-22 17:49:11,103:INFO:Declaring metric variables
2025-03-22 17:49:11,106:INFO:Importing untrained model
2025-03-22 17:49:11,108:INFO:Extra Trees Classifier Imported successfully
2025-03-22 17:49:11,113:INFO:Starting cross validation
2025-03-22 17:49:11,114:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:49:11,475:INFO:Calculating mean and std
2025-03-22 17:49:11,476:INFO:Creating metrics dataframe
2025-03-22 17:49:11,477:INFO:Uploading results into container
2025-03-22 17:49:11,477:INFO:Uploading model into container now
2025-03-22 17:49:11,478:INFO:_master_model_container: 12
2025-03-22 17:49:11,478:INFO:_display_container: 2
2025-03-22 17:49:11,478:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-03-22 17:49:11,478:INFO:create_model() successfully completed......................................
2025-03-22 17:49:11,592:INFO:SubProcess create_model() end ==================================
2025-03-22 17:49:11,592:INFO:Creating metrics dataframe
2025-03-22 17:49:11,598:INFO:Initializing Light Gradient Boosting Machine
2025-03-22 17:49:11,598:INFO:Total runtime is 0.5951839526494344 minutes
2025-03-22 17:49:11,600:INFO:SubProcess create_model() called ==================================
2025-03-22 17:49:11,600:INFO:Initializing create_model()
2025-03-22 17:49:11,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:49:11,600:INFO:Checking exceptions
2025-03-22 17:49:11,600:INFO:Importing libraries
2025-03-22 17:49:11,600:INFO:Copying training dataset
2025-03-22 17:49:11,651:INFO:Defining folds
2025-03-22 17:49:11,651:INFO:Declaring metric variables
2025-03-22 17:49:11,653:INFO:Importing untrained model
2025-03-22 17:49:11,655:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-22 17:49:11,659:INFO:Starting cross validation
2025-03-22 17:49:11,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:49:17,034:INFO:Calculating mean and std
2025-03-22 17:49:17,036:INFO:Creating metrics dataframe
2025-03-22 17:49:17,038:INFO:Uploading results into container
2025-03-22 17:49:17,038:INFO:Uploading model into container now
2025-03-22 17:49:17,039:INFO:_master_model_container: 13
2025-03-22 17:49:17,039:INFO:_display_container: 2
2025-03-22 17:49:17,040:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-22 17:49:17,040:INFO:create_model() successfully completed......................................
2025-03-22 17:49:17,175:INFO:SubProcess create_model() end ==================================
2025-03-22 17:49:17,175:INFO:Creating metrics dataframe
2025-03-22 17:49:17,181:INFO:Initializing Dummy Classifier
2025-03-22 17:49:17,181:INFO:Total runtime is 0.6882484078407287 minutes
2025-03-22 17:49:17,183:INFO:SubProcess create_model() called ==================================
2025-03-22 17:49:17,183:INFO:Initializing create_model()
2025-03-22 17:49:17,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024DB67DC1F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:49:17,183:INFO:Checking exceptions
2025-03-22 17:49:17,183:INFO:Importing libraries
2025-03-22 17:49:17,183:INFO:Copying training dataset
2025-03-22 17:49:17,235:INFO:Defining folds
2025-03-22 17:49:17,235:INFO:Declaring metric variables
2025-03-22 17:49:17,238:INFO:Importing untrained model
2025-03-22 17:49:17,240:INFO:Dummy Classifier Imported successfully
2025-03-22 17:49:17,243:INFO:Starting cross validation
2025-03-22 17:49:17,245:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:49:17,379:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:49:17,392:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:49:17,409:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:49:17,420:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:49:17,435:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:49:17,435:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:49:17,439:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:49:17,447:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:49:17,457:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 17:49:17,462:INFO:Calculating mean and std
2025-03-22 17:49:17,463:INFO:Creating metrics dataframe
2025-03-22 17:49:17,464:INFO:Uploading results into container
2025-03-22 17:49:17,464:INFO:Uploading model into container now
2025-03-22 17:49:17,465:INFO:_master_model_container: 14
2025-03-22 17:49:17,465:INFO:_display_container: 2
2025-03-22 17:49:17,465:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-03-22 17:49:17,465:INFO:create_model() successfully completed......................................
2025-03-22 17:49:17,574:INFO:SubProcess create_model() end ==================================
2025-03-22 17:49:17,575:INFO:Creating metrics dataframe
2025-03-22 17:49:17,603:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-22 17:49:17,608:INFO:Initializing create_model()
2025-03-22 17:49:17,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:49:17,609:INFO:Checking exceptions
2025-03-22 17:49:17,610:INFO:Importing libraries
2025-03-22 17:49:17,610:INFO:Copying training dataset
2025-03-22 17:49:17,655:INFO:Defining folds
2025-03-22 17:49:17,655:INFO:Declaring metric variables
2025-03-22 17:49:17,655:INFO:Importing untrained model
2025-03-22 17:49:17,655:INFO:Declaring custom model
2025-03-22 17:49:17,655:INFO:Random Forest Classifier Imported successfully
2025-03-22 17:49:17,657:INFO:Cross validation set to False
2025-03-22 17:49:17,657:INFO:Fitting Model
2025-03-22 17:49:17,780:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 17:49:17,780:INFO:create_model() successfully completed......................................
2025-03-22 17:49:17,896:INFO:Creating Dashboard logs
2025-03-22 17:49:17,899:INFO:Model: Random Forest Classifier
2025-03-22 17:49:17,946:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 17:49:18,042:INFO:Initializing predict_model()
2025-03-22 17:49:18,042:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024DAD13D630>)
2025-03-22 17:49:18,042:INFO:Checking exceptions
2025-03-22 17:49:18,042:INFO:Preloading libraries
2025-03-22 17:49:20,835:INFO:Creating Dashboard logs
2025-03-22 17:49:20,838:INFO:Model: Extra Trees Classifier
2025-03-22 17:49:20,874:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 17:49:21,115:INFO:Creating Dashboard logs
2025-03-22 17:49:21,117:INFO:Model: Logistic Regression
2025-03-22 17:49:21,153:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 17:49:21,390:INFO:Creating Dashboard logs
2025-03-22 17:49:21,392:INFO:Model: Gradient Boosting Classifier
2025-03-22 17:49:21,428:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 17:49:21,667:INFO:Creating Dashboard logs
2025-03-22 17:49:21,670:INFO:Model: Light Gradient Boosting Machine
2025-03-22 17:49:21,705:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-22 17:49:21,953:INFO:Creating Dashboard logs
2025-03-22 17:49:21,955:INFO:Model: Decision Tree Classifier
2025-03-22 17:49:21,990:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 123, 'splitter': 'best'}
2025-03-22 17:49:22,221:INFO:Creating Dashboard logs
2025-03-22 17:49:22,223:INFO:Model: K Neighbors Classifier
2025-03-22 17:49:22,261:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-22 17:49:22,497:INFO:Creating Dashboard logs
2025-03-22 17:49:22,499:INFO:Model: Ridge Classifier
2025-03-22 17:49:22,535:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2025-03-22 17:49:22,767:INFO:Creating Dashboard logs
2025-03-22 17:49:22,769:INFO:Model: Naive Bayes
2025-03-22 17:49:22,805:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-03-22 17:49:23,030:INFO:Creating Dashboard logs
2025-03-22 17:49:23,032:INFO:Model: SVM - Linear Kernel
2025-03-22 17:49:23,068:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 17:49:23,308:INFO:Creating Dashboard logs
2025-03-22 17:49:23,310:INFO:Model: Linear Discriminant Analysis
2025-03-22 17:49:23,346:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-03-22 17:49:23,570:INFO:Creating Dashboard logs
2025-03-22 17:49:23,572:INFO:Model: Ada Boost Classifier
2025-03-22 17:49:23,606:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 123}
2025-03-22 17:49:23,835:INFO:Creating Dashboard logs
2025-03-22 17:49:23,837:INFO:Model: Quadratic Discriminant Analysis
2025-03-22 17:49:23,871:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-03-22 17:49:24,094:INFO:Creating Dashboard logs
2025-03-22 17:49:24,096:INFO:Model: Dummy Classifier
2025-03-22 17:49:24,131:INFO:Logged params: {'constant': None, 'random_state': 123, 'strategy': 'prior'}
2025-03-22 17:49:24,360:INFO:_master_model_container: 14
2025-03-22 17:49:24,360:INFO:_display_container: 2
2025-03-22 17:49:24,360:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 17:49:24,360:INFO:compare_models() successfully completed......................................
2025-03-22 17:50:25,904:INFO:Initializing create_model()
2025-03-22 17:50:25,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 17:50:25,904:INFO:Checking exceptions
2025-03-22 17:50:25,914:INFO:Importing libraries
2025-03-22 17:50:25,914:INFO:Copying training dataset
2025-03-22 17:50:25,963:INFO:Defining folds
2025-03-22 17:50:25,964:INFO:Declaring metric variables
2025-03-22 17:50:25,966:INFO:Importing untrained model
2025-03-22 17:50:25,968:INFO:Random Forest Classifier Imported successfully
2025-03-22 17:50:25,972:INFO:Starting cross validation
2025-03-22 17:50:25,973:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 17:50:26,438:INFO:Calculating mean and std
2025-03-22 17:50:26,438:INFO:Creating metrics dataframe
2025-03-22 17:50:26,442:INFO:Finalizing model
2025-03-22 17:50:26,582:INFO:Creating Dashboard logs
2025-03-22 17:50:26,584:INFO:Model: Random Forest Classifier
2025-03-22 17:50:26,626:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 17:50:26,727:INFO:Initializing predict_model()
2025-03-22 17:50:26,727:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024DAD17FC70>)
2025-03-22 17:50:26,727:INFO:Checking exceptions
2025-03-22 17:50:26,727:INFO:Preloading libraries
2025-03-22 17:50:27,424:INFO:Uploading results into container
2025-03-22 17:50:27,424:INFO:Uploading model into container now
2025-03-22 17:50:27,431:INFO:_master_model_container: 15
2025-03-22 17:50:27,431:INFO:_display_container: 3
2025-03-22 17:50:27,431:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 17:50:27,431:INFO:create_model() successfully completed......................................
2025-03-22 17:50:37,027:INFO:Initializing plot_model()
2025-03-22 17:50:37,027:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, system=True)
2025-03-22 17:50:37,027:INFO:Checking exceptions
2025-03-22 17:50:37,085:INFO:Preloading libraries
2025-03-22 17:50:37,089:INFO:Copying training dataset
2025-03-22 17:50:37,090:INFO:Plot type: confusion_matrix
2025-03-22 17:50:37,731:INFO:Fitting Model
2025-03-22 17:50:37,741:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-03-22 17:50:37,741:INFO:Scoring test/hold-out set
2025-03-22 17:50:37,921:INFO:Visual Rendered Successfully
2025-03-22 17:50:38,034:INFO:plot_model() successfully completed......................................
2025-03-22 17:50:52,964:INFO:Initializing evaluate_model()
2025-03-22 17:50:52,964:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-22 17:50:53,002:INFO:Initializing plot_model()
2025-03-22 17:50:53,002:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, system=True)
2025-03-22 17:50:53,002:INFO:Checking exceptions
2025-03-22 17:50:53,042:INFO:Preloading libraries
2025-03-22 17:50:53,045:INFO:Copying training dataset
2025-03-22 17:50:53,045:INFO:Plot type: pipeline
2025-03-22 17:50:53,249:INFO:Visual Rendered Successfully
2025-03-22 17:50:53,368:INFO:plot_model() successfully completed......................................
2025-03-22 17:50:56,951:INFO:Initializing plot_model()
2025-03-22 17:50:56,951:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, system=True)
2025-03-22 17:50:56,951:INFO:Checking exceptions
2025-03-22 17:50:57,005:INFO:Preloading libraries
2025-03-22 17:50:57,008:INFO:Copying training dataset
2025-03-22 17:50:57,008:INFO:Plot type: parameter
2025-03-22 17:50:57,010:INFO:Visual Rendered Successfully
2025-03-22 17:50:57,122:INFO:plot_model() successfully completed......................................
2025-03-22 17:51:01,529:INFO:Initializing plot_model()
2025-03-22 17:51:01,529:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, system=True)
2025-03-22 17:51:01,529:INFO:Checking exceptions
2025-03-22 17:51:01,580:INFO:Preloading libraries
2025-03-22 17:51:01,583:INFO:Copying training dataset
2025-03-22 17:51:01,583:INFO:Plot type: auc
2025-03-22 17:51:02,136:INFO:Fitting Model
2025-03-22 17:51:02,136:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-03-22 17:51:02,137:INFO:Scoring test/hold-out set
2025-03-22 17:51:02,325:INFO:Visual Rendered Successfully
2025-03-22 17:51:02,437:INFO:plot_model() successfully completed......................................
2025-03-22 17:51:08,950:INFO:Initializing plot_model()
2025-03-22 17:51:08,950:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, system=True)
2025-03-22 17:51:08,951:INFO:Checking exceptions
2025-03-22 17:51:09,000:INFO:Preloading libraries
2025-03-22 17:51:09,004:INFO:Copying training dataset
2025-03-22 17:51:09,004:INFO:Plot type: confusion_matrix
2025-03-22 17:51:09,559:INFO:Fitting Model
2025-03-22 17:51:09,559:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-03-22 17:51:09,559:INFO:Scoring test/hold-out set
2025-03-22 17:51:09,702:INFO:Visual Rendered Successfully
2025-03-22 17:51:09,811:INFO:plot_model() successfully completed......................................
2025-03-22 17:51:11,941:INFO:Initializing plot_model()
2025-03-22 17:51:11,941:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, system=True)
2025-03-22 17:51:11,941:INFO:Checking exceptions
2025-03-22 17:51:30,948:INFO:Initializing plot_model()
2025-03-22 17:51:30,948:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, system=True)
2025-03-22 17:51:30,948:INFO:Checking exceptions
2025-03-22 17:51:30,986:INFO:Preloading libraries
2025-03-22 17:51:30,990:INFO:Copying training dataset
2025-03-22 17:51:30,990:INFO:Plot type: pr
2025-03-22 17:51:31,668:INFO:Fitting Model
2025-03-22 17:51:32,044:INFO:Scoring test/hold-out set
2025-03-22 17:51:32,410:INFO:Visual Rendered Successfully
2025-03-22 17:51:32,524:INFO:plot_model() successfully completed......................................
2025-03-22 17:51:34,241:INFO:Initializing plot_model()
2025-03-22 17:51:34,241:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, system=True)
2025-03-22 17:51:34,242:INFO:Checking exceptions
2025-03-22 17:51:34,282:INFO:Preloading libraries
2025-03-22 17:51:34,286:INFO:Copying training dataset
2025-03-22 17:51:34,286:INFO:Plot type: error
2025-03-22 17:51:34,843:INFO:Fitting Model
2025-03-22 17:51:34,844:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-03-22 17:51:34,844:INFO:Scoring test/hold-out set
2025-03-22 17:51:35,024:INFO:Visual Rendered Successfully
2025-03-22 17:51:35,143:INFO:plot_model() successfully completed......................................
2025-03-22 17:51:36,930:INFO:Initializing plot_model()
2025-03-22 17:51:36,930:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024DAB1D8040>, system=True)
2025-03-22 17:51:36,930:INFO:Checking exceptions
2025-03-22 17:51:36,979:INFO:Preloading libraries
2025-03-22 17:51:36,982:INFO:Copying training dataset
2025-03-22 17:51:36,982:INFO:Plot type: class_report
2025-03-22 17:51:37,539:INFO:Fitting Model
2025-03-22 17:51:37,539:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-03-22 17:51:37,540:INFO:Scoring test/hold-out set
2025-03-22 17:51:37,726:INFO:Visual Rendered Successfully
2025-03-22 17:51:37,844:INFO:plot_model() successfully completed......................................
2025-03-22 18:01:57,406:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_6a45d66753a349588b22ddf38be35b7b
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_221619f7ecb045719069b26be887bde3_3ae82585d4084134a231f1109b18975a
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_b32d26e3af13450f99ba908d12eeb629
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_1ad94c028c064a96ac53c8bac60a2d19_2ef96de268b744cf90c2ef65b7a377ea
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_42f3e1321de34ad9a4f5950d34cd941c
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_bbb8222c2d6b496a9b4a5085611c391f_937116a0a4ab496b99fdaf6cb487749b
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_662a8f12e7ed4a3f82dd53618345426b
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_864b1037d4f64aadbcbeb5bdee39f738_be2ec7d784914be593204185e2d9e315
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_f9b8568bf0754b93bab7c3a908880e74
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_d25afbcc614d481988eba1983dc9a34c_bb91ea0cfe3e48a5b5dbe4f52a4a4594
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_c9af596d816b4758909fe17f816ceab7
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_158c867b6beb420eb7e5ff93a80c6442_5db4fdf510ad4d56b4bba3762ef2df68
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_d5ad3cbcb07a40419a9a489753acd1c3
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_2843ca9a808649649b275eb523a43320_a3264d8670454f76ba7a75f369ac8c86
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,407:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_c190e5f5457442a6987239ebfe97c8ad
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_f375ea2fd797460c968ce0aacb9041dc_8655a6972ae64b1fa2d532a5f4952f3e
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_0a0569a7d25849efaa1f019bf3cf358a
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_c31ef433856c47638d3c31856eff83ac_ba9430bfb83f47618daf76c4a41e9258
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_4584393b4d9949d39674894bd139716e
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_f58580886f964b8d8f811f4894ff37ff_fe1ae55677de4658abb0817d80c96a0d
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_99382481afc04371831f3cec910021ac
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_7c62d7760c1e45369e6edef4575b72ce_35830bdeed434a92b937515fbf1586a9
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_8238d0cb2cdc4e2d95dce6a019729d7f
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_ce0bfd6e86f549689ec9e36c606a4945_172f05b4a2cd4b88ac47445bea5a103e
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_2a1e08a78a544a88a1332054d1c2cf60
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_af3d01fa49c1471bb463638c9dc6ffb8_deeca5757d6e40deb30eef42e0e8404d
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_5610cc43a8c443ddbf331550065635f1
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_0e56edc8671d4c3b9f6fc900f367c206_897395073c1c40a381f3f3659775afd2
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_37270b9bef6348a9abbec095b5f31b7c
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:01:57,408:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_12688_b7a96f7a5aca40c08a4f5ca1bf92c56f_26e4bc9f30fe4659bc964bb27ec8bfe6
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:02:05,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:02:05,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:02:05,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:02:05,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:03:05,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:03:05,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:03:05,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:03:05,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:04:32,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:04:32,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:04:32,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:04:32,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:05:15,069:INFO:PyCaret ClassificationExperiment
2025-03-22 18:05:15,069:INFO:Logging name: Mentalrisk_task2
2025-03-22 18:05:15,069:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-22 18:05:15,069:INFO:version 3.3.2
2025-03-22 18:05:15,069:INFO:Initializing setup()
2025-03-22 18:05:15,069:INFO:self.USI: 3827
2025-03-22 18:05:15,069:INFO:self._variable_keys: {'n_jobs_param', '_available_plots', 'X_train', 'html_param', 'exp_id', 'y', 'is_multiclass', '_ml_usecase', 'gpu_n_jobs_param', 'seed', 'target_param', 'y_test', 'fold_shuffle_param', 'data', 'memory', 'fold_generator', 'X_test', 'exp_name_log', 'fix_imbalance', 'USI', 'fold_groups_param', 'gpu_param', 'X', 'idx', 'pipeline', 'log_plots_param', 'y_train', 'logging_param'}
2025-03-22 18:05:15,069:INFO:Checking environment
2025-03-22 18:05:15,069:INFO:python_version: 3.10.11
2025-03-22 18:05:15,069:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-03-22 18:05:15,069:INFO:machine: AMD64
2025-03-22 18:05:15,069:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-22 18:05:15,072:INFO:Memory: svmem(total=34188517376, available=17376473088, percent=49.2, used=16812044288, free=17376473088)
2025-03-22 18:05:15,072:INFO:Physical Core: 12
2025-03-22 18:05:15,073:INFO:Logical Core: 20
2025-03-22 18:05:15,073:INFO:Checking libraries
2025-03-22 18:05:15,073:INFO:System:
2025-03-22 18:05:15,073:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-03-22 18:05:15,073:INFO:executable: C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\Scripts\python.exe
2025-03-22 18:05:15,073:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-22 18:05:15,073:INFO:PyCaret required dependencies:
2025-03-22 18:05:15,111:INFO:                 pip: 24.2
2025-03-22 18:05:15,111:INFO:          setuptools: 73.0.1
2025-03-22 18:05:15,111:INFO:             pycaret: 3.3.2
2025-03-22 18:05:15,111:INFO:             IPython: 8.34.0
2025-03-22 18:05:15,111:INFO:          ipywidgets: 8.1.5
2025-03-22 18:05:15,111:INFO:                tqdm: 4.67.1
2025-03-22 18:05:15,111:INFO:               numpy: 1.26.4
2025-03-22 18:05:15,111:INFO:              pandas: 2.1.4
2025-03-22 18:05:15,111:INFO:              jinja2: 3.1.6
2025-03-22 18:05:15,111:INFO:               scipy: 1.11.4
2025-03-22 18:05:15,111:INFO:              joblib: 1.3.2
2025-03-22 18:05:15,111:INFO:             sklearn: 1.4.2
2025-03-22 18:05:15,111:INFO:                pyod: 2.0.3
2025-03-22 18:05:15,111:INFO:            imblearn: 0.13.0
2025-03-22 18:05:15,111:INFO:   category_encoders: 2.7.0
2025-03-22 18:05:15,111:INFO:            lightgbm: 4.6.0
2025-03-22 18:05:15,111:INFO:               numba: 0.61.0
2025-03-22 18:05:15,111:INFO:            requests: 2.32.3
2025-03-22 18:05:15,111:INFO:          matplotlib: 3.7.5
2025-03-22 18:05:15,111:INFO:          scikitplot: 0.3.7
2025-03-22 18:05:15,111:INFO:         yellowbrick: 1.5
2025-03-22 18:05:15,111:INFO:              plotly: 5.24.1
2025-03-22 18:05:15,111:INFO:    plotly-resampler: Not installed
2025-03-22 18:05:15,111:INFO:             kaleido: 0.2.1
2025-03-22 18:05:15,111:INFO:           schemdraw: 0.15
2025-03-22 18:05:15,111:INFO:         statsmodels: 0.14.4
2025-03-22 18:05:15,111:INFO:              sktime: 0.26.0
2025-03-22 18:05:15,111:INFO:               tbats: 1.1.3
2025-03-22 18:05:15,111:INFO:            pmdarima: 2.0.4
2025-03-22 18:05:15,111:INFO:              psutil: 7.0.0
2025-03-22 18:05:15,111:INFO:          markupsafe: 3.0.2
2025-03-22 18:05:15,111:INFO:             pickle5: Not installed
2025-03-22 18:05:15,111:INFO:         cloudpickle: 3.1.1
2025-03-22 18:05:15,111:INFO:         deprecation: 2.1.0
2025-03-22 18:05:15,111:INFO:              xxhash: 3.5.0
2025-03-22 18:05:15,111:INFO:           wurlitzer: Not installed
2025-03-22 18:05:15,111:INFO:PyCaret optional dependencies:
2025-03-22 18:05:15,123:INFO:                shap: Not installed
2025-03-22 18:05:15,123:INFO:           interpret: Not installed
2025-03-22 18:05:15,123:INFO:                umap: Not installed
2025-03-22 18:05:15,123:INFO:     ydata_profiling: Not installed
2025-03-22 18:05:15,123:INFO:  explainerdashboard: Not installed
2025-03-22 18:05:15,123:INFO:             autoviz: Not installed
2025-03-22 18:05:15,123:INFO:           fairlearn: Not installed
2025-03-22 18:05:15,123:INFO:          deepchecks: Not installed
2025-03-22 18:05:15,123:INFO:             xgboost: Not installed
2025-03-22 18:05:15,123:INFO:            catboost: Not installed
2025-03-22 18:05:15,123:INFO:              kmodes: Not installed
2025-03-22 18:05:15,123:INFO:             mlxtend: Not installed
2025-03-22 18:05:15,123:INFO:       statsforecast: Not installed
2025-03-22 18:05:15,123:INFO:        tune_sklearn: Not installed
2025-03-22 18:05:15,123:INFO:                 ray: Not installed
2025-03-22 18:05:15,123:INFO:            hyperopt: Not installed
2025-03-22 18:05:15,123:INFO:              optuna: Not installed
2025-03-22 18:05:15,123:INFO:               skopt: Not installed
2025-03-22 18:05:15,123:INFO:              mlflow: 2.16.0
2025-03-22 18:05:15,123:INFO:              gradio: Not installed
2025-03-22 18:05:15,123:INFO:             fastapi: Not installed
2025-03-22 18:05:15,123:INFO:             uvicorn: Not installed
2025-03-22 18:05:15,123:INFO:              m2cgen: Not installed
2025-03-22 18:05:15,123:INFO:           evidently: Not installed
2025-03-22 18:05:15,123:INFO:               fugue: Not installed
2025-03-22 18:05:15,123:INFO:           streamlit: Not installed
2025-03-22 18:05:15,123:INFO:             prophet: Not installed
2025-03-22 18:05:15,123:INFO:None
2025-03-22 18:05:15,123:INFO:Set up data.
2025-03-22 18:05:15,184:INFO:Set up folding strategy.
2025-03-22 18:05:15,184:INFO:Set up train/test split.
2025-03-22 18:05:15,221:INFO:Set up index.
2025-03-22 18:05:15,221:INFO:Assigning column types.
2025-03-22 18:05:15,260:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-22 18:05:15,281:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 18:05:15,283:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:05:15,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 18:05:15,323:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:05:15,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,339:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-22 18:05:15,361:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:05:15,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,397:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:05:15,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,412:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-22 18:05:15,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,486:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:15,488:INFO:Preparing preprocessing pipeline...
2025-03-22 18:05:15,495:INFO:Set up simple imputation.
2025-03-22 18:05:15,788:INFO:Finished creating preprocessing pipeline.
2025-03-22 18:05:15,794:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 18:05:15,794:INFO:Creating final display dataframe.
2025-03-22 18:05:16,536:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type        Multiclass
3           Original data shape        (540, 769)
4        Transformed data shape        (540, 769)
5   Transformed train set shape        (432, 769)
6    Transformed test set shape        (108, 769)
7              Numeric features               768
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment      MlflowLogger
17              Experiment Name  Mentalrisk_task2
18                          USI              3827
2025-03-22 18:05:16,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:16,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:16,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:16,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:05:16,615:INFO:Logging experiment in loggers
2025-03-22 18:05:16,804:INFO:SubProcess save_model() called ==================================
2025-03-22 18:05:16,811:INFO:Initializing save_model()
2025-03-22 18:05:16,811:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\jeiso\AppData\Local\Temp\tmpyfjqi7ru\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 18:05:16,811:INFO:Adding model into prep_pipe
2025-03-22 18:05:16,811:WARNING:Only Model saved as it was a pipeline.
2025-03-22 18:05:16,817:INFO:C:\Users\jeiso\AppData\Local\Temp\tmpyfjqi7ru\Transformation Pipeline.pkl saved in current working directory
2025-03-22 18:05:16,821:INFO:Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 18:05:16,821:INFO:save_model() successfully completed......................................
2025-03-22 18:05:16,944:INFO:SubProcess save_model() end ==================================
2025-03-22 18:05:16,976:INFO:setup() successfully completed in 1.55s...............
2025-03-22 18:05:19,764:INFO:Initializing compare_models()
2025-03-22 18:05:19,764:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, include=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-22 18:05:19,764:INFO:Checking exceptions
2025-03-22 18:05:19,794:INFO:Preparing display monitor
2025-03-22 18:05:19,807:INFO:Initializing Logistic Regression
2025-03-22 18:05:19,807:INFO:Total runtime is 0.0 minutes
2025-03-22 18:05:19,810:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:19,810:INFO:Initializing create_model()
2025-03-22 18:05:19,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:19,810:INFO:Checking exceptions
2025-03-22 18:05:19,810:INFO:Importing libraries
2025-03-22 18:05:19,810:INFO:Copying training dataset
2025-03-22 18:05:19,857:INFO:Defining folds
2025-03-22 18:05:19,857:INFO:Declaring metric variables
2025-03-22 18:05:19,859:INFO:Importing untrained model
2025-03-22 18:05:19,862:INFO:Logistic Regression Imported successfully
2025-03-22 18:05:19,866:INFO:Starting cross validation
2025-03-22 18:05:19,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:22,253:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:22,292:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:22,308:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:22,343:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:22,353:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:22,358:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:22,367:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:22,374:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:22,380:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:22,425:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:22,445:INFO:Calculating mean and std
2025-03-22 18:05:22,447:INFO:Creating metrics dataframe
2025-03-22 18:05:22,448:INFO:Uploading results into container
2025-03-22 18:05:22,448:INFO:Uploading model into container now
2025-03-22 18:05:22,449:INFO:_master_model_container: 1
2025-03-22 18:05:22,449:INFO:_display_container: 2
2025-03-22 18:05:22,449:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:05:22,449:INFO:create_model() successfully completed......................................
2025-03-22 18:05:22,570:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:22,571:INFO:Creating metrics dataframe
2025-03-22 18:05:22,576:INFO:Initializing K Neighbors Classifier
2025-03-22 18:05:22,576:INFO:Total runtime is 0.04616040786107381 minutes
2025-03-22 18:05:22,578:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:22,579:INFO:Initializing create_model()
2025-03-22 18:05:22,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:22,580:INFO:Checking exceptions
2025-03-22 18:05:22,580:INFO:Importing libraries
2025-03-22 18:05:22,580:INFO:Copying training dataset
2025-03-22 18:05:22,631:INFO:Defining folds
2025-03-22 18:05:22,631:INFO:Declaring metric variables
2025-03-22 18:05:22,634:INFO:Importing untrained model
2025-03-22 18:05:22,636:INFO:K Neighbors Classifier Imported successfully
2025-03-22 18:05:22,640:INFO:Starting cross validation
2025-03-22 18:05:22,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:24,613:INFO:Calculating mean and std
2025-03-22 18:05:24,615:INFO:Creating metrics dataframe
2025-03-22 18:05:24,616:INFO:Uploading results into container
2025-03-22 18:05:24,616:INFO:Uploading model into container now
2025-03-22 18:05:24,617:INFO:_master_model_container: 2
2025-03-22 18:05:24,617:INFO:_display_container: 2
2025-03-22 18:05:24,617:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-22 18:05:24,617:INFO:create_model() successfully completed......................................
2025-03-22 18:05:24,734:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:24,734:INFO:Creating metrics dataframe
2025-03-22 18:05:24,738:INFO:Initializing Naive Bayes
2025-03-22 18:05:24,738:INFO:Total runtime is 0.08219163815180461 minutes
2025-03-22 18:05:24,740:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:24,741:INFO:Initializing create_model()
2025-03-22 18:05:24,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:24,741:INFO:Checking exceptions
2025-03-22 18:05:24,741:INFO:Importing libraries
2025-03-22 18:05:24,741:INFO:Copying training dataset
2025-03-22 18:05:24,792:INFO:Defining folds
2025-03-22 18:05:24,792:INFO:Declaring metric variables
2025-03-22 18:05:24,796:INFO:Importing untrained model
2025-03-22 18:05:24,798:INFO:Naive Bayes Imported successfully
2025-03-22 18:05:24,802:INFO:Starting cross validation
2025-03-22 18:05:24,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:24,994:INFO:Calculating mean and std
2025-03-22 18:05:24,995:INFO:Creating metrics dataframe
2025-03-22 18:05:24,996:INFO:Uploading results into container
2025-03-22 18:05:24,997:INFO:Uploading model into container now
2025-03-22 18:05:24,997:INFO:_master_model_container: 3
2025-03-22 18:05:24,997:INFO:_display_container: 2
2025-03-22 18:05:24,997:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-22 18:05:24,997:INFO:create_model() successfully completed......................................
2025-03-22 18:05:25,113:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:25,113:INFO:Creating metrics dataframe
2025-03-22 18:05:25,117:INFO:Initializing Decision Tree Classifier
2025-03-22 18:05:25,118:INFO:Total runtime is 0.08851370414098104 minutes
2025-03-22 18:05:25,120:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:25,120:INFO:Initializing create_model()
2025-03-22 18:05:25,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:25,120:INFO:Checking exceptions
2025-03-22 18:05:25,120:INFO:Importing libraries
2025-03-22 18:05:25,120:INFO:Copying training dataset
2025-03-22 18:05:25,173:INFO:Defining folds
2025-03-22 18:05:25,173:INFO:Declaring metric variables
2025-03-22 18:05:25,175:INFO:Importing untrained model
2025-03-22 18:05:25,177:INFO:Decision Tree Classifier Imported successfully
2025-03-22 18:05:25,181:INFO:Starting cross validation
2025-03-22 18:05:25,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:25,453:INFO:Calculating mean and std
2025-03-22 18:05:25,454:INFO:Creating metrics dataframe
2025-03-22 18:05:25,455:INFO:Uploading results into container
2025-03-22 18:05:25,456:INFO:Uploading model into container now
2025-03-22 18:05:25,456:INFO:_master_model_container: 4
2025-03-22 18:05:25,456:INFO:_display_container: 2
2025-03-22 18:05:25,456:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-03-22 18:05:25,456:INFO:create_model() successfully completed......................................
2025-03-22 18:05:25,572:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:25,572:INFO:Creating metrics dataframe
2025-03-22 18:05:25,577:INFO:Initializing SVM - Linear Kernel
2025-03-22 18:05:25,577:INFO:Total runtime is 0.09616447687149049 minutes
2025-03-22 18:05:25,579:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:25,580:INFO:Initializing create_model()
2025-03-22 18:05:25,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:25,580:INFO:Checking exceptions
2025-03-22 18:05:25,580:INFO:Importing libraries
2025-03-22 18:05:25,580:INFO:Copying training dataset
2025-03-22 18:05:25,630:INFO:Defining folds
2025-03-22 18:05:25,630:INFO:Declaring metric variables
2025-03-22 18:05:25,632:INFO:Importing untrained model
2025-03-22 18:05:25,635:INFO:SVM - Linear Kernel Imported successfully
2025-03-22 18:05:25,639:INFO:Starting cross validation
2025-03-22 18:05:25,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:25,740:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:25,761:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:25,770:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:25,787:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:25,802:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:25,802:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:25,817:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:25,818:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:25,833:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:25,834:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:25,851:INFO:Calculating mean and std
2025-03-22 18:05:25,852:INFO:Creating metrics dataframe
2025-03-22 18:05:25,853:INFO:Uploading results into container
2025-03-22 18:05:25,854:INFO:Uploading model into container now
2025-03-22 18:05:25,854:INFO:_master_model_container: 5
2025-03-22 18:05:25,854:INFO:_display_container: 2
2025-03-22 18:05:25,854:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-22 18:05:25,854:INFO:create_model() successfully completed......................................
2025-03-22 18:05:25,972:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:25,972:INFO:Creating metrics dataframe
2025-03-22 18:05:25,977:INFO:Initializing Ridge Classifier
2025-03-22 18:05:25,977:INFO:Total runtime is 0.10283195972442628 minutes
2025-03-22 18:05:25,979:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:25,979:INFO:Initializing create_model()
2025-03-22 18:05:25,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:25,980:INFO:Checking exceptions
2025-03-22 18:05:25,980:INFO:Importing libraries
2025-03-22 18:05:25,980:INFO:Copying training dataset
2025-03-22 18:05:26,029:INFO:Defining folds
2025-03-22 18:05:26,030:INFO:Declaring metric variables
2025-03-22 18:05:26,032:INFO:Importing untrained model
2025-03-22 18:05:26,034:INFO:Ridge Classifier Imported successfully
2025-03-22 18:05:26,038:INFO:Starting cross validation
2025-03-22 18:05:26,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:26,127:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:26,141:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:26,148:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:26,160:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:26,170:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:26,183:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:26,183:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:26,196:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:26,201:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:26,207:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:26,215:INFO:Calculating mean and std
2025-03-22 18:05:26,216:INFO:Creating metrics dataframe
2025-03-22 18:05:26,218:INFO:Uploading results into container
2025-03-22 18:05:26,218:INFO:Uploading model into container now
2025-03-22 18:05:26,218:INFO:_master_model_container: 6
2025-03-22 18:05:26,218:INFO:_display_container: 2
2025-03-22 18:05:26,219:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-03-22 18:05:26,219:INFO:create_model() successfully completed......................................
2025-03-22 18:05:26,332:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:26,332:INFO:Creating metrics dataframe
2025-03-22 18:05:26,337:INFO:Initializing Random Forest Classifier
2025-03-22 18:05:26,337:INFO:Total runtime is 0.10883278052012127 minutes
2025-03-22 18:05:26,339:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:26,340:INFO:Initializing create_model()
2025-03-22 18:05:26,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:26,340:INFO:Checking exceptions
2025-03-22 18:05:26,340:INFO:Importing libraries
2025-03-22 18:05:26,340:INFO:Copying training dataset
2025-03-22 18:05:26,390:INFO:Defining folds
2025-03-22 18:05:26,391:INFO:Declaring metric variables
2025-03-22 18:05:26,394:INFO:Importing untrained model
2025-03-22 18:05:26,396:INFO:Random Forest Classifier Imported successfully
2025-03-22 18:05:26,400:INFO:Starting cross validation
2025-03-22 18:05:26,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:26,957:INFO:Calculating mean and std
2025-03-22 18:05:26,958:INFO:Creating metrics dataframe
2025-03-22 18:05:26,959:INFO:Uploading results into container
2025-03-22 18:05:26,959:INFO:Uploading model into container now
2025-03-22 18:05:26,960:INFO:_master_model_container: 7
2025-03-22 18:05:26,960:INFO:_display_container: 2
2025-03-22 18:05:26,960:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 18:05:26,960:INFO:create_model() successfully completed......................................
2025-03-22 18:05:27,073:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:27,073:INFO:Creating metrics dataframe
2025-03-22 18:05:27,078:INFO:Initializing Quadratic Discriminant Analysis
2025-03-22 18:05:27,078:INFO:Total runtime is 0.1211888353029887 minutes
2025-03-22 18:05:27,081:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:27,081:INFO:Initializing create_model()
2025-03-22 18:05:27,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:27,081:INFO:Checking exceptions
2025-03-22 18:05:27,081:INFO:Importing libraries
2025-03-22 18:05:27,081:INFO:Copying training dataset
2025-03-22 18:05:27,134:INFO:Defining folds
2025-03-22 18:05:27,134:INFO:Declaring metric variables
2025-03-22 18:05:27,137:INFO:Importing untrained model
2025-03-22 18:05:27,139:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-22 18:05:27,143:INFO:Starting cross validation
2025-03-22 18:05:27,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:27,265:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:05:27,279:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:05:27,293:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:05:27,300:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:05:27,306:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:27,306:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:27,309:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:27,312:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:05:27,312:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:27,328:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:27,331:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:27,334:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:27,336:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:05:27,337:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:27,338:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:05:27,339:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:05:27,340:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:27,343:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:27,357:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:05:27,363:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:27,365:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:27,365:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:27,365:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:27,368:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:27,368:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:27,376:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:05:27,382:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:27,384:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:27,401:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:27,403:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:27,418:INFO:Calculating mean and std
2025-03-22 18:05:27,424:INFO:Creating metrics dataframe
2025-03-22 18:05:27,425:INFO:Uploading results into container
2025-03-22 18:05:27,425:INFO:Uploading model into container now
2025-03-22 18:05:27,426:INFO:_master_model_container: 8
2025-03-22 18:05:27,426:INFO:_display_container: 2
2025-03-22 18:05:27,426:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-22 18:05:27,426:INFO:create_model() successfully completed......................................
2025-03-22 18:05:27,541:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:27,541:INFO:Creating metrics dataframe
2025-03-22 18:05:27,546:INFO:Initializing Ada Boost Classifier
2025-03-22 18:05:27,546:INFO:Total runtime is 0.12899558146794637 minutes
2025-03-22 18:05:27,549:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:27,549:INFO:Initializing create_model()
2025-03-22 18:05:27,549:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:27,549:INFO:Checking exceptions
2025-03-22 18:05:27,549:INFO:Importing libraries
2025-03-22 18:05:27,549:INFO:Copying training dataset
2025-03-22 18:05:27,601:INFO:Defining folds
2025-03-22 18:05:27,601:INFO:Declaring metric variables
2025-03-22 18:05:27,604:INFO:Importing untrained model
2025-03-22 18:05:27,606:INFO:Ada Boost Classifier Imported successfully
2025-03-22 18:05:27,610:INFO:Starting cross validation
2025-03-22 18:05:27,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:27,677:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:05:27,688:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:05:27,698:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:05:27,706:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:05:27,717:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:05:27,728:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:05:27,739:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:05:27,752:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:05:27,763:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:05:27,777:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:05:28,946:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:28,959:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:28,962:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:29,031:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:29,032:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:29,032:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:29,033:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:29,034:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:29,035:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:29,048:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:29,057:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:29,075:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:29,094:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:29,096:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:29,125:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:29,127:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:05:29,133:INFO:Calculating mean and std
2025-03-22 18:05:29,134:INFO:Creating metrics dataframe
2025-03-22 18:05:29,135:INFO:Uploading results into container
2025-03-22 18:05:29,136:INFO:Uploading model into container now
2025-03-22 18:05:29,136:INFO:_master_model_container: 9
2025-03-22 18:05:29,136:INFO:_display_container: 2
2025-03-22 18:05:29,136:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-03-22 18:05:29,136:INFO:create_model() successfully completed......................................
2025-03-22 18:05:29,249:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:29,249:INFO:Creating metrics dataframe
2025-03-22 18:05:29,255:INFO:Initializing Gradient Boosting Classifier
2025-03-22 18:05:29,255:INFO:Total runtime is 0.15747079849243165 minutes
2025-03-22 18:05:29,256:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:29,257:INFO:Initializing create_model()
2025-03-22 18:05:29,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:29,257:INFO:Checking exceptions
2025-03-22 18:05:29,257:INFO:Importing libraries
2025-03-22 18:05:29,257:INFO:Copying training dataset
2025-03-22 18:05:29,308:INFO:Defining folds
2025-03-22 18:05:29,308:INFO:Declaring metric variables
2025-03-22 18:05:29,311:INFO:Importing untrained model
2025-03-22 18:05:29,313:INFO:Gradient Boosting Classifier Imported successfully
2025-03-22 18:05:29,317:INFO:Starting cross validation
2025-03-22 18:05:29,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:57,030:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:57,309:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:57,356:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:57,412:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:57,450:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:57,479:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:57,487:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:57,535:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:57,596:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:57,857:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:57,865:INFO:Calculating mean and std
2025-03-22 18:05:57,866:INFO:Creating metrics dataframe
2025-03-22 18:05:57,867:INFO:Uploading results into container
2025-03-22 18:05:57,868:INFO:Uploading model into container now
2025-03-22 18:05:57,868:INFO:_master_model_container: 10
2025-03-22 18:05:57,868:INFO:_display_container: 2
2025-03-22 18:05:57,868:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-22 18:05:57,868:INFO:create_model() successfully completed......................................
2025-03-22 18:05:57,985:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:57,985:INFO:Creating metrics dataframe
2025-03-22 18:05:57,990:INFO:Initializing Linear Discriminant Analysis
2025-03-22 18:05:57,990:INFO:Total runtime is 0.6363951484362285 minutes
2025-03-22 18:05:57,993:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:57,993:INFO:Initializing create_model()
2025-03-22 18:05:57,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:57,993:INFO:Checking exceptions
2025-03-22 18:05:57,993:INFO:Importing libraries
2025-03-22 18:05:57,993:INFO:Copying training dataset
2025-03-22 18:05:58,048:INFO:Defining folds
2025-03-22 18:05:58,048:INFO:Declaring metric variables
2025-03-22 18:05:58,050:INFO:Importing untrained model
2025-03-22 18:05:58,052:INFO:Linear Discriminant Analysis Imported successfully
2025-03-22 18:05:58,055:INFO:Starting cross validation
2025-03-22 18:05:58,057:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:58,172:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:58,190:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:58,203:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:58,209:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:58,234:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:58,242:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:58,244:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:58,267:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:58,272:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:58,282:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:05:58,295:INFO:Calculating mean and std
2025-03-22 18:05:58,296:INFO:Creating metrics dataframe
2025-03-22 18:05:58,297:INFO:Uploading results into container
2025-03-22 18:05:58,297:INFO:Uploading model into container now
2025-03-22 18:05:58,298:INFO:_master_model_container: 11
2025-03-22 18:05:58,298:INFO:_display_container: 2
2025-03-22 18:05:58,298:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-22 18:05:58,298:INFO:create_model() successfully completed......................................
2025-03-22 18:05:58,412:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:58,412:INFO:Creating metrics dataframe
2025-03-22 18:05:58,417:INFO:Initializing Extra Trees Classifier
2025-03-22 18:05:58,417:INFO:Total runtime is 0.6435048341751098 minutes
2025-03-22 18:05:58,419:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:58,420:INFO:Initializing create_model()
2025-03-22 18:05:58,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:58,420:INFO:Checking exceptions
2025-03-22 18:05:58,420:INFO:Importing libraries
2025-03-22 18:05:58,420:INFO:Copying training dataset
2025-03-22 18:05:58,468:INFO:Defining folds
2025-03-22 18:05:58,468:INFO:Declaring metric variables
2025-03-22 18:05:58,470:INFO:Importing untrained model
2025-03-22 18:05:58,472:INFO:Extra Trees Classifier Imported successfully
2025-03-22 18:05:58,477:INFO:Starting cross validation
2025-03-22 18:05:58,479:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:05:58,896:INFO:Calculating mean and std
2025-03-22 18:05:58,897:INFO:Creating metrics dataframe
2025-03-22 18:05:58,898:INFO:Uploading results into container
2025-03-22 18:05:58,898:INFO:Uploading model into container now
2025-03-22 18:05:58,899:INFO:_master_model_container: 12
2025-03-22 18:05:58,899:INFO:_display_container: 2
2025-03-22 18:05:58,899:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-03-22 18:05:58,899:INFO:create_model() successfully completed......................................
2025-03-22 18:05:59,014:INFO:SubProcess create_model() end ==================================
2025-03-22 18:05:59,014:INFO:Creating metrics dataframe
2025-03-22 18:05:59,019:INFO:Initializing Light Gradient Boosting Machine
2025-03-22 18:05:59,019:INFO:Total runtime is 0.6535459796587626 minutes
2025-03-22 18:05:59,021:INFO:SubProcess create_model() called ==================================
2025-03-22 18:05:59,022:INFO:Initializing create_model()
2025-03-22 18:05:59,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:05:59,022:INFO:Checking exceptions
2025-03-22 18:05:59,022:INFO:Importing libraries
2025-03-22 18:05:59,022:INFO:Copying training dataset
2025-03-22 18:05:59,071:INFO:Defining folds
2025-03-22 18:05:59,071:INFO:Declaring metric variables
2025-03-22 18:05:59,074:INFO:Importing untrained model
2025-03-22 18:05:59,077:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-22 18:05:59,080:INFO:Starting cross validation
2025-03-22 18:05:59,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:06:05,841:INFO:Calculating mean and std
2025-03-22 18:06:05,843:INFO:Creating metrics dataframe
2025-03-22 18:06:05,845:INFO:Uploading results into container
2025-03-22 18:06:05,845:INFO:Uploading model into container now
2025-03-22 18:06:05,846:INFO:_master_model_container: 13
2025-03-22 18:06:05,846:INFO:_display_container: 2
2025-03-22 18:06:05,847:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-22 18:06:05,847:INFO:create_model() successfully completed......................................
2025-03-22 18:06:06,004:INFO:SubProcess create_model() end ==================================
2025-03-22 18:06:06,004:INFO:Creating metrics dataframe
2025-03-22 18:06:06,012:INFO:Initializing Dummy Classifier
2025-03-22 18:06:06,012:INFO:Total runtime is 0.770088279247284 minutes
2025-03-22 18:06:06,015:INFO:SubProcess create_model() called ==================================
2025-03-22 18:06:06,016:INFO:Initializing create_model()
2025-03-22 18:06:06,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F3ADBCB730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:06:06,016:INFO:Checking exceptions
2025-03-22 18:06:06,016:INFO:Importing libraries
2025-03-22 18:06:06,016:INFO:Copying training dataset
2025-03-22 18:06:06,085:INFO:Defining folds
2025-03-22 18:06:06,086:INFO:Declaring metric variables
2025-03-22 18:06:06,088:INFO:Importing untrained model
2025-03-22 18:06:06,090:INFO:Dummy Classifier Imported successfully
2025-03-22 18:06:06,094:INFO:Starting cross validation
2025-03-22 18:06:06,095:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:06:06,259:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:06:06,271:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:06:06,289:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:06:06,308:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:06:06,309:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:06:06,319:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:06:06,340:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:06:06,350:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:06:06,362:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:06:06,362:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:06:06,375:INFO:Calculating mean and std
2025-03-22 18:06:06,376:INFO:Creating metrics dataframe
2025-03-22 18:06:06,378:INFO:Uploading results into container
2025-03-22 18:06:06,378:INFO:Uploading model into container now
2025-03-22 18:06:06,379:INFO:_master_model_container: 14
2025-03-22 18:06:06,379:INFO:_display_container: 2
2025-03-22 18:06:06,379:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-03-22 18:06:06,379:INFO:create_model() successfully completed......................................
2025-03-22 18:06:06,504:INFO:SubProcess create_model() end ==================================
2025-03-22 18:06:06,504:INFO:Creating metrics dataframe
2025-03-22 18:06:06,512:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-22 18:06:06,517:INFO:Initializing create_model()
2025-03-22 18:06:06,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:06:06,517:INFO:Checking exceptions
2025-03-22 18:06:06,519:INFO:Importing libraries
2025-03-22 18:06:06,519:INFO:Copying training dataset
2025-03-22 18:06:06,577:INFO:Defining folds
2025-03-22 18:06:06,578:INFO:Declaring metric variables
2025-03-22 18:06:06,578:INFO:Importing untrained model
2025-03-22 18:06:06,578:INFO:Declaring custom model
2025-03-22 18:06:06,578:INFO:Logistic Regression Imported successfully
2025-03-22 18:06:06,579:INFO:Cross validation set to False
2025-03-22 18:06:06,579:INFO:Fitting Model
2025-03-22 18:06:06,739:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:06:06,740:INFO:create_model() successfully completed......................................
2025-03-22 18:06:06,856:INFO:Creating Dashboard logs
2025-03-22 18:06:06,859:INFO:Model: Logistic Regression
2025-03-22 18:06:06,903:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 18:06:06,996:INFO:Initializing predict_model()
2025-03-22 18:06:06,996:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F3B5810040>)
2025-03-22 18:06:06,996:INFO:Checking exceptions
2025-03-22 18:06:06,996:INFO:Preloading libraries
2025-03-22 18:06:08,490:INFO:Creating Dashboard logs
2025-03-22 18:06:08,494:INFO:Model: Ridge Classifier
2025-03-22 18:06:08,533:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2025-03-22 18:06:08,786:INFO:Creating Dashboard logs
2025-03-22 18:06:08,789:INFO:Model: SVM - Linear Kernel
2025-03-22 18:06:08,824:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 18:06:09,080:INFO:Creating Dashboard logs
2025-03-22 18:06:09,082:INFO:Model: Random Forest Classifier
2025-03-22 18:06:09,117:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 18:06:09,379:INFO:Creating Dashboard logs
2025-03-22 18:06:09,382:INFO:Model: Light Gradient Boosting Machine
2025-03-22 18:06:09,416:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-22 18:06:09,673:INFO:Creating Dashboard logs
2025-03-22 18:06:09,675:INFO:Model: Extra Trees Classifier
2025-03-22 18:06:09,711:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 18:06:09,965:INFO:Creating Dashboard logs
2025-03-22 18:06:09,968:INFO:Model: Gradient Boosting Classifier
2025-03-22 18:06:10,002:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 18:06:10,258:INFO:Creating Dashboard logs
2025-03-22 18:06:10,261:INFO:Model: Naive Bayes
2025-03-22 18:06:10,296:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-03-22 18:06:10,532:INFO:Creating Dashboard logs
2025-03-22 18:06:10,534:INFO:Model: K Neighbors Classifier
2025-03-22 18:06:10,567:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-22 18:06:10,802:INFO:Creating Dashboard logs
2025-03-22 18:06:10,805:INFO:Model: Decision Tree Classifier
2025-03-22 18:06:10,841:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 123, 'splitter': 'best'}
2025-03-22 18:06:11,080:INFO:Creating Dashboard logs
2025-03-22 18:06:11,083:INFO:Model: Linear Discriminant Analysis
2025-03-22 18:06:11,118:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-03-22 18:06:11,360:INFO:Creating Dashboard logs
2025-03-22 18:06:11,362:INFO:Model: Ada Boost Classifier
2025-03-22 18:06:11,399:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 123}
2025-03-22 18:06:11,634:INFO:Creating Dashboard logs
2025-03-22 18:06:11,637:INFO:Model: Quadratic Discriminant Analysis
2025-03-22 18:06:11,670:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-03-22 18:06:11,909:INFO:Creating Dashboard logs
2025-03-22 18:06:11,910:INFO:Model: Dummy Classifier
2025-03-22 18:06:11,947:INFO:Logged params: {'constant': None, 'random_state': 123, 'strategy': 'prior'}
2025-03-22 18:06:12,181:INFO:_master_model_container: 14
2025-03-22 18:06:12,181:INFO:_display_container: 2
2025-03-22 18:06:12,181:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:06:12,181:INFO:compare_models() successfully completed......................................
2025-03-22 18:07:04,481:INFO:Initializing create_model()
2025-03-22 18:07:04,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:07:04,481:INFO:Checking exceptions
2025-03-22 18:07:04,490:INFO:Importing libraries
2025-03-22 18:07:04,490:INFO:Copying training dataset
2025-03-22 18:07:04,537:INFO:Defining folds
2025-03-22 18:07:04,538:INFO:Declaring metric variables
2025-03-22 18:07:04,540:INFO:Importing untrained model
2025-03-22 18:07:04,543:INFO:Logistic Regression Imported successfully
2025-03-22 18:07:04,546:INFO:Starting cross validation
2025-03-22 18:07:04,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:07:04,703:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:07:04,706:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:07:04,721:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:07:04,727:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:07:04,728:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:07:04,755:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:07:04,757:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:07:04,760:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:07:04,770:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:07:04,771:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:07:04,781:INFO:Calculating mean and std
2025-03-22 18:07:04,782:INFO:Creating metrics dataframe
2025-03-22 18:07:04,785:INFO:Finalizing model
2025-03-22 18:07:04,942:INFO:Creating Dashboard logs
2025-03-22 18:07:04,944:INFO:Model: Logistic Regression
2025-03-22 18:07:04,991:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 18:07:05,097:INFO:Initializing predict_model()
2025-03-22 18:07:05,097:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001F3B5943AC0>)
2025-03-22 18:07:05,097:INFO:Checking exceptions
2025-03-22 18:07:05,097:INFO:Preloading libraries
2025-03-22 18:07:05,722:INFO:Uploading results into container
2025-03-22 18:07:05,722:INFO:Uploading model into container now
2025-03-22 18:07:05,729:INFO:_master_model_container: 15
2025-03-22 18:07:05,729:INFO:_display_container: 3
2025-03-22 18:07:05,729:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:07:05,729:INFO:create_model() successfully completed......................................
2025-03-22 18:07:14,172:INFO:Initializing plot_model()
2025-03-22 18:07:14,172:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, system=True)
2025-03-22 18:07:14,172:INFO:Checking exceptions
2025-03-22 18:07:14,193:INFO:Preloading libraries
2025-03-22 18:07:14,194:INFO:Copying training dataset
2025-03-22 18:07:14,194:INFO:Plot type: confusion_matrix
2025-03-22 18:07:14,776:INFO:Fitting Model
2025-03-22 18:07:14,776:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 18:07:14,776:INFO:Scoring test/hold-out set
2025-03-22 18:07:14,879:INFO:Visual Rendered Successfully
2025-03-22 18:07:14,996:INFO:plot_model() successfully completed......................................
2025-03-22 18:07:46,611:INFO:Initializing evaluate_model()
2025-03-22 18:07:46,611:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-22 18:07:46,641:INFO:Initializing plot_model()
2025-03-22 18:07:46,641:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F3AD1A3940>, system=True)
2025-03-22 18:07:46,641:INFO:Checking exceptions
2025-03-22 18:07:46,662:INFO:Preloading libraries
2025-03-22 18:07:46,662:INFO:Copying training dataset
2025-03-22 18:07:46,662:INFO:Plot type: pipeline
2025-03-22 18:07:46,753:INFO:Visual Rendered Successfully
2025-03-22 18:07:46,866:INFO:plot_model() successfully completed......................................
2025-03-22 18:07:49,418:INFO:Initializing save_model()
2025-03-22 18:07:49,418:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=rf_task2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 18:07:49,418:INFO:Adding model into prep_pipe
2025-03-22 18:07:49,426:INFO:rf_task2.pkl saved in current working directory
2025-03-22 18:07:49,430:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'feature_17', 'feature_18',
                                             'feature_19', 'feat...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-03-22 18:07:49,430:INFO:save_model() successfully completed......................................
2025-03-22 18:10:20,341:INFO:PyCaret ClassificationExperiment
2025-03-22 18:10:20,341:INFO:Logging name: Mentalrisk_task1
2025-03-22 18:10:20,341:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-22 18:10:20,341:INFO:version 3.3.2
2025-03-22 18:10:20,341:INFO:Initializing setup()
2025-03-22 18:10:20,341:INFO:self.USI: 93d0
2025-03-22 18:10:20,341:INFO:self._variable_keys: {'target_param', '_ml_usecase', 'memory', 'exp_id', 'exp_name_log', 'fold_shuffle_param', 'log_plots_param', 'data', 'logging_param', 'fold_generator', 'fix_imbalance', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'X', 'idx', 'seed', '_available_plots', 'html_param', 'gpu_param', 'pipeline', 'fold_groups_param', 'is_multiclass', 'y_test', 'X_train', 'y_train', 'USI', 'X_test'}
2025-03-22 18:10:20,341:INFO:Checking environment
2025-03-22 18:10:20,341:INFO:python_version: 3.10.11
2025-03-22 18:10:20,341:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-03-22 18:10:20,342:INFO:machine: AMD64
2025-03-22 18:10:20,342:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-22 18:10:20,345:INFO:Memory: svmem(total=34188517376, available=14192001024, percent=58.5, used=19996516352, free=14192001024)
2025-03-22 18:10:20,345:INFO:Physical Core: 12
2025-03-22 18:10:20,345:INFO:Logical Core: 20
2025-03-22 18:10:20,345:INFO:Checking libraries
2025-03-22 18:10:20,345:INFO:System:
2025-03-22 18:10:20,345:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-03-22 18:10:20,345:INFO:executable: C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\Scripts\python.exe
2025-03-22 18:10:20,345:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-22 18:10:20,345:INFO:PyCaret required dependencies:
2025-03-22 18:10:20,387:INFO:                 pip: 24.2
2025-03-22 18:10:20,387:INFO:          setuptools: 73.0.1
2025-03-22 18:10:20,387:INFO:             pycaret: 3.3.2
2025-03-22 18:10:20,387:INFO:             IPython: 8.34.0
2025-03-22 18:10:20,387:INFO:          ipywidgets: 8.1.5
2025-03-22 18:10:20,387:INFO:                tqdm: 4.67.1
2025-03-22 18:10:20,387:INFO:               numpy: 1.26.4
2025-03-22 18:10:20,387:INFO:              pandas: 2.1.4
2025-03-22 18:10:20,387:INFO:              jinja2: 3.1.6
2025-03-22 18:10:20,387:INFO:               scipy: 1.11.4
2025-03-22 18:10:20,387:INFO:              joblib: 1.3.2
2025-03-22 18:10:20,388:INFO:             sklearn: 1.4.2
2025-03-22 18:10:20,388:INFO:                pyod: 2.0.3
2025-03-22 18:10:20,388:INFO:            imblearn: 0.13.0
2025-03-22 18:10:20,388:INFO:   category_encoders: 2.7.0
2025-03-22 18:10:20,388:INFO:            lightgbm: 4.6.0
2025-03-22 18:10:20,388:INFO:               numba: 0.61.0
2025-03-22 18:10:20,388:INFO:            requests: 2.32.3
2025-03-22 18:10:20,388:INFO:          matplotlib: 3.7.5
2025-03-22 18:10:20,388:INFO:          scikitplot: 0.3.7
2025-03-22 18:10:20,388:INFO:         yellowbrick: 1.5
2025-03-22 18:10:20,388:INFO:              plotly: 5.24.1
2025-03-22 18:10:20,388:INFO:    plotly-resampler: Not installed
2025-03-22 18:10:20,388:INFO:             kaleido: 0.2.1
2025-03-22 18:10:20,388:INFO:           schemdraw: 0.15
2025-03-22 18:10:20,388:INFO:         statsmodels: 0.14.4
2025-03-22 18:10:20,388:INFO:              sktime: 0.26.0
2025-03-22 18:10:20,388:INFO:               tbats: 1.1.3
2025-03-22 18:10:20,388:INFO:            pmdarima: 2.0.4
2025-03-22 18:10:20,388:INFO:              psutil: 7.0.0
2025-03-22 18:10:20,388:INFO:          markupsafe: 3.0.2
2025-03-22 18:10:20,388:INFO:             pickle5: Not installed
2025-03-22 18:10:20,388:INFO:         cloudpickle: 3.1.1
2025-03-22 18:10:20,388:INFO:         deprecation: 2.1.0
2025-03-22 18:10:20,388:INFO:              xxhash: 3.5.0
2025-03-22 18:10:20,388:INFO:           wurlitzer: Not installed
2025-03-22 18:10:20,388:INFO:PyCaret optional dependencies:
2025-03-22 18:10:20,400:INFO:                shap: Not installed
2025-03-22 18:10:20,400:INFO:           interpret: Not installed
2025-03-22 18:10:20,400:INFO:                umap: Not installed
2025-03-22 18:10:20,400:INFO:     ydata_profiling: Not installed
2025-03-22 18:10:20,400:INFO:  explainerdashboard: Not installed
2025-03-22 18:10:20,400:INFO:             autoviz: Not installed
2025-03-22 18:10:20,400:INFO:           fairlearn: Not installed
2025-03-22 18:10:20,400:INFO:          deepchecks: Not installed
2025-03-22 18:10:20,400:INFO:             xgboost: Not installed
2025-03-22 18:10:20,400:INFO:            catboost: Not installed
2025-03-22 18:10:20,400:INFO:              kmodes: Not installed
2025-03-22 18:10:20,400:INFO:             mlxtend: Not installed
2025-03-22 18:10:20,400:INFO:       statsforecast: Not installed
2025-03-22 18:10:20,400:INFO:        tune_sklearn: Not installed
2025-03-22 18:10:20,400:INFO:                 ray: Not installed
2025-03-22 18:10:20,400:INFO:            hyperopt: Not installed
2025-03-22 18:10:20,400:INFO:              optuna: Not installed
2025-03-22 18:10:20,400:INFO:               skopt: Not installed
2025-03-22 18:10:20,400:INFO:              mlflow: 2.16.0
2025-03-22 18:10:20,400:INFO:              gradio: Not installed
2025-03-22 18:10:20,400:INFO:             fastapi: Not installed
2025-03-22 18:10:20,400:INFO:             uvicorn: Not installed
2025-03-22 18:10:20,400:INFO:              m2cgen: Not installed
2025-03-22 18:10:20,400:INFO:           evidently: Not installed
2025-03-22 18:10:20,400:INFO:               fugue: Not installed
2025-03-22 18:10:20,400:INFO:           streamlit: Not installed
2025-03-22 18:10:20,400:INFO:             prophet: Not installed
2025-03-22 18:10:20,400:INFO:None
2025-03-22 18:10:20,400:INFO:Set up data.
2025-03-22 18:10:20,583:INFO:Set up folding strategy.
2025-03-22 18:10:20,583:INFO:Set up train/test split.
2025-03-22 18:10:20,618:INFO:Set up index.
2025-03-22 18:10:20,618:INFO:Assigning column types.
2025-03-22 18:10:20,659:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-22 18:10:20,680:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 18:10:20,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:10:20,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 18:10:20,721:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:10:20,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,736:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-22 18:10:20,759:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:10:20,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,795:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:10:20,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,808:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-22 18:10:20,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:20,882:INFO:Preparing preprocessing pipeline...
2025-03-22 18:10:20,890:INFO:Set up simple imputation.
2025-03-22 18:10:21,059:INFO:Finished creating preprocessing pipeline.
2025-03-22 18:10:21,063:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 18:10:21,063:INFO:Creating final display dataframe.
2025-03-22 18:10:21,761:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             level
2                   Target type            Binary
3           Original data shape        (462, 769)
4        Transformed data shape        (462, 769)
5   Transformed train set shape        (369, 769)
6    Transformed test set shape         (93, 769)
7              Numeric features               768
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment      MlflowLogger
17              Experiment Name  Mentalrisk_task1
18                          USI              93d0
2025-03-22 18:10:21,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:21,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:21,840:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:21,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:10:21,841:INFO:Logging experiment in loggers
2025-03-22 18:10:21,999:INFO:SubProcess save_model() called ==================================
2025-03-22 18:10:22,006:INFO:Initializing save_model()
2025-03-22 18:10:22,006:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\jeiso\AppData\Local\Temp\tmp2zdrgf6c\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 18:10:22,006:INFO:Adding model into prep_pipe
2025-03-22 18:10:22,006:WARNING:Only Model saved as it was a pipeline.
2025-03-22 18:10:22,011:INFO:C:\Users\jeiso\AppData\Local\Temp\tmp2zdrgf6c\Transformation Pipeline.pkl saved in current working directory
2025-03-22 18:10:22,015:INFO:Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 18:10:22,015:INFO:save_model() successfully completed......................................
2025-03-22 18:10:22,117:INFO:SubProcess save_model() end ==================================
2025-03-22 18:10:22,155:INFO:setup() successfully completed in 1.5s...............
2025-03-22 18:12:53,502:INFO:PyCaret ClassificationExperiment
2025-03-22 18:12:53,502:INFO:Logging name: Mentalrisk_task2
2025-03-22 18:12:53,502:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-22 18:12:53,502:INFO:version 3.3.2
2025-03-22 18:12:53,502:INFO:Initializing setup()
2025-03-22 18:12:53,502:INFO:self.USI: 9f98
2025-03-22 18:12:53,502:INFO:self._variable_keys: {'n_jobs_param', '_available_plots', 'X_train', 'html_param', 'exp_id', 'y', 'is_multiclass', '_ml_usecase', 'gpu_n_jobs_param', 'seed', 'target_param', 'y_test', 'fold_shuffle_param', 'data', 'memory', 'fold_generator', 'X_test', 'exp_name_log', 'fix_imbalance', 'USI', 'fold_groups_param', 'gpu_param', 'X', 'idx', 'pipeline', 'log_plots_param', 'y_train', 'logging_param'}
2025-03-22 18:12:53,502:INFO:Checking environment
2025-03-22 18:12:53,502:INFO:python_version: 3.10.11
2025-03-22 18:12:53,502:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-03-22 18:12:53,502:INFO:machine: AMD64
2025-03-22 18:12:53,502:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-22 18:12:53,506:INFO:Memory: svmem(total=34188517376, available=16913129472, percent=50.5, used=17275387904, free=16913129472)
2025-03-22 18:12:53,506:INFO:Physical Core: 12
2025-03-22 18:12:53,506:INFO:Logical Core: 20
2025-03-22 18:12:53,506:INFO:Checking libraries
2025-03-22 18:12:53,506:INFO:System:
2025-03-22 18:12:53,506:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-03-22 18:12:53,506:INFO:executable: C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\Scripts\python.exe
2025-03-22 18:12:53,506:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-22 18:12:53,506:INFO:PyCaret required dependencies:
2025-03-22 18:12:53,506:INFO:                 pip: 24.2
2025-03-22 18:12:53,506:INFO:          setuptools: 73.0.1
2025-03-22 18:12:53,506:INFO:             pycaret: 3.3.2
2025-03-22 18:12:53,506:INFO:             IPython: 8.34.0
2025-03-22 18:12:53,506:INFO:          ipywidgets: 8.1.5
2025-03-22 18:12:53,506:INFO:                tqdm: 4.67.1
2025-03-22 18:12:53,506:INFO:               numpy: 1.26.4
2025-03-22 18:12:53,506:INFO:              pandas: 2.1.4
2025-03-22 18:12:53,506:INFO:              jinja2: 3.1.6
2025-03-22 18:12:53,506:INFO:               scipy: 1.11.4
2025-03-22 18:12:53,506:INFO:              joblib: 1.3.2
2025-03-22 18:12:53,506:INFO:             sklearn: 1.4.2
2025-03-22 18:12:53,506:INFO:                pyod: 2.0.3
2025-03-22 18:12:53,506:INFO:            imblearn: 0.13.0
2025-03-22 18:12:53,506:INFO:   category_encoders: 2.7.0
2025-03-22 18:12:53,506:INFO:            lightgbm: 4.6.0
2025-03-22 18:12:53,506:INFO:               numba: 0.61.0
2025-03-22 18:12:53,506:INFO:            requests: 2.32.3
2025-03-22 18:12:53,506:INFO:          matplotlib: 3.7.5
2025-03-22 18:12:53,506:INFO:          scikitplot: 0.3.7
2025-03-22 18:12:53,506:INFO:         yellowbrick: 1.5
2025-03-22 18:12:53,506:INFO:              plotly: 5.24.1
2025-03-22 18:12:53,506:INFO:    plotly-resampler: Not installed
2025-03-22 18:12:53,506:INFO:             kaleido: 0.2.1
2025-03-22 18:12:53,506:INFO:           schemdraw: 0.15
2025-03-22 18:12:53,506:INFO:         statsmodels: 0.14.4
2025-03-22 18:12:53,506:INFO:              sktime: 0.26.0
2025-03-22 18:12:53,507:INFO:               tbats: 1.1.3
2025-03-22 18:12:53,507:INFO:            pmdarima: 2.0.4
2025-03-22 18:12:53,507:INFO:              psutil: 7.0.0
2025-03-22 18:12:53,507:INFO:          markupsafe: 3.0.2
2025-03-22 18:12:53,507:INFO:             pickle5: Not installed
2025-03-22 18:12:53,507:INFO:         cloudpickle: 3.1.1
2025-03-22 18:12:53,507:INFO:         deprecation: 2.1.0
2025-03-22 18:12:53,507:INFO:              xxhash: 3.5.0
2025-03-22 18:12:53,507:INFO:           wurlitzer: Not installed
2025-03-22 18:12:53,507:INFO:PyCaret optional dependencies:
2025-03-22 18:12:53,507:INFO:                shap: Not installed
2025-03-22 18:12:53,507:INFO:           interpret: Not installed
2025-03-22 18:12:53,507:INFO:                umap: Not installed
2025-03-22 18:12:53,507:INFO:     ydata_profiling: Not installed
2025-03-22 18:12:53,507:INFO:  explainerdashboard: Not installed
2025-03-22 18:12:53,507:INFO:             autoviz: Not installed
2025-03-22 18:12:53,507:INFO:           fairlearn: Not installed
2025-03-22 18:12:53,507:INFO:          deepchecks: Not installed
2025-03-22 18:12:53,507:INFO:             xgboost: Not installed
2025-03-22 18:12:53,507:INFO:            catboost: Not installed
2025-03-22 18:12:53,507:INFO:              kmodes: Not installed
2025-03-22 18:12:53,507:INFO:             mlxtend: Not installed
2025-03-22 18:12:53,507:INFO:       statsforecast: Not installed
2025-03-22 18:12:53,507:INFO:        tune_sklearn: Not installed
2025-03-22 18:12:53,507:INFO:                 ray: Not installed
2025-03-22 18:12:53,507:INFO:            hyperopt: Not installed
2025-03-22 18:12:53,507:INFO:              optuna: Not installed
2025-03-22 18:12:53,507:INFO:               skopt: Not installed
2025-03-22 18:12:53,507:INFO:              mlflow: 2.16.0
2025-03-22 18:12:53,507:INFO:              gradio: Not installed
2025-03-22 18:12:53,507:INFO:             fastapi: Not installed
2025-03-22 18:12:53,507:INFO:             uvicorn: Not installed
2025-03-22 18:12:53,507:INFO:              m2cgen: Not installed
2025-03-22 18:12:53,507:INFO:           evidently: Not installed
2025-03-22 18:12:53,507:INFO:               fugue: Not installed
2025-03-22 18:12:53,507:INFO:           streamlit: Not installed
2025-03-22 18:12:53,507:INFO:             prophet: Not installed
2025-03-22 18:12:53,507:INFO:None
2025-03-22 18:12:53,507:INFO:Set up data.
2025-03-22 18:13:01,741:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_e2585ca9dd924029b25bbd116a7d67a9
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,741:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_97f1434befab4e38bb132a25b2d2d08e_ae8d9a57b5054d4ab4e2c7a0d485d295
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,741:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_f8c74b0413e541b8af1b7ede41224d8b
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,741:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_1040f0b6e1054e27b31f092b016bd895_6bd0f0f7dcc0427db81cd3f4f3351a95
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_b06e67c7cd9648b987fd9042adebc846
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_a6fb4420c59f4698b980eb2662a118f2_6de565f4fb4743afb41d9ac1b5ff4026
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_8d39a9d31641497599d3849abb990b15
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_221755ea9170486093042b1f1efc2d04_65a88783a0d14ef3b0efd0dd3957075c
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_8d7d27b7d44f447693df2751b4305958
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_25f7771d5e0147ac848a4fa5fc6ab0c9_da41c14c96ec4fe5957f906e41c7ba12
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_3e0e9b626d10456c9aa0548769bd093b
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_1f1ed8baff9b4bf3a4ae8e15ca9cfbca_515f90fb21af4e6fa1d8e6a8b2c8afb9
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_58893e9ed5b940e0a91ccb344e00a5a4
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_2d0fe747859c458a8c078d84e956511c_1e764d43b81941128651af74014a4d9a
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_6819b273cbfc4443a910aa46cf9b2555
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_736c9615f10049d580fa9f0d162f8f0b_ed3f70a1a31a4d399a4f45bc99524ce3
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_f825c19e6e7049aabf15d9f99743032b
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_2095296bbedf4c3eba3382da27c1b2af_840db6c24f6e4bc49154f45463fc9dec
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_6cf08facc2094fe590f95b70f7c47359
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,742:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_65783332900e4cddbefba93c09aefac6_cb7d9c3a54c6481eb34913a5cf90279a
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,743:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_c1522b8e4a5a49009e089d41266b12b0
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,743:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_e931a895cb834b51a9a361a1437ab25f_1c123beffc664f7f932d8414f2aa9841
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,743:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_5b1771c418b34833911d74374f89815a
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,743:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_e86e7762b5b64eacb735d9d4b78a1a34_5c7d761801474fb584f4fcbeebe6c58b
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,743:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_0f218cdbaec94380ac066be0896aeb5d
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,743:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_e4677503e1ff47bf80447cda006aa9f2_04a40f8cc9184a51b305adc3ebd7644a
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,743:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_b1cefbaf30924e6ea106b9653652d9f7
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,743:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_6bf50d4fec2845fa8cd52fb73b1e529f_852f3c6ac3ac4333bb622dbbd02a00be
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,743:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_a4d3e6c62f734935b292195b1562bb89
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:01,743:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_10232_827e4b3b5dd04bdb8acdeb3ad6097f9c_b8b2b140af544058a3a61ccd1a61e888
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 18:13:10,662:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:13:10,663:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:13:10,663:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:13:10,663:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:13:41,054:INFO:PyCaret ClassificationExperiment
2025-03-22 18:13:41,054:INFO:Logging name: Mentalrisk_task2
2025-03-22 18:13:41,054:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-22 18:13:41,054:INFO:version 3.3.2
2025-03-22 18:13:41,054:INFO:Initializing setup()
2025-03-22 18:13:41,054:INFO:self.USI: 01a7
2025-03-22 18:13:41,054:INFO:self._variable_keys: {'seed', 'gpu_n_jobs_param', 'y_train', 'fold_generator', 'logging_param', 'memory', 'fix_imbalance', 'y_test', 'X_train', 'n_jobs_param', '_available_plots', 'exp_id', 'exp_name_log', 'idx', 'data', 'X', 'gpu_param', 'html_param', 'fold_groups_param', 'target_param', 'log_plots_param', 'y', 'X_test', 'pipeline', 'is_multiclass', 'USI', '_ml_usecase', 'fold_shuffle_param'}
2025-03-22 18:13:41,054:INFO:Checking environment
2025-03-22 18:13:41,054:INFO:python_version: 3.10.11
2025-03-22 18:13:41,054:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-03-22 18:13:41,054:INFO:machine: AMD64
2025-03-22 18:13:41,054:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-22 18:13:41,057:INFO:Memory: svmem(total=34188517376, available=16992219136, percent=50.3, used=17196298240, free=16992219136)
2025-03-22 18:13:41,057:INFO:Physical Core: 12
2025-03-22 18:13:41,057:INFO:Logical Core: 20
2025-03-22 18:13:41,057:INFO:Checking libraries
2025-03-22 18:13:41,057:INFO:System:
2025-03-22 18:13:41,058:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-03-22 18:13:41,058:INFO:executable: C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\Scripts\python.exe
2025-03-22 18:13:41,058:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-22 18:13:41,058:INFO:PyCaret required dependencies:
2025-03-22 18:13:41,094:INFO:                 pip: 24.2
2025-03-22 18:13:41,094:INFO:          setuptools: 73.0.1
2025-03-22 18:13:41,094:INFO:             pycaret: 3.3.2
2025-03-22 18:13:41,094:INFO:             IPython: 8.34.0
2025-03-22 18:13:41,094:INFO:          ipywidgets: 8.1.5
2025-03-22 18:13:41,094:INFO:                tqdm: 4.67.1
2025-03-22 18:13:41,094:INFO:               numpy: 1.26.4
2025-03-22 18:13:41,094:INFO:              pandas: 2.1.4
2025-03-22 18:13:41,094:INFO:              jinja2: 3.1.6
2025-03-22 18:13:41,094:INFO:               scipy: 1.11.4
2025-03-22 18:13:41,094:INFO:              joblib: 1.3.2
2025-03-22 18:13:41,094:INFO:             sklearn: 1.4.2
2025-03-22 18:13:41,094:INFO:                pyod: 2.0.3
2025-03-22 18:13:41,094:INFO:            imblearn: 0.13.0
2025-03-22 18:13:41,094:INFO:   category_encoders: 2.7.0
2025-03-22 18:13:41,094:INFO:            lightgbm: 4.6.0
2025-03-22 18:13:41,095:INFO:               numba: 0.61.0
2025-03-22 18:13:41,095:INFO:            requests: 2.32.3
2025-03-22 18:13:41,095:INFO:          matplotlib: 3.7.5
2025-03-22 18:13:41,095:INFO:          scikitplot: 0.3.7
2025-03-22 18:13:41,095:INFO:         yellowbrick: 1.5
2025-03-22 18:13:41,095:INFO:              plotly: 5.24.1
2025-03-22 18:13:41,095:INFO:    plotly-resampler: Not installed
2025-03-22 18:13:41,095:INFO:             kaleido: 0.2.1
2025-03-22 18:13:41,095:INFO:           schemdraw: 0.15
2025-03-22 18:13:41,095:INFO:         statsmodels: 0.14.4
2025-03-22 18:13:41,095:INFO:              sktime: 0.26.0
2025-03-22 18:13:41,095:INFO:               tbats: 1.1.3
2025-03-22 18:13:41,095:INFO:            pmdarima: 2.0.4
2025-03-22 18:13:41,095:INFO:              psutil: 7.0.0
2025-03-22 18:13:41,095:INFO:          markupsafe: 3.0.2
2025-03-22 18:13:41,095:INFO:             pickle5: Not installed
2025-03-22 18:13:41,095:INFO:         cloudpickle: 3.1.1
2025-03-22 18:13:41,095:INFO:         deprecation: 2.1.0
2025-03-22 18:13:41,095:INFO:              xxhash: 3.5.0
2025-03-22 18:13:41,095:INFO:           wurlitzer: Not installed
2025-03-22 18:13:41,095:INFO:PyCaret optional dependencies:
2025-03-22 18:13:41,106:INFO:                shap: Not installed
2025-03-22 18:13:41,106:INFO:           interpret: Not installed
2025-03-22 18:13:41,106:INFO:                umap: Not installed
2025-03-22 18:13:41,106:INFO:     ydata_profiling: Not installed
2025-03-22 18:13:41,106:INFO:  explainerdashboard: Not installed
2025-03-22 18:13:41,106:INFO:             autoviz: Not installed
2025-03-22 18:13:41,106:INFO:           fairlearn: Not installed
2025-03-22 18:13:41,106:INFO:          deepchecks: Not installed
2025-03-22 18:13:41,107:INFO:             xgboost: Not installed
2025-03-22 18:13:41,107:INFO:            catboost: Not installed
2025-03-22 18:13:41,107:INFO:              kmodes: Not installed
2025-03-22 18:13:41,107:INFO:             mlxtend: Not installed
2025-03-22 18:13:41,107:INFO:       statsforecast: Not installed
2025-03-22 18:13:41,107:INFO:        tune_sklearn: Not installed
2025-03-22 18:13:41,107:INFO:                 ray: Not installed
2025-03-22 18:13:41,107:INFO:            hyperopt: Not installed
2025-03-22 18:13:41,107:INFO:              optuna: Not installed
2025-03-22 18:13:41,107:INFO:               skopt: Not installed
2025-03-22 18:13:41,107:INFO:              mlflow: 2.16.0
2025-03-22 18:13:41,107:INFO:              gradio: Not installed
2025-03-22 18:13:41,107:INFO:             fastapi: Not installed
2025-03-22 18:13:41,107:INFO:             uvicorn: Not installed
2025-03-22 18:13:41,107:INFO:              m2cgen: Not installed
2025-03-22 18:13:41,107:INFO:           evidently: Not installed
2025-03-22 18:13:41,107:INFO:               fugue: Not installed
2025-03-22 18:13:41,107:INFO:           streamlit: Not installed
2025-03-22 18:13:41,107:INFO:             prophet: Not installed
2025-03-22 18:13:41,107:INFO:None
2025-03-22 18:13:41,107:INFO:Set up data.
2025-03-22 18:13:41,270:INFO:Set up folding strategy.
2025-03-22 18:13:41,270:INFO:Set up train/test split.
2025-03-22 18:13:41,306:INFO:Set up index.
2025-03-22 18:13:41,307:INFO:Assigning column types.
2025-03-22 18:13:41,346:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-22 18:13:41,369:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 18:13:41,371:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:13:41,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 18:13:41,410:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:13:41,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,424:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-22 18:13:41,446:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:13:41,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,483:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:13:41,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,497:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-22 18:13:41,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:41,571:INFO:Preparing preprocessing pipeline...
2025-03-22 18:13:41,578:INFO:Set up simple imputation.
2025-03-22 18:13:41,733:INFO:Finished creating preprocessing pipeline.
2025-03-22 18:13:41,737:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 18:13:41,738:INFO:Creating final display dataframe.
2025-03-22 18:13:42,445:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type        Multiclass
3           Original data shape        (540, 769)
4        Transformed data shape        (540, 769)
5   Transformed train set shape        (432, 769)
6    Transformed test set shape        (108, 769)
7              Numeric features               768
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment      MlflowLogger
17              Experiment Name  Mentalrisk_task2
18                          USI              01a7
2025-03-22 18:13:42,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:42,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:42,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:42,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:13:42,526:INFO:Logging experiment in loggers
2025-03-22 18:13:42,723:INFO:SubProcess save_model() called ==================================
2025-03-22 18:13:42,732:INFO:Initializing save_model()
2025-03-22 18:13:42,732:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\jeiso\AppData\Local\Temp\tmpwb1blg3f\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 18:13:42,732:INFO:Adding model into prep_pipe
2025-03-22 18:13:42,732:WARNING:Only Model saved as it was a pipeline.
2025-03-22 18:13:42,737:INFO:C:\Users\jeiso\AppData\Local\Temp\tmpwb1blg3f\Transformation Pipeline.pkl saved in current working directory
2025-03-22 18:13:42,741:INFO:Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 18:13:42,741:INFO:save_model() successfully completed......................................
2025-03-22 18:13:42,855:INFO:SubProcess save_model() end ==================================
2025-03-22 18:13:42,882:INFO:setup() successfully completed in 1.48s...............
2025-03-22 18:13:45,662:INFO:Initializing compare_models()
2025-03-22 18:13:45,662:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, include=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-22 18:13:45,662:INFO:Checking exceptions
2025-03-22 18:13:45,691:INFO:Preparing display monitor
2025-03-22 18:13:45,706:INFO:Initializing Logistic Regression
2025-03-22 18:13:45,707:INFO:Total runtime is 1.6649564107259113e-05 minutes
2025-03-22 18:13:45,709:INFO:SubProcess create_model() called ==================================
2025-03-22 18:13:45,709:INFO:Initializing create_model()
2025-03-22 18:13:45,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:13:45,709:INFO:Checking exceptions
2025-03-22 18:13:45,709:INFO:Importing libraries
2025-03-22 18:13:45,709:INFO:Copying training dataset
2025-03-22 18:13:45,756:INFO:Defining folds
2025-03-22 18:13:45,756:INFO:Declaring metric variables
2025-03-22 18:13:45,759:INFO:Importing untrained model
2025-03-22 18:13:45,761:INFO:Logistic Regression Imported successfully
2025-03-22 18:13:45,765:INFO:Starting cross validation
2025-03-22 18:13:45,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:13:48,098:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:48,106:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:48,119:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:48,123:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:48,166:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:48,166:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:48,170:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:48,171:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:48,183:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:48,240:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:48,251:INFO:Calculating mean and std
2025-03-22 18:13:48,253:INFO:Creating metrics dataframe
2025-03-22 18:13:48,254:INFO:Uploading results into container
2025-03-22 18:13:48,254:INFO:Uploading model into container now
2025-03-22 18:13:48,255:INFO:_master_model_container: 1
2025-03-22 18:13:48,255:INFO:_display_container: 2
2025-03-22 18:13:48,255:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:13:48,255:INFO:create_model() successfully completed......................................
2025-03-22 18:13:48,361:INFO:SubProcess create_model() end ==================================
2025-03-22 18:13:48,361:INFO:Creating metrics dataframe
2025-03-22 18:13:48,365:INFO:Initializing K Neighbors Classifier
2025-03-22 18:13:48,365:INFO:Total runtime is 0.04430662790934245 minutes
2025-03-22 18:13:48,367:INFO:SubProcess create_model() called ==================================
2025-03-22 18:13:48,367:INFO:Initializing create_model()
2025-03-22 18:13:48,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:13:48,367:INFO:Checking exceptions
2025-03-22 18:13:48,368:INFO:Importing libraries
2025-03-22 18:13:48,368:INFO:Copying training dataset
2025-03-22 18:13:48,417:INFO:Defining folds
2025-03-22 18:13:48,417:INFO:Declaring metric variables
2025-03-22 18:13:48,420:INFO:Importing untrained model
2025-03-22 18:13:48,422:INFO:K Neighbors Classifier Imported successfully
2025-03-22 18:13:48,426:INFO:Starting cross validation
2025-03-22 18:13:48,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:13:50,367:INFO:Calculating mean and std
2025-03-22 18:13:50,368:INFO:Creating metrics dataframe
2025-03-22 18:13:50,370:INFO:Uploading results into container
2025-03-22 18:13:50,370:INFO:Uploading model into container now
2025-03-22 18:13:50,371:INFO:_master_model_container: 2
2025-03-22 18:13:50,371:INFO:_display_container: 2
2025-03-22 18:13:50,371:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-22 18:13:50,371:INFO:create_model() successfully completed......................................
2025-03-22 18:13:50,480:INFO:SubProcess create_model() end ==================================
2025-03-22 18:13:50,480:INFO:Creating metrics dataframe
2025-03-22 18:13:50,485:INFO:Initializing Naive Bayes
2025-03-22 18:13:50,485:INFO:Total runtime is 0.07964593569437663 minutes
2025-03-22 18:13:50,487:INFO:SubProcess create_model() called ==================================
2025-03-22 18:13:50,487:INFO:Initializing create_model()
2025-03-22 18:13:50,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:13:50,487:INFO:Checking exceptions
2025-03-22 18:13:50,487:INFO:Importing libraries
2025-03-22 18:13:50,487:INFO:Copying training dataset
2025-03-22 18:13:50,534:INFO:Defining folds
2025-03-22 18:13:50,534:INFO:Declaring metric variables
2025-03-22 18:13:50,537:INFO:Importing untrained model
2025-03-22 18:13:50,539:INFO:Naive Bayes Imported successfully
2025-03-22 18:13:50,543:INFO:Starting cross validation
2025-03-22 18:13:50,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:13:50,733:INFO:Calculating mean and std
2025-03-22 18:13:50,734:INFO:Creating metrics dataframe
2025-03-22 18:13:50,735:INFO:Uploading results into container
2025-03-22 18:13:50,736:INFO:Uploading model into container now
2025-03-22 18:13:50,736:INFO:_master_model_container: 3
2025-03-22 18:13:50,736:INFO:_display_container: 2
2025-03-22 18:13:50,736:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-22 18:13:50,736:INFO:create_model() successfully completed......................................
2025-03-22 18:13:50,845:INFO:SubProcess create_model() end ==================================
2025-03-22 18:13:50,845:INFO:Creating metrics dataframe
2025-03-22 18:13:50,849:INFO:Initializing Decision Tree Classifier
2025-03-22 18:13:50,849:INFO:Total runtime is 0.08571091890335084 minutes
2025-03-22 18:13:50,851:INFO:SubProcess create_model() called ==================================
2025-03-22 18:13:50,851:INFO:Initializing create_model()
2025-03-22 18:13:50,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:13:50,851:INFO:Checking exceptions
2025-03-22 18:13:50,851:INFO:Importing libraries
2025-03-22 18:13:50,851:INFO:Copying training dataset
2025-03-22 18:13:50,901:INFO:Defining folds
2025-03-22 18:13:50,901:INFO:Declaring metric variables
2025-03-22 18:13:50,903:INFO:Importing untrained model
2025-03-22 18:13:50,906:INFO:Decision Tree Classifier Imported successfully
2025-03-22 18:13:50,910:INFO:Starting cross validation
2025-03-22 18:13:50,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:13:51,193:INFO:Calculating mean and std
2025-03-22 18:13:51,194:INFO:Creating metrics dataframe
2025-03-22 18:13:51,195:INFO:Uploading results into container
2025-03-22 18:13:51,195:INFO:Uploading model into container now
2025-03-22 18:13:51,196:INFO:_master_model_container: 4
2025-03-22 18:13:51,196:INFO:_display_container: 2
2025-03-22 18:13:51,196:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-03-22 18:13:51,196:INFO:create_model() successfully completed......................................
2025-03-22 18:13:51,304:INFO:SubProcess create_model() end ==================================
2025-03-22 18:13:51,304:INFO:Creating metrics dataframe
2025-03-22 18:13:51,308:INFO:Initializing SVM - Linear Kernel
2025-03-22 18:13:51,308:INFO:Total runtime is 0.09337066809336345 minutes
2025-03-22 18:13:51,310:INFO:SubProcess create_model() called ==================================
2025-03-22 18:13:51,310:INFO:Initializing create_model()
2025-03-22 18:13:51,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:13:51,311:INFO:Checking exceptions
2025-03-22 18:13:51,311:INFO:Importing libraries
2025-03-22 18:13:51,311:INFO:Copying training dataset
2025-03-22 18:13:51,360:INFO:Defining folds
2025-03-22 18:13:51,360:INFO:Declaring metric variables
2025-03-22 18:13:51,363:INFO:Importing untrained model
2025-03-22 18:13:51,366:INFO:SVM - Linear Kernel Imported successfully
2025-03-22 18:13:51,370:INFO:Starting cross validation
2025-03-22 18:13:51,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:13:51,485:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,493:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,509:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,512:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,523:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,540:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,540:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,540:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,554:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,570:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,589:INFO:Calculating mean and std
2025-03-22 18:13:51,590:INFO:Creating metrics dataframe
2025-03-22 18:13:51,592:INFO:Uploading results into container
2025-03-22 18:13:51,592:INFO:Uploading model into container now
2025-03-22 18:13:51,593:INFO:_master_model_container: 5
2025-03-22 18:13:51,593:INFO:_display_container: 2
2025-03-22 18:13:51,593:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-22 18:13:51,593:INFO:create_model() successfully completed......................................
2025-03-22 18:13:51,702:INFO:SubProcess create_model() end ==================================
2025-03-22 18:13:51,702:INFO:Creating metrics dataframe
2025-03-22 18:13:51,707:INFO:Initializing Ridge Classifier
2025-03-22 18:13:51,707:INFO:Total runtime is 0.10001413822174073 minutes
2025-03-22 18:13:51,709:INFO:SubProcess create_model() called ==================================
2025-03-22 18:13:51,709:INFO:Initializing create_model()
2025-03-22 18:13:51,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:13:51,709:INFO:Checking exceptions
2025-03-22 18:13:51,709:INFO:Importing libraries
2025-03-22 18:13:51,709:INFO:Copying training dataset
2025-03-22 18:13:51,758:INFO:Defining folds
2025-03-22 18:13:51,758:INFO:Declaring metric variables
2025-03-22 18:13:51,760:INFO:Importing untrained model
2025-03-22 18:13:51,763:INFO:Ridge Classifier Imported successfully
2025-03-22 18:13:51,767:INFO:Starting cross validation
2025-03-22 18:13:51,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:13:51,858:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,866:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,885:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,886:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,899:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,907:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,908:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,927:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,927:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,936:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:51,952:INFO:Calculating mean and std
2025-03-22 18:13:51,953:INFO:Creating metrics dataframe
2025-03-22 18:13:51,954:INFO:Uploading results into container
2025-03-22 18:13:51,955:INFO:Uploading model into container now
2025-03-22 18:13:51,955:INFO:_master_model_container: 6
2025-03-22 18:13:51,955:INFO:_display_container: 2
2025-03-22 18:13:51,955:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-03-22 18:13:51,955:INFO:create_model() successfully completed......................................
2025-03-22 18:13:52,063:INFO:SubProcess create_model() end ==================================
2025-03-22 18:13:52,063:INFO:Creating metrics dataframe
2025-03-22 18:13:52,068:INFO:Initializing Random Forest Classifier
2025-03-22 18:13:52,068:INFO:Total runtime is 0.10603135029474894 minutes
2025-03-22 18:13:52,070:INFO:SubProcess create_model() called ==================================
2025-03-22 18:13:52,070:INFO:Initializing create_model()
2025-03-22 18:13:52,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:13:52,070:INFO:Checking exceptions
2025-03-22 18:13:52,070:INFO:Importing libraries
2025-03-22 18:13:52,070:INFO:Copying training dataset
2025-03-22 18:13:52,120:INFO:Defining folds
2025-03-22 18:13:52,121:INFO:Declaring metric variables
2025-03-22 18:13:52,123:INFO:Importing untrained model
2025-03-22 18:13:52,125:INFO:Random Forest Classifier Imported successfully
2025-03-22 18:13:52,130:INFO:Starting cross validation
2025-03-22 18:13:52,131:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:13:52,698:INFO:Calculating mean and std
2025-03-22 18:13:52,699:INFO:Creating metrics dataframe
2025-03-22 18:13:52,700:INFO:Uploading results into container
2025-03-22 18:13:52,701:INFO:Uploading model into container now
2025-03-22 18:13:52,701:INFO:_master_model_container: 7
2025-03-22 18:13:52,701:INFO:_display_container: 2
2025-03-22 18:13:52,701:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 18:13:52,701:INFO:create_model() successfully completed......................................
2025-03-22 18:13:52,807:INFO:SubProcess create_model() end ==================================
2025-03-22 18:13:52,808:INFO:Creating metrics dataframe
2025-03-22 18:13:52,812:INFO:Initializing Quadratic Discriminant Analysis
2025-03-22 18:13:52,812:INFO:Total runtime is 0.1184282660484314 minutes
2025-03-22 18:13:52,814:INFO:SubProcess create_model() called ==================================
2025-03-22 18:13:52,815:INFO:Initializing create_model()
2025-03-22 18:13:52,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:13:52,815:INFO:Checking exceptions
2025-03-22 18:13:52,815:INFO:Importing libraries
2025-03-22 18:13:52,815:INFO:Copying training dataset
2025-03-22 18:13:52,861:INFO:Defining folds
2025-03-22 18:13:52,862:INFO:Declaring metric variables
2025-03-22 18:13:52,864:INFO:Importing untrained model
2025-03-22 18:13:52,866:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-22 18:13:52,870:INFO:Starting cross validation
2025-03-22 18:13:52,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:13:53,000:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:13:53,001:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:13:53,014:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:13:53,025:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:13:53,028:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:53,030:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:13:53,031:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:53,044:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:53,047:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:53,048:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:53,049:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:13:53,052:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:53,053:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:53,055:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:53,060:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:53,062:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:53,064:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:13:53,068:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:13:53,074:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:13:53,075:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:53,077:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:53,091:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:53,094:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:53,094:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:53,097:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:53,099:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:13:53,100:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:53,102:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:53,124:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:53,127:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:53,141:INFO:Calculating mean and std
2025-03-22 18:13:53,143:INFO:Creating metrics dataframe
2025-03-22 18:13:53,145:INFO:Uploading results into container
2025-03-22 18:13:53,145:INFO:Uploading model into container now
2025-03-22 18:13:53,145:INFO:_master_model_container: 8
2025-03-22 18:13:53,146:INFO:_display_container: 2
2025-03-22 18:13:53,146:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-22 18:13:53,146:INFO:create_model() successfully completed......................................
2025-03-22 18:13:53,259:INFO:SubProcess create_model() end ==================================
2025-03-22 18:13:53,259:INFO:Creating metrics dataframe
2025-03-22 18:13:53,264:INFO:Initializing Ada Boost Classifier
2025-03-22 18:13:53,264:INFO:Total runtime is 0.12595858971277873 minutes
2025-03-22 18:13:53,266:INFO:SubProcess create_model() called ==================================
2025-03-22 18:13:53,266:INFO:Initializing create_model()
2025-03-22 18:13:53,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:13:53,266:INFO:Checking exceptions
2025-03-22 18:13:53,266:INFO:Importing libraries
2025-03-22 18:13:53,266:INFO:Copying training dataset
2025-03-22 18:13:53,319:INFO:Defining folds
2025-03-22 18:13:53,319:INFO:Declaring metric variables
2025-03-22 18:13:53,322:INFO:Importing untrained model
2025-03-22 18:13:53,325:INFO:Ada Boost Classifier Imported successfully
2025-03-22 18:13:53,328:INFO:Starting cross validation
2025-03-22 18:13:53,329:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:13:53,396:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:13:53,403:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:13:53,414:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:13:53,425:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:13:53,432:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:13:53,446:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:13:53,466:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:13:53,476:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:13:53,489:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:13:53,504:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:13:54,741:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:54,745:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:54,753:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:54,761:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:54,763:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:54,766:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:54,775:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:54,776:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:54,777:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:54,778:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:54,780:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:54,791:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:54,794:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:54,797:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:54,829:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:13:54,832:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:13:54,840:INFO:Calculating mean and std
2025-03-22 18:13:54,841:INFO:Creating metrics dataframe
2025-03-22 18:13:54,842:INFO:Uploading results into container
2025-03-22 18:13:54,842:INFO:Uploading model into container now
2025-03-22 18:13:54,843:INFO:_master_model_container: 9
2025-03-22 18:13:54,843:INFO:_display_container: 2
2025-03-22 18:13:54,843:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-03-22 18:13:54,843:INFO:create_model() successfully completed......................................
2025-03-22 18:13:54,949:INFO:SubProcess create_model() end ==================================
2025-03-22 18:13:54,949:INFO:Creating metrics dataframe
2025-03-22 18:13:54,956:INFO:Initializing Gradient Boosting Classifier
2025-03-22 18:13:54,956:INFO:Total runtime is 0.1541558067003886 minutes
2025-03-22 18:13:54,958:INFO:SubProcess create_model() called ==================================
2025-03-22 18:13:54,958:INFO:Initializing create_model()
2025-03-22 18:13:54,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:13:54,958:INFO:Checking exceptions
2025-03-22 18:13:54,958:INFO:Importing libraries
2025-03-22 18:13:54,958:INFO:Copying training dataset
2025-03-22 18:13:55,009:INFO:Defining folds
2025-03-22 18:13:55,009:INFO:Declaring metric variables
2025-03-22 18:13:55,011:INFO:Importing untrained model
2025-03-22 18:13:55,014:INFO:Gradient Boosting Classifier Imported successfully
2025-03-22 18:13:55,018:INFO:Starting cross validation
2025-03-22 18:13:55,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:14:21,029:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,129:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,202:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,203:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,287:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,313:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,384:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,434:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,471:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,553:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,567:INFO:Calculating mean and std
2025-03-22 18:14:21,568:INFO:Creating metrics dataframe
2025-03-22 18:14:21,569:INFO:Uploading results into container
2025-03-22 18:14:21,569:INFO:Uploading model into container now
2025-03-22 18:14:21,570:INFO:_master_model_container: 10
2025-03-22 18:14:21,570:INFO:_display_container: 2
2025-03-22 18:14:21,570:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-22 18:14:21,570:INFO:create_model() successfully completed......................................
2025-03-22 18:14:21,677:INFO:SubProcess create_model() end ==================================
2025-03-22 18:14:21,678:INFO:Creating metrics dataframe
2025-03-22 18:14:21,683:INFO:Initializing Linear Discriminant Analysis
2025-03-22 18:14:21,683:INFO:Total runtime is 0.5996179699897766 minutes
2025-03-22 18:14:21,686:INFO:SubProcess create_model() called ==================================
2025-03-22 18:14:21,687:INFO:Initializing create_model()
2025-03-22 18:14:21,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:14:21,687:INFO:Checking exceptions
2025-03-22 18:14:21,687:INFO:Importing libraries
2025-03-22 18:14:21,687:INFO:Copying training dataset
2025-03-22 18:14:21,743:INFO:Defining folds
2025-03-22 18:14:21,743:INFO:Declaring metric variables
2025-03-22 18:14:21,746:INFO:Importing untrained model
2025-03-22 18:14:21,748:INFO:Linear Discriminant Analysis Imported successfully
2025-03-22 18:14:21,752:INFO:Starting cross validation
2025-03-22 18:14:21,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:14:21,879:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,881:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,892:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,896:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,909:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,930:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,931:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,932:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,945:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,955:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:14:21,965:INFO:Calculating mean and std
2025-03-22 18:14:21,966:INFO:Creating metrics dataframe
2025-03-22 18:14:21,967:INFO:Uploading results into container
2025-03-22 18:14:21,967:INFO:Uploading model into container now
2025-03-22 18:14:21,968:INFO:_master_model_container: 11
2025-03-22 18:14:21,968:INFO:_display_container: 2
2025-03-22 18:14:21,968:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-22 18:14:21,968:INFO:create_model() successfully completed......................................
2025-03-22 18:14:22,075:INFO:SubProcess create_model() end ==================================
2025-03-22 18:14:22,076:INFO:Creating metrics dataframe
2025-03-22 18:14:22,082:INFO:Initializing Extra Trees Classifier
2025-03-22 18:14:22,082:INFO:Total runtime is 0.6062622388203939 minutes
2025-03-22 18:14:22,084:INFO:SubProcess create_model() called ==================================
2025-03-22 18:14:22,084:INFO:Initializing create_model()
2025-03-22 18:14:22,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:14:22,084:INFO:Checking exceptions
2025-03-22 18:14:22,084:INFO:Importing libraries
2025-03-22 18:14:22,084:INFO:Copying training dataset
2025-03-22 18:14:22,136:INFO:Defining folds
2025-03-22 18:14:22,136:INFO:Declaring metric variables
2025-03-22 18:14:22,138:INFO:Importing untrained model
2025-03-22 18:14:22,141:INFO:Extra Trees Classifier Imported successfully
2025-03-22 18:14:22,144:INFO:Starting cross validation
2025-03-22 18:14:22,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:14:22,501:INFO:Calculating mean and std
2025-03-22 18:14:22,502:INFO:Creating metrics dataframe
2025-03-22 18:14:22,503:INFO:Uploading results into container
2025-03-22 18:14:22,503:INFO:Uploading model into container now
2025-03-22 18:14:22,504:INFO:_master_model_container: 12
2025-03-22 18:14:22,504:INFO:_display_container: 2
2025-03-22 18:14:22,504:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-03-22 18:14:22,504:INFO:create_model() successfully completed......................................
2025-03-22 18:14:22,610:INFO:SubProcess create_model() end ==================================
2025-03-22 18:14:22,610:INFO:Creating metrics dataframe
2025-03-22 18:14:22,616:INFO:Initializing Light Gradient Boosting Machine
2025-03-22 18:14:22,616:INFO:Total runtime is 0.6151690006256103 minutes
2025-03-22 18:14:22,618:INFO:SubProcess create_model() called ==================================
2025-03-22 18:14:22,618:INFO:Initializing create_model()
2025-03-22 18:14:22,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:14:22,618:INFO:Checking exceptions
2025-03-22 18:14:22,618:INFO:Importing libraries
2025-03-22 18:14:22,618:INFO:Copying training dataset
2025-03-22 18:14:22,670:INFO:Defining folds
2025-03-22 18:14:22,670:INFO:Declaring metric variables
2025-03-22 18:14:22,672:INFO:Importing untrained model
2025-03-22 18:14:22,675:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-22 18:14:22,679:INFO:Starting cross validation
2025-03-22 18:14:22,680:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:14:28,960:INFO:Calculating mean and std
2025-03-22 18:14:28,962:INFO:Creating metrics dataframe
2025-03-22 18:14:28,964:INFO:Uploading results into container
2025-03-22 18:14:28,964:INFO:Uploading model into container now
2025-03-22 18:14:28,965:INFO:_master_model_container: 13
2025-03-22 18:14:28,965:INFO:_display_container: 2
2025-03-22 18:14:28,966:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-22 18:14:28,966:INFO:create_model() successfully completed......................................
2025-03-22 18:14:29,099:INFO:SubProcess create_model() end ==================================
2025-03-22 18:14:29,099:INFO:Creating metrics dataframe
2025-03-22 18:14:29,104:INFO:Initializing Dummy Classifier
2025-03-22 18:14:29,104:INFO:Total runtime is 0.7232947429021199 minutes
2025-03-22 18:14:29,106:INFO:SubProcess create_model() called ==================================
2025-03-22 18:14:29,107:INFO:Initializing create_model()
2025-03-22 18:14:29,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BD06A40D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:14:29,107:INFO:Checking exceptions
2025-03-22 18:14:29,107:INFO:Importing libraries
2025-03-22 18:14:29,107:INFO:Copying training dataset
2025-03-22 18:14:29,158:INFO:Defining folds
2025-03-22 18:14:29,158:INFO:Declaring metric variables
2025-03-22 18:14:29,161:INFO:Importing untrained model
2025-03-22 18:14:29,163:INFO:Dummy Classifier Imported successfully
2025-03-22 18:14:29,166:INFO:Starting cross validation
2025-03-22 18:14:29,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:14:29,302:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:14:29,304:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:14:29,328:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:14:29,339:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:14:29,340:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:14:29,348:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:14:29,370:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:14:29,371:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:14:29,381:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:14:29,382:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:14:29,389:INFO:Calculating mean and std
2025-03-22 18:14:29,390:INFO:Creating metrics dataframe
2025-03-22 18:14:29,391:INFO:Uploading results into container
2025-03-22 18:14:29,392:INFO:Uploading model into container now
2025-03-22 18:14:29,392:INFO:_master_model_container: 14
2025-03-22 18:14:29,392:INFO:_display_container: 2
2025-03-22 18:14:29,392:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-03-22 18:14:29,392:INFO:create_model() successfully completed......................................
2025-03-22 18:14:29,496:INFO:SubProcess create_model() end ==================================
2025-03-22 18:14:29,496:INFO:Creating metrics dataframe
2025-03-22 18:14:29,504:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-22 18:14:29,510:INFO:Initializing create_model()
2025-03-22 18:14:29,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:14:29,511:INFO:Checking exceptions
2025-03-22 18:14:29,512:INFO:Importing libraries
2025-03-22 18:14:29,512:INFO:Copying training dataset
2025-03-22 18:14:29,561:INFO:Defining folds
2025-03-22 18:14:29,561:INFO:Declaring metric variables
2025-03-22 18:14:29,561:INFO:Importing untrained model
2025-03-22 18:14:29,561:INFO:Declaring custom model
2025-03-22 18:14:29,561:INFO:Logistic Regression Imported successfully
2025-03-22 18:14:29,562:INFO:Cross validation set to False
2025-03-22 18:14:29,562:INFO:Fitting Model
2025-03-22 18:14:29,698:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:14:29,698:INFO:create_model() successfully completed......................................
2025-03-22 18:14:29,812:INFO:Creating Dashboard logs
2025-03-22 18:14:29,814:INFO:Model: Logistic Regression
2025-03-22 18:14:29,858:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 18:14:29,948:INFO:Initializing predict_model()
2025-03-22 18:14:29,948:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021BD0A69F30>)
2025-03-22 18:14:29,948:INFO:Checking exceptions
2025-03-22 18:14:29,948:INFO:Preloading libraries
2025-03-22 18:14:31,378:INFO:Creating Dashboard logs
2025-03-22 18:14:31,380:INFO:Model: Ridge Classifier
2025-03-22 18:14:31,413:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2025-03-22 18:14:31,644:INFO:Creating Dashboard logs
2025-03-22 18:14:31,647:INFO:Model: SVM - Linear Kernel
2025-03-22 18:14:31,683:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 18:14:31,917:INFO:Creating Dashboard logs
2025-03-22 18:14:31,920:INFO:Model: Random Forest Classifier
2025-03-22 18:14:31,956:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 18:14:32,187:INFO:Creating Dashboard logs
2025-03-22 18:14:32,190:INFO:Model: Light Gradient Boosting Machine
2025-03-22 18:14:32,224:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-22 18:14:32,458:INFO:Creating Dashboard logs
2025-03-22 18:14:32,461:INFO:Model: Extra Trees Classifier
2025-03-22 18:14:32,495:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 18:14:32,726:INFO:Creating Dashboard logs
2025-03-22 18:14:32,728:INFO:Model: Gradient Boosting Classifier
2025-03-22 18:14:32,762:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 18:14:33,004:INFO:Creating Dashboard logs
2025-03-22 18:14:33,006:INFO:Model: Naive Bayes
2025-03-22 18:14:33,038:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-03-22 18:14:33,267:INFO:Creating Dashboard logs
2025-03-22 18:14:33,269:INFO:Model: K Neighbors Classifier
2025-03-22 18:14:33,305:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-22 18:14:33,527:INFO:Creating Dashboard logs
2025-03-22 18:14:33,530:INFO:Model: Decision Tree Classifier
2025-03-22 18:14:33,563:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 123, 'splitter': 'best'}
2025-03-22 18:14:33,788:INFO:Creating Dashboard logs
2025-03-22 18:14:33,790:INFO:Model: Linear Discriminant Analysis
2025-03-22 18:14:33,826:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-03-22 18:14:34,053:INFO:Creating Dashboard logs
2025-03-22 18:14:34,055:INFO:Model: Ada Boost Classifier
2025-03-22 18:14:34,087:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 123}
2025-03-22 18:14:34,309:INFO:Creating Dashboard logs
2025-03-22 18:14:34,311:INFO:Model: Quadratic Discriminant Analysis
2025-03-22 18:14:34,343:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-03-22 18:14:34,556:INFO:Creating Dashboard logs
2025-03-22 18:14:34,559:INFO:Model: Dummy Classifier
2025-03-22 18:14:34,592:INFO:Logged params: {'constant': None, 'random_state': 123, 'strategy': 'prior'}
2025-03-22 18:14:34,824:INFO:_master_model_container: 14
2025-03-22 18:14:34,824:INFO:_display_container: 2
2025-03-22 18:14:34,824:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:14:34,824:INFO:compare_models() successfully completed......................................
2025-03-22 18:17:08,856:INFO:Initializing create_model()
2025-03-22 18:17:08,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:17:08,856:INFO:Checking exceptions
2025-03-22 18:17:08,869:INFO:Importing libraries
2025-03-22 18:17:08,869:INFO:Copying training dataset
2025-03-22 18:17:08,922:INFO:Defining folds
2025-03-22 18:17:08,922:INFO:Declaring metric variables
2025-03-22 18:17:08,924:INFO:Importing untrained model
2025-03-22 18:17:08,927:INFO:Logistic Regression Imported successfully
2025-03-22 18:17:08,933:INFO:Starting cross validation
2025-03-22 18:17:08,935:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:17:09,121:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:17:09,142:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:17:09,154:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:17:09,182:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:17:09,195:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:17:09,202:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:17:09,214:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:17:09,217:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:17:09,222:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:17:09,238:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 18:17:09,251:INFO:Calculating mean and std
2025-03-22 18:17:09,251:INFO:Creating metrics dataframe
2025-03-22 18:17:09,255:INFO:Finalizing model
2025-03-22 18:17:09,416:INFO:Creating Dashboard logs
2025-03-22 18:17:09,419:INFO:Model: Logistic Regression
2025-03-22 18:17:09,465:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 18:17:09,559:INFO:Initializing predict_model()
2025-03-22 18:17:09,559:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021BD0C4CF70>)
2025-03-22 18:17:09,559:INFO:Checking exceptions
2025-03-22 18:17:09,559:INFO:Preloading libraries
2025-03-22 18:17:10,194:INFO:Uploading results into container
2025-03-22 18:17:10,195:INFO:Uploading model into container now
2025-03-22 18:17:10,202:INFO:_master_model_container: 15
2025-03-22 18:17:10,202:INFO:_display_container: 3
2025-03-22 18:17:10,202:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:17:10,202:INFO:create_model() successfully completed......................................
2025-03-22 18:17:16,386:INFO:Initializing plot_model()
2025-03-22 18:17:16,386:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, system=True)
2025-03-22 18:17:16,387:INFO:Checking exceptions
2025-03-22 18:17:16,408:INFO:Preloading libraries
2025-03-22 18:17:16,409:INFO:Copying training dataset
2025-03-22 18:17:16,409:INFO:Plot type: confusion_matrix
2025-03-22 18:17:16,888:INFO:Fitting Model
2025-03-22 18:17:16,889:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 18:17:16,889:INFO:Scoring test/hold-out set
2025-03-22 18:17:17,012:INFO:Visual Rendered Successfully
2025-03-22 18:17:17,126:INFO:plot_model() successfully completed......................................
2025-03-22 18:17:19,955:INFO:Initializing evaluate_model()
2025-03-22 18:17:19,955:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-22 18:17:19,984:INFO:Initializing plot_model()
2025-03-22 18:17:19,984:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BC3993AF0>, system=True)
2025-03-22 18:17:19,984:INFO:Checking exceptions
2025-03-22 18:17:20,001:INFO:Preloading libraries
2025-03-22 18:17:20,001:INFO:Copying training dataset
2025-03-22 18:17:20,001:INFO:Plot type: pipeline
2025-03-22 18:17:20,093:INFO:Visual Rendered Successfully
2025-03-22 18:17:20,200:INFO:plot_model() successfully completed......................................
2025-03-22 18:17:22,418:INFO:Initializing save_model()
2025-03-22 18:17:22,418:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=rf_task2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 18:17:22,418:INFO:Adding model into prep_pipe
2025-03-22 18:17:22,425:INFO:rf_task2.pkl saved in current working directory
2025-03-22 18:17:22,430:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'feature_17', 'feature_18',
                                             'feature_19', 'feat...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-03-22 18:17:22,430:INFO:save_model() successfully completed......................................
2025-03-22 18:17:59,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:17:59,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:17:59,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:17:59,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 18:18:32,929:INFO:PyCaret ClassificationExperiment
2025-03-22 18:18:32,929:INFO:Logging name: Mentalrisk_task1
2025-03-22 18:18:32,929:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-22 18:18:32,929:INFO:version 3.3.2
2025-03-22 18:18:32,929:INFO:Initializing setup()
2025-03-22 18:18:32,929:INFO:self.USI: 6f52
2025-03-22 18:18:32,929:INFO:self._variable_keys: {'_ml_usecase', 'X_train', 'fix_imbalance', 'fold_shuffle_param', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'seed', '_available_plots', 'exp_name_log', 'logging_param', 'log_plots_param', 'data', 'fold_generator', 'X_test', 'html_param', 'memory', 'fold_groups_param', 'exp_id', 'pipeline', 'is_multiclass', 'target_param', 'y_test', 'idx', 'X', 'y', 'y_train', 'n_jobs_param'}
2025-03-22 18:18:32,929:INFO:Checking environment
2025-03-22 18:18:32,929:INFO:python_version: 3.10.11
2025-03-22 18:18:32,929:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-03-22 18:18:32,929:INFO:machine: AMD64
2025-03-22 18:18:32,929:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-22 18:18:32,933:INFO:Memory: svmem(total=34188517376, available=14304681984, percent=58.2, used=19883835392, free=14304681984)
2025-03-22 18:18:32,933:INFO:Physical Core: 12
2025-03-22 18:18:32,933:INFO:Logical Core: 20
2025-03-22 18:18:32,933:INFO:Checking libraries
2025-03-22 18:18:32,933:INFO:System:
2025-03-22 18:18:32,933:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-03-22 18:18:32,933:INFO:executable: C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\Scripts\python.exe
2025-03-22 18:18:32,933:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-22 18:18:32,933:INFO:PyCaret required dependencies:
2025-03-22 18:18:32,972:INFO:                 pip: 24.2
2025-03-22 18:18:32,972:INFO:          setuptools: 73.0.1
2025-03-22 18:18:32,972:INFO:             pycaret: 3.3.2
2025-03-22 18:18:32,972:INFO:             IPython: 8.34.0
2025-03-22 18:18:32,972:INFO:          ipywidgets: 8.1.5
2025-03-22 18:18:32,972:INFO:                tqdm: 4.67.1
2025-03-22 18:18:32,972:INFO:               numpy: 1.26.4
2025-03-22 18:18:32,972:INFO:              pandas: 2.1.4
2025-03-22 18:18:32,972:INFO:              jinja2: 3.1.6
2025-03-22 18:18:32,972:INFO:               scipy: 1.11.4
2025-03-22 18:18:32,972:INFO:              joblib: 1.3.2
2025-03-22 18:18:32,972:INFO:             sklearn: 1.4.2
2025-03-22 18:18:32,972:INFO:                pyod: 2.0.3
2025-03-22 18:18:32,972:INFO:            imblearn: 0.13.0
2025-03-22 18:18:32,972:INFO:   category_encoders: 2.7.0
2025-03-22 18:18:32,972:INFO:            lightgbm: 4.6.0
2025-03-22 18:18:32,972:INFO:               numba: 0.61.0
2025-03-22 18:18:32,972:INFO:            requests: 2.32.3
2025-03-22 18:18:32,972:INFO:          matplotlib: 3.7.5
2025-03-22 18:18:32,972:INFO:          scikitplot: 0.3.7
2025-03-22 18:18:32,972:INFO:         yellowbrick: 1.5
2025-03-22 18:18:32,972:INFO:              plotly: 5.24.1
2025-03-22 18:18:32,972:INFO:    plotly-resampler: Not installed
2025-03-22 18:18:32,972:INFO:             kaleido: 0.2.1
2025-03-22 18:18:32,972:INFO:           schemdraw: 0.15
2025-03-22 18:18:32,972:INFO:         statsmodels: 0.14.4
2025-03-22 18:18:32,972:INFO:              sktime: 0.26.0
2025-03-22 18:18:32,972:INFO:               tbats: 1.1.3
2025-03-22 18:18:32,972:INFO:            pmdarima: 2.0.4
2025-03-22 18:18:32,972:INFO:              psutil: 7.0.0
2025-03-22 18:18:32,972:INFO:          markupsafe: 3.0.2
2025-03-22 18:18:32,972:INFO:             pickle5: Not installed
2025-03-22 18:18:32,972:INFO:         cloudpickle: 3.1.1
2025-03-22 18:18:32,972:INFO:         deprecation: 2.1.0
2025-03-22 18:18:32,972:INFO:              xxhash: 3.5.0
2025-03-22 18:18:32,972:INFO:           wurlitzer: Not installed
2025-03-22 18:18:32,972:INFO:PyCaret optional dependencies:
2025-03-22 18:18:32,984:INFO:                shap: Not installed
2025-03-22 18:18:32,984:INFO:           interpret: Not installed
2025-03-22 18:18:32,984:INFO:                umap: Not installed
2025-03-22 18:18:32,984:INFO:     ydata_profiling: Not installed
2025-03-22 18:18:32,984:INFO:  explainerdashboard: Not installed
2025-03-22 18:18:32,984:INFO:             autoviz: Not installed
2025-03-22 18:18:32,984:INFO:           fairlearn: Not installed
2025-03-22 18:18:32,984:INFO:          deepchecks: Not installed
2025-03-22 18:18:32,984:INFO:             xgboost: Not installed
2025-03-22 18:18:32,985:INFO:            catboost: Not installed
2025-03-22 18:18:32,985:INFO:              kmodes: Not installed
2025-03-22 18:18:32,985:INFO:             mlxtend: Not installed
2025-03-22 18:18:32,985:INFO:       statsforecast: Not installed
2025-03-22 18:18:32,985:INFO:        tune_sklearn: Not installed
2025-03-22 18:18:32,985:INFO:                 ray: Not installed
2025-03-22 18:18:32,985:INFO:            hyperopt: Not installed
2025-03-22 18:18:32,985:INFO:              optuna: Not installed
2025-03-22 18:18:32,985:INFO:               skopt: Not installed
2025-03-22 18:18:32,985:INFO:              mlflow: 2.16.0
2025-03-22 18:18:32,985:INFO:              gradio: Not installed
2025-03-22 18:18:32,985:INFO:             fastapi: Not installed
2025-03-22 18:18:32,985:INFO:             uvicorn: Not installed
2025-03-22 18:18:32,985:INFO:              m2cgen: Not installed
2025-03-22 18:18:32,985:INFO:           evidently: Not installed
2025-03-22 18:18:32,985:INFO:               fugue: Not installed
2025-03-22 18:18:32,985:INFO:           streamlit: Not installed
2025-03-22 18:18:32,985:INFO:             prophet: Not installed
2025-03-22 18:18:32,985:INFO:None
2025-03-22 18:18:32,985:INFO:Set up data.
2025-03-22 18:18:33,148:INFO:Set up folding strategy.
2025-03-22 18:18:33,148:INFO:Set up train/test split.
2025-03-22 18:18:33,185:INFO:Set up index.
2025-03-22 18:18:33,186:INFO:Assigning column types.
2025-03-22 18:18:33,224:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-22 18:18:33,246:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 18:18:33,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:18:33,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,292:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 18:18:33,292:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:18:33,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,309:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,309:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-22 18:18:33,333:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:18:33,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,371:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 18:18:33,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,386:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-22 18:18:33,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:33,462:INFO:Preparing preprocessing pipeline...
2025-03-22 18:18:33,469:INFO:Set up simple imputation.
2025-03-22 18:18:33,632:INFO:Finished creating preprocessing pipeline.
2025-03-22 18:18:33,637:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 18:18:33,637:INFO:Creating final display dataframe.
2025-03-22 18:18:34,221:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             level
2                   Target type            Binary
3           Original data shape        (462, 769)
4        Transformed data shape        (462, 769)
5   Transformed train set shape        (369, 769)
6    Transformed test set shape         (93, 769)
7              Numeric features               768
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment      MlflowLogger
17              Experiment Name  Mentalrisk_task1
18                          USI              6f52
2025-03-22 18:18:34,262:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:34,262:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:34,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:34,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 18:18:34,304:INFO:Logging experiment in loggers
2025-03-22 18:18:34,487:INFO:SubProcess save_model() called ==================================
2025-03-22 18:18:34,494:INFO:Initializing save_model()
2025-03-22 18:18:34,494:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\jeiso\AppData\Local\Temp\tmptoqljq1x\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 18:18:34,494:INFO:Adding model into prep_pipe
2025-03-22 18:18:34,494:WARNING:Only Model saved as it was a pipeline.
2025-03-22 18:18:34,500:INFO:C:\Users\jeiso\AppData\Local\Temp\tmptoqljq1x\Transformation Pipeline.pkl saved in current working directory
2025-03-22 18:18:34,503:INFO:Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 18:18:34,503:INFO:save_model() successfully completed......................................
2025-03-22 18:18:34,605:INFO:SubProcess save_model() end ==================================
2025-03-22 18:18:34,629:INFO:setup() successfully completed in 1.38s...............
2025-03-22 18:18:36,844:INFO:Initializing compare_models()
2025-03-22 18:18:36,844:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, include=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-22 18:18:36,844:INFO:Checking exceptions
2025-03-22 18:18:36,874:INFO:Preparing display monitor
2025-03-22 18:18:36,888:INFO:Initializing Logistic Regression
2025-03-22 18:18:36,888:INFO:Total runtime is 0.0 minutes
2025-03-22 18:18:36,890:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:36,890:INFO:Initializing create_model()
2025-03-22 18:18:36,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:36,891:INFO:Checking exceptions
2025-03-22 18:18:36,891:INFO:Importing libraries
2025-03-22 18:18:36,891:INFO:Copying training dataset
2025-03-22 18:18:36,937:INFO:Defining folds
2025-03-22 18:18:36,937:INFO:Declaring metric variables
2025-03-22 18:18:36,940:INFO:Importing untrained model
2025-03-22 18:18:36,942:INFO:Logistic Regression Imported successfully
2025-03-22 18:18:36,946:INFO:Starting cross validation
2025-03-22 18:18:36,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:39,494:INFO:Calculating mean and std
2025-03-22 18:18:39,495:INFO:Creating metrics dataframe
2025-03-22 18:18:39,497:INFO:Uploading results into container
2025-03-22 18:18:39,497:INFO:Uploading model into container now
2025-03-22 18:18:39,497:INFO:_master_model_container: 1
2025-03-22 18:18:39,498:INFO:_display_container: 2
2025-03-22 18:18:39,498:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:18:39,498:INFO:create_model() successfully completed......................................
2025-03-22 18:18:39,608:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:39,608:INFO:Creating metrics dataframe
2025-03-22 18:18:39,612:INFO:Initializing K Neighbors Classifier
2025-03-22 18:18:39,612:INFO:Total runtime is 0.0454019029935201 minutes
2025-03-22 18:18:39,614:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:39,615:INFO:Initializing create_model()
2025-03-22 18:18:39,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:39,615:INFO:Checking exceptions
2025-03-22 18:18:39,615:INFO:Importing libraries
2025-03-22 18:18:39,615:INFO:Copying training dataset
2025-03-22 18:18:39,662:INFO:Defining folds
2025-03-22 18:18:39,663:INFO:Declaring metric variables
2025-03-22 18:18:39,665:INFO:Importing untrained model
2025-03-22 18:18:39,668:INFO:K Neighbors Classifier Imported successfully
2025-03-22 18:18:39,672:INFO:Starting cross validation
2025-03-22 18:18:39,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:41,661:INFO:Calculating mean and std
2025-03-22 18:18:41,664:INFO:Creating metrics dataframe
2025-03-22 18:18:41,666:INFO:Uploading results into container
2025-03-22 18:18:41,666:INFO:Uploading model into container now
2025-03-22 18:18:41,666:INFO:_master_model_container: 2
2025-03-22 18:18:41,666:INFO:_display_container: 2
2025-03-22 18:18:41,666:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-22 18:18:41,667:INFO:create_model() successfully completed......................................
2025-03-22 18:18:41,779:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:41,779:INFO:Creating metrics dataframe
2025-03-22 18:18:41,784:INFO:Initializing Naive Bayes
2025-03-22 18:18:41,784:INFO:Total runtime is 0.0816044807434082 minutes
2025-03-22 18:18:41,786:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:41,786:INFO:Initializing create_model()
2025-03-22 18:18:41,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:41,786:INFO:Checking exceptions
2025-03-22 18:18:41,786:INFO:Importing libraries
2025-03-22 18:18:41,786:INFO:Copying training dataset
2025-03-22 18:18:41,836:INFO:Defining folds
2025-03-22 18:18:41,837:INFO:Declaring metric variables
2025-03-22 18:18:41,839:INFO:Importing untrained model
2025-03-22 18:18:41,842:INFO:Naive Bayes Imported successfully
2025-03-22 18:18:41,846:INFO:Starting cross validation
2025-03-22 18:18:41,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:42,038:INFO:Calculating mean and std
2025-03-22 18:18:42,039:INFO:Creating metrics dataframe
2025-03-22 18:18:42,040:INFO:Uploading results into container
2025-03-22 18:18:42,040:INFO:Uploading model into container now
2025-03-22 18:18:42,041:INFO:_master_model_container: 3
2025-03-22 18:18:42,041:INFO:_display_container: 2
2025-03-22 18:18:42,041:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-22 18:18:42,041:INFO:create_model() successfully completed......................................
2025-03-22 18:18:42,151:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:42,151:INFO:Creating metrics dataframe
2025-03-22 18:18:42,155:INFO:Initializing Decision Tree Classifier
2025-03-22 18:18:42,155:INFO:Total runtime is 0.08777883450190226 minutes
2025-03-22 18:18:42,157:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:42,157:INFO:Initializing create_model()
2025-03-22 18:18:42,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:42,157:INFO:Checking exceptions
2025-03-22 18:18:42,157:INFO:Importing libraries
2025-03-22 18:18:42,157:INFO:Copying training dataset
2025-03-22 18:18:42,203:INFO:Defining folds
2025-03-22 18:18:42,203:INFO:Declaring metric variables
2025-03-22 18:18:42,206:INFO:Importing untrained model
2025-03-22 18:18:42,208:INFO:Decision Tree Classifier Imported successfully
2025-03-22 18:18:42,212:INFO:Starting cross validation
2025-03-22 18:18:42,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:42,528:INFO:Calculating mean and std
2025-03-22 18:18:42,529:INFO:Creating metrics dataframe
2025-03-22 18:18:42,530:INFO:Uploading results into container
2025-03-22 18:18:42,531:INFO:Uploading model into container now
2025-03-22 18:18:42,531:INFO:_master_model_container: 4
2025-03-22 18:18:42,531:INFO:_display_container: 2
2025-03-22 18:18:42,531:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-03-22 18:18:42,532:INFO:create_model() successfully completed......................................
2025-03-22 18:18:42,638:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:42,639:INFO:Creating metrics dataframe
2025-03-22 18:18:42,643:INFO:Initializing SVM - Linear Kernel
2025-03-22 18:18:42,643:INFO:Total runtime is 0.09591497977574666 minutes
2025-03-22 18:18:42,646:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:42,646:INFO:Initializing create_model()
2025-03-22 18:18:42,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:42,646:INFO:Checking exceptions
2025-03-22 18:18:42,646:INFO:Importing libraries
2025-03-22 18:18:42,646:INFO:Copying training dataset
2025-03-22 18:18:42,694:INFO:Defining folds
2025-03-22 18:18:42,694:INFO:Declaring metric variables
2025-03-22 18:18:42,697:INFO:Importing untrained model
2025-03-22 18:18:42,699:INFO:SVM - Linear Kernel Imported successfully
2025-03-22 18:18:42,703:INFO:Starting cross validation
2025-03-22 18:18:42,705:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:42,892:INFO:Calculating mean and std
2025-03-22 18:18:42,893:INFO:Creating metrics dataframe
2025-03-22 18:18:42,894:INFO:Uploading results into container
2025-03-22 18:18:42,895:INFO:Uploading model into container now
2025-03-22 18:18:42,895:INFO:_master_model_container: 5
2025-03-22 18:18:42,896:INFO:_display_container: 2
2025-03-22 18:18:42,896:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-22 18:18:42,896:INFO:create_model() successfully completed......................................
2025-03-22 18:18:43,007:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:43,008:INFO:Creating metrics dataframe
2025-03-22 18:18:43,012:INFO:Initializing Ridge Classifier
2025-03-22 18:18:43,013:INFO:Total runtime is 0.10207789738972982 minutes
2025-03-22 18:18:43,015:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:43,015:INFO:Initializing create_model()
2025-03-22 18:18:43,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:43,015:INFO:Checking exceptions
2025-03-22 18:18:43,015:INFO:Importing libraries
2025-03-22 18:18:43,015:INFO:Copying training dataset
2025-03-22 18:18:43,062:INFO:Defining folds
2025-03-22 18:18:43,062:INFO:Declaring metric variables
2025-03-22 18:18:43,065:INFO:Importing untrained model
2025-03-22 18:18:43,067:INFO:Ridge Classifier Imported successfully
2025-03-22 18:18:43,071:INFO:Starting cross validation
2025-03-22 18:18:43,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:43,257:INFO:Calculating mean and std
2025-03-22 18:18:43,258:INFO:Creating metrics dataframe
2025-03-22 18:18:43,259:INFO:Uploading results into container
2025-03-22 18:18:43,259:INFO:Uploading model into container now
2025-03-22 18:18:43,260:INFO:_master_model_container: 6
2025-03-22 18:18:43,260:INFO:_display_container: 2
2025-03-22 18:18:43,260:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-03-22 18:18:43,260:INFO:create_model() successfully completed......................................
2025-03-22 18:18:43,386:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:43,386:INFO:Creating metrics dataframe
2025-03-22 18:18:43,392:INFO:Initializing Random Forest Classifier
2025-03-22 18:18:43,393:INFO:Total runtime is 0.10841181278228759 minutes
2025-03-22 18:18:43,395:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:43,396:INFO:Initializing create_model()
2025-03-22 18:18:43,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:43,396:INFO:Checking exceptions
2025-03-22 18:18:43,396:INFO:Importing libraries
2025-03-22 18:18:43,396:INFO:Copying training dataset
2025-03-22 18:18:43,446:INFO:Defining folds
2025-03-22 18:18:43,446:INFO:Declaring metric variables
2025-03-22 18:18:43,448:INFO:Importing untrained model
2025-03-22 18:18:43,451:INFO:Random Forest Classifier Imported successfully
2025-03-22 18:18:43,455:INFO:Starting cross validation
2025-03-22 18:18:43,456:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:44,032:INFO:Calculating mean and std
2025-03-22 18:18:44,033:INFO:Creating metrics dataframe
2025-03-22 18:18:44,034:INFO:Uploading results into container
2025-03-22 18:18:44,035:INFO:Uploading model into container now
2025-03-22 18:18:44,035:INFO:_master_model_container: 7
2025-03-22 18:18:44,035:INFO:_display_container: 2
2025-03-22 18:18:44,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 18:18:44,035:INFO:create_model() successfully completed......................................
2025-03-22 18:18:44,144:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:44,144:INFO:Creating metrics dataframe
2025-03-22 18:18:44,149:INFO:Initializing Quadratic Discriminant Analysis
2025-03-22 18:18:44,149:INFO:Total runtime is 0.1210231860478719 minutes
2025-03-22 18:18:44,151:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:44,151:INFO:Initializing create_model()
2025-03-22 18:18:44,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:44,151:INFO:Checking exceptions
2025-03-22 18:18:44,151:INFO:Importing libraries
2025-03-22 18:18:44,151:INFO:Copying training dataset
2025-03-22 18:18:44,202:INFO:Defining folds
2025-03-22 18:18:44,202:INFO:Declaring metric variables
2025-03-22 18:18:44,205:INFO:Importing untrained model
2025-03-22 18:18:44,207:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-22 18:18:44,211:INFO:Starting cross validation
2025-03-22 18:18:44,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:44,345:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:18:44,349:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:18:44,361:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:18:44,374:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:18:44,379:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:18:44,393:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:18:44,402:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:18:44,415:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:18:44,422:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:18:44,428:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 18:18:44,459:INFO:Calculating mean and std
2025-03-22 18:18:44,460:INFO:Creating metrics dataframe
2025-03-22 18:18:44,461:INFO:Uploading results into container
2025-03-22 18:18:44,462:INFO:Uploading model into container now
2025-03-22 18:18:44,462:INFO:_master_model_container: 8
2025-03-22 18:18:44,462:INFO:_display_container: 2
2025-03-22 18:18:44,462:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-22 18:18:44,463:INFO:create_model() successfully completed......................................
2025-03-22 18:18:44,576:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:44,576:INFO:Creating metrics dataframe
2025-03-22 18:18:44,581:INFO:Initializing Ada Boost Classifier
2025-03-22 18:18:44,581:INFO:Total runtime is 0.12822548548380533 minutes
2025-03-22 18:18:44,583:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:44,583:INFO:Initializing create_model()
2025-03-22 18:18:44,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:44,583:INFO:Checking exceptions
2025-03-22 18:18:44,583:INFO:Importing libraries
2025-03-22 18:18:44,583:INFO:Copying training dataset
2025-03-22 18:18:44,635:INFO:Defining folds
2025-03-22 18:18:44,635:INFO:Declaring metric variables
2025-03-22 18:18:44,637:INFO:Importing untrained model
2025-03-22 18:18:44,639:INFO:Ada Boost Classifier Imported successfully
2025-03-22 18:18:44,644:INFO:Starting cross validation
2025-03-22 18:18:44,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:44,713:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:18:44,723:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:18:44,734:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:18:44,743:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:18:44,756:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:18:44,759:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:18:44,773:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:18:44,780:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:18:44,800:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:18:44,823:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 18:18:46,028:INFO:Calculating mean and std
2025-03-22 18:18:46,029:INFO:Creating metrics dataframe
2025-03-22 18:18:46,030:INFO:Uploading results into container
2025-03-22 18:18:46,030:INFO:Uploading model into container now
2025-03-22 18:18:46,031:INFO:_master_model_container: 9
2025-03-22 18:18:46,031:INFO:_display_container: 2
2025-03-22 18:18:46,031:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-03-22 18:18:46,031:INFO:create_model() successfully completed......................................
2025-03-22 18:18:46,138:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:46,138:INFO:Creating metrics dataframe
2025-03-22 18:18:46,143:INFO:Initializing Gradient Boosting Classifier
2025-03-22 18:18:46,143:INFO:Total runtime is 0.15424670378367106 minutes
2025-03-22 18:18:46,145:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:46,145:INFO:Initializing create_model()
2025-03-22 18:18:46,145:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:46,145:INFO:Checking exceptions
2025-03-22 18:18:46,145:INFO:Importing libraries
2025-03-22 18:18:46,145:INFO:Copying training dataset
2025-03-22 18:18:46,195:INFO:Defining folds
2025-03-22 18:18:46,196:INFO:Declaring metric variables
2025-03-22 18:18:46,198:INFO:Importing untrained model
2025-03-22 18:18:46,200:INFO:Gradient Boosting Classifier Imported successfully
2025-03-22 18:18:46,204:INFO:Starting cross validation
2025-03-22 18:18:46,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:52,450:INFO:Calculating mean and std
2025-03-22 18:18:52,451:INFO:Creating metrics dataframe
2025-03-22 18:18:52,452:INFO:Uploading results into container
2025-03-22 18:18:52,452:INFO:Uploading model into container now
2025-03-22 18:18:52,453:INFO:_master_model_container: 10
2025-03-22 18:18:52,453:INFO:_display_container: 2
2025-03-22 18:18:52,453:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-22 18:18:52,453:INFO:create_model() successfully completed......................................
2025-03-22 18:18:52,558:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:52,558:INFO:Creating metrics dataframe
2025-03-22 18:18:52,563:INFO:Initializing Linear Discriminant Analysis
2025-03-22 18:18:52,563:INFO:Total runtime is 0.2612547675768534 minutes
2025-03-22 18:18:52,565:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:52,566:INFO:Initializing create_model()
2025-03-22 18:18:52,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:52,566:INFO:Checking exceptions
2025-03-22 18:18:52,566:INFO:Importing libraries
2025-03-22 18:18:52,566:INFO:Copying training dataset
2025-03-22 18:18:52,618:INFO:Defining folds
2025-03-22 18:18:52,618:INFO:Declaring metric variables
2025-03-22 18:18:52,621:INFO:Importing untrained model
2025-03-22 18:18:52,623:INFO:Linear Discriminant Analysis Imported successfully
2025-03-22 18:18:52,628:INFO:Starting cross validation
2025-03-22 18:18:52,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:52,846:INFO:Calculating mean and std
2025-03-22 18:18:52,847:INFO:Creating metrics dataframe
2025-03-22 18:18:52,848:INFO:Uploading results into container
2025-03-22 18:18:52,848:INFO:Uploading model into container now
2025-03-22 18:18:52,849:INFO:_master_model_container: 11
2025-03-22 18:18:52,849:INFO:_display_container: 2
2025-03-22 18:18:52,849:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-22 18:18:52,849:INFO:create_model() successfully completed......................................
2025-03-22 18:18:52,959:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:52,959:INFO:Creating metrics dataframe
2025-03-22 18:18:52,965:INFO:Initializing Extra Trees Classifier
2025-03-22 18:18:52,965:INFO:Total runtime is 0.2679495016733805 minutes
2025-03-22 18:18:52,967:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:52,967:INFO:Initializing create_model()
2025-03-22 18:18:52,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:52,967:INFO:Checking exceptions
2025-03-22 18:18:52,967:INFO:Importing libraries
2025-03-22 18:18:52,967:INFO:Copying training dataset
2025-03-22 18:18:53,020:INFO:Defining folds
2025-03-22 18:18:53,020:INFO:Declaring metric variables
2025-03-22 18:18:53,022:INFO:Importing untrained model
2025-03-22 18:18:53,024:INFO:Extra Trees Classifier Imported successfully
2025-03-22 18:18:53,028:INFO:Starting cross validation
2025-03-22 18:18:53,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:53,400:INFO:Calculating mean and std
2025-03-22 18:18:53,401:INFO:Creating metrics dataframe
2025-03-22 18:18:53,402:INFO:Uploading results into container
2025-03-22 18:18:53,402:INFO:Uploading model into container now
2025-03-22 18:18:53,403:INFO:_master_model_container: 12
2025-03-22 18:18:53,403:INFO:_display_container: 2
2025-03-22 18:18:53,403:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-03-22 18:18:53,403:INFO:create_model() successfully completed......................................
2025-03-22 18:18:53,509:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:53,509:INFO:Creating metrics dataframe
2025-03-22 18:18:53,515:INFO:Initializing Light Gradient Boosting Machine
2025-03-22 18:18:53,515:INFO:Total runtime is 0.27711030642191564 minutes
2025-03-22 18:18:53,516:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:53,517:INFO:Initializing create_model()
2025-03-22 18:18:53,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:53,517:INFO:Checking exceptions
2025-03-22 18:18:53,517:INFO:Importing libraries
2025-03-22 18:18:53,517:INFO:Copying training dataset
2025-03-22 18:18:53,569:INFO:Defining folds
2025-03-22 18:18:53,569:INFO:Declaring metric variables
2025-03-22 18:18:53,571:INFO:Importing untrained model
2025-03-22 18:18:53,574:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-22 18:18:53,578:INFO:Starting cross validation
2025-03-22 18:18:53,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:54,864:INFO:Calculating mean and std
2025-03-22 18:18:54,866:INFO:Creating metrics dataframe
2025-03-22 18:18:54,868:INFO:Uploading results into container
2025-03-22 18:18:54,868:INFO:Uploading model into container now
2025-03-22 18:18:54,869:INFO:_master_model_container: 13
2025-03-22 18:18:54,869:INFO:_display_container: 2
2025-03-22 18:18:54,869:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-22 18:18:54,869:INFO:create_model() successfully completed......................................
2025-03-22 18:18:55,014:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:55,014:INFO:Creating metrics dataframe
2025-03-22 18:18:55,021:INFO:Initializing Dummy Classifier
2025-03-22 18:18:55,021:INFO:Total runtime is 0.30221755901972447 minutes
2025-03-22 18:18:55,023:INFO:SubProcess create_model() called ==================================
2025-03-22 18:18:55,023:INFO:Initializing create_model()
2025-03-22 18:18:55,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F75997EE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:55,023:INFO:Checking exceptions
2025-03-22 18:18:55,023:INFO:Importing libraries
2025-03-22 18:18:55,024:INFO:Copying training dataset
2025-03-22 18:18:55,082:INFO:Defining folds
2025-03-22 18:18:55,082:INFO:Declaring metric variables
2025-03-22 18:18:55,085:INFO:Importing untrained model
2025-03-22 18:18:55,087:INFO:Dummy Classifier Imported successfully
2025-03-22 18:18:55,092:INFO:Starting cross validation
2025-03-22 18:18:55,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:18:55,226:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:18:55,236:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:18:55,254:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:18:55,276:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:18:55,280:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 18:18:55,342:INFO:Calculating mean and std
2025-03-22 18:18:55,343:INFO:Creating metrics dataframe
2025-03-22 18:18:55,344:INFO:Uploading results into container
2025-03-22 18:18:55,344:INFO:Uploading model into container now
2025-03-22 18:18:55,345:INFO:_master_model_container: 14
2025-03-22 18:18:55,345:INFO:_display_container: 2
2025-03-22 18:18:55,345:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-03-22 18:18:55,345:INFO:create_model() successfully completed......................................
2025-03-22 18:18:55,454:INFO:SubProcess create_model() end ==================================
2025-03-22 18:18:55,454:INFO:Creating metrics dataframe
2025-03-22 18:18:55,461:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-22 18:18:55,467:INFO:Initializing create_model()
2025-03-22 18:18:55,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:18:55,467:INFO:Checking exceptions
2025-03-22 18:18:55,469:INFO:Importing libraries
2025-03-22 18:18:55,469:INFO:Copying training dataset
2025-03-22 18:18:55,518:INFO:Defining folds
2025-03-22 18:18:55,518:INFO:Declaring metric variables
2025-03-22 18:18:55,518:INFO:Importing untrained model
2025-03-22 18:18:55,518:INFO:Declaring custom model
2025-03-22 18:18:55,519:INFO:Logistic Regression Imported successfully
2025-03-22 18:18:55,520:INFO:Cross validation set to False
2025-03-22 18:18:55,520:INFO:Fitting Model
2025-03-22 18:18:55,587:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:18:55,587:INFO:create_model() successfully completed......................................
2025-03-22 18:18:55,698:INFO:Creating Dashboard logs
2025-03-22 18:18:55,700:INFO:Model: Logistic Regression
2025-03-22 18:18:55,743:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 18:18:55,844:INFO:Initializing predict_model()
2025-03-22 18:18:55,844:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F81641F30>)
2025-03-22 18:18:55,844:INFO:Checking exceptions
2025-03-22 18:18:55,844:INFO:Preloading libraries
2025-03-22 18:18:57,281:INFO:Creating Dashboard logs
2025-03-22 18:18:57,284:INFO:Model: Ridge Classifier
2025-03-22 18:18:57,318:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2025-03-22 18:18:57,559:INFO:Creating Dashboard logs
2025-03-22 18:18:57,562:INFO:Model: Light Gradient Boosting Machine
2025-03-22 18:18:57,594:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-22 18:18:57,833:INFO:Creating Dashboard logs
2025-03-22 18:18:57,835:INFO:Model: Extra Trees Classifier
2025-03-22 18:18:57,867:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 18:18:58,111:INFO:Creating Dashboard logs
2025-03-22 18:18:58,113:INFO:Model: Random Forest Classifier
2025-03-22 18:18:58,151:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 18:18:58,395:INFO:Creating Dashboard logs
2025-03-22 18:18:58,397:INFO:Model: Ada Boost Classifier
2025-03-22 18:18:58,432:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 123}
2025-03-22 18:18:58,663:INFO:Creating Dashboard logs
2025-03-22 18:18:58,665:INFO:Model: Gradient Boosting Classifier
2025-03-22 18:18:58,699:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 18:18:58,944:INFO:Creating Dashboard logs
2025-03-22 18:18:58,946:INFO:Model: SVM - Linear Kernel
2025-03-22 18:18:58,979:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 18:18:59,224:INFO:Creating Dashboard logs
2025-03-22 18:18:59,226:INFO:Model: Linear Discriminant Analysis
2025-03-22 18:18:59,257:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-03-22 18:18:59,481:INFO:Creating Dashboard logs
2025-03-22 18:18:59,483:INFO:Model: K Neighbors Classifier
2025-03-22 18:18:59,515:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-22 18:18:59,740:INFO:Creating Dashboard logs
2025-03-22 18:18:59,742:INFO:Model: Decision Tree Classifier
2025-03-22 18:18:59,774:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 123, 'splitter': 'best'}
2025-03-22 18:19:00,005:INFO:Creating Dashboard logs
2025-03-22 18:19:00,008:INFO:Model: Quadratic Discriminant Analysis
2025-03-22 18:19:00,042:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-03-22 18:19:00,271:INFO:Creating Dashboard logs
2025-03-22 18:19:00,273:INFO:Model: Naive Bayes
2025-03-22 18:19:00,306:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-03-22 18:19:00,530:INFO:Creating Dashboard logs
2025-03-22 18:19:00,532:INFO:Model: Dummy Classifier
2025-03-22 18:19:00,564:INFO:Logged params: {'constant': None, 'random_state': 123, 'strategy': 'prior'}
2025-03-22 18:19:00,788:INFO:_master_model_container: 14
2025-03-22 18:19:00,788:INFO:_display_container: 2
2025-03-22 18:19:00,788:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:19:00,788:INFO:compare_models() successfully completed......................................
2025-03-22 18:20:12,448:INFO:Initializing create_model()
2025-03-22 18:20:12,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 18:20:12,448:INFO:Checking exceptions
2025-03-22 18:20:12,456:INFO:Importing libraries
2025-03-22 18:20:12,456:INFO:Copying training dataset
2025-03-22 18:20:12,503:INFO:Defining folds
2025-03-22 18:20:12,503:INFO:Declaring metric variables
2025-03-22 18:20:12,505:INFO:Importing untrained model
2025-03-22 18:20:12,508:INFO:Logistic Regression Imported successfully
2025-03-22 18:20:12,511:INFO:Starting cross validation
2025-03-22 18:20:12,513:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 18:20:12,729:INFO:Calculating mean and std
2025-03-22 18:20:12,729:INFO:Creating metrics dataframe
2025-03-22 18:20:12,732:INFO:Finalizing model
2025-03-22 18:20:12,810:INFO:Creating Dashboard logs
2025-03-22 18:20:12,812:INFO:Model: Logistic Regression
2025-03-22 18:20:12,864:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 18:20:12,979:INFO:Initializing predict_model()
2025-03-22 18:20:12,979:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F818813F0>)
2025-03-22 18:20:12,979:INFO:Checking exceptions
2025-03-22 18:20:12,979:INFO:Preloading libraries
2025-03-22 18:20:13,604:INFO:Uploading results into container
2025-03-22 18:20:13,605:INFO:Uploading model into container now
2025-03-22 18:20:13,611:INFO:_master_model_container: 15
2025-03-22 18:20:13,611:INFO:_display_container: 3
2025-03-22 18:20:13,611:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 18:20:13,611:INFO:create_model() successfully completed......................................
2025-03-22 18:20:35,253:INFO:Initializing plot_model()
2025-03-22 18:20:35,253:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 18:20:35,253:INFO:Checking exceptions
2025-03-22 18:20:35,273:INFO:Preloading libraries
2025-03-22 18:20:35,273:INFO:Copying training dataset
2025-03-22 18:20:35,273:INFO:Plot type: confusion_matrix
2025-03-22 18:20:35,734:INFO:Fitting Model
2025-03-22 18:20:35,734:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 18:20:35,734:INFO:Scoring test/hold-out set
2025-03-22 18:20:35,818:INFO:Visual Rendered Successfully
2025-03-22 18:20:35,926:INFO:plot_model() successfully completed......................................
2025-03-22 18:21:26,546:INFO:Initializing evaluate_model()
2025-03-22 18:21:26,546:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-22 18:21:26,573:INFO:Initializing plot_model()
2025-03-22 18:21:26,573:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 18:21:26,573:INFO:Checking exceptions
2025-03-22 18:21:26,590:INFO:Preloading libraries
2025-03-22 18:21:26,590:INFO:Copying training dataset
2025-03-22 18:21:26,590:INFO:Plot type: pipeline
2025-03-22 18:21:26,685:INFO:Visual Rendered Successfully
2025-03-22 18:21:26,791:INFO:plot_model() successfully completed......................................
2025-03-22 18:21:28,185:INFO:Initializing plot_model()
2025-03-22 18:21:28,185:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 18:21:28,185:INFO:Checking exceptions
2025-03-22 18:21:28,203:INFO:Preloading libraries
2025-03-22 18:21:28,203:INFO:Copying training dataset
2025-03-22 18:21:28,203:INFO:Plot type: parameter
2025-03-22 18:21:28,206:INFO:Visual Rendered Successfully
2025-03-22 18:21:28,308:INFO:plot_model() successfully completed......................................
2025-03-22 18:21:29,826:INFO:Initializing plot_model()
2025-03-22 18:21:29,826:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 18:21:29,826:INFO:Checking exceptions
2025-03-22 18:21:29,844:INFO:Preloading libraries
2025-03-22 18:21:29,844:INFO:Copying training dataset
2025-03-22 18:21:29,845:INFO:Plot type: auc
2025-03-22 18:21:30,282:INFO:Fitting Model
2025-03-22 18:21:30,283:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 18:21:30,283:INFO:Scoring test/hold-out set
2025-03-22 18:21:30,407:INFO:Visual Rendered Successfully
2025-03-22 18:21:30,514:INFO:plot_model() successfully completed......................................
2025-03-22 18:21:38,418:INFO:Initializing plot_model()
2025-03-22 18:21:38,419:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 18:21:38,419:INFO:Checking exceptions
2025-03-22 18:21:38,437:INFO:Preloading libraries
2025-03-22 18:21:38,438:INFO:Copying training dataset
2025-03-22 18:21:38,438:INFO:Plot type: confusion_matrix
2025-03-22 18:21:38,904:INFO:Fitting Model
2025-03-22 18:21:38,904:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 18:21:38,904:INFO:Scoring test/hold-out set
2025-03-22 18:21:38,973:INFO:Visual Rendered Successfully
2025-03-22 18:21:39,082:INFO:plot_model() successfully completed......................................
2025-03-22 18:21:41,155:INFO:Initializing plot_model()
2025-03-22 18:21:41,155:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 18:21:41,155:INFO:Checking exceptions
2025-03-22 18:21:41,172:INFO:Preloading libraries
2025-03-22 18:21:41,172:INFO:Copying training dataset
2025-03-22 18:21:41,172:INFO:Plot type: threshold
2025-03-22 18:21:41,634:INFO:Fitting Model
2025-03-22 18:21:44,448:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 18:21:44,458:INFO:Scoring test/hold-out set
2025-03-22 18:21:44,779:INFO:Visual Rendered Successfully
2025-03-22 18:21:44,886:INFO:plot_model() successfully completed......................................
2025-03-22 18:21:46,560:INFO:Initializing plot_model()
2025-03-22 18:21:46,560:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 18:21:46,560:INFO:Checking exceptions
2025-03-22 18:21:46,578:INFO:Preloading libraries
2025-03-22 18:21:46,578:INFO:Copying training dataset
2025-03-22 18:21:46,578:INFO:Plot type: pr
2025-03-22 18:21:47,018:INFO:Fitting Model
2025-03-22 18:21:47,018:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 18:21:47,019:INFO:Scoring test/hold-out set
2025-03-22 18:21:47,131:INFO:Visual Rendered Successfully
2025-03-22 18:21:47,236:INFO:plot_model() successfully completed......................................
2025-03-22 18:21:50,332:INFO:Initializing plot_model()
2025-03-22 18:21:50,332:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 18:21:50,332:INFO:Checking exceptions
2025-03-22 18:21:50,351:INFO:Preloading libraries
2025-03-22 18:21:50,351:INFO:Copying training dataset
2025-03-22 18:21:50,351:INFO:Plot type: error
2025-03-22 18:21:50,800:INFO:Fitting Model
2025-03-22 18:21:50,800:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 18:21:50,800:INFO:Scoring test/hold-out set
2025-03-22 18:21:50,905:INFO:Visual Rendered Successfully
2025-03-22 18:21:51,014:INFO:plot_model() successfully completed......................................
2025-03-22 18:21:52,619:INFO:Initializing plot_model()
2025-03-22 18:21:52,619:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 18:21:52,619:INFO:Checking exceptions
2025-03-22 18:21:52,638:INFO:Preloading libraries
2025-03-22 18:21:52,638:INFO:Copying training dataset
2025-03-22 18:21:52,638:INFO:Plot type: class_report
2025-03-22 18:21:53,084:INFO:Fitting Model
2025-03-22 18:21:53,084:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 18:21:53,084:INFO:Scoring test/hold-out set
2025-03-22 18:21:53,206:INFO:Visual Rendered Successfully
2025-03-22 18:21:53,315:INFO:plot_model() successfully completed......................................
2025-03-22 18:35:40,526:INFO:Initializing save_model()
2025-03-22 18:35:40,526:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=lr_task2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 18:35:40,526:INFO:Adding model into prep_pipe
2025-03-22 18:35:40,534:INFO:lr_task2.pkl saved in current working directory
2025-03-22 18:35:40,538:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'feature_17', 'feature_18',
                                             'feature_19', 'feat...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-03-22 18:35:40,538:INFO:save_model() successfully completed......................................
2025-03-22 18:36:02,366:INFO:Initializing evaluate_model()
2025-03-22 18:36:02,366:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-22 18:36:02,394:INFO:Initializing plot_model()
2025-03-22 18:36:02,394:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 18:36:02,394:INFO:Checking exceptions
2025-03-22 18:36:02,411:INFO:Preloading libraries
2025-03-22 18:36:02,412:INFO:Copying training dataset
2025-03-22 18:36:02,412:INFO:Plot type: pipeline
2025-03-22 18:36:02,485:INFO:Visual Rendered Successfully
2025-03-22 18:36:02,615:INFO:plot_model() successfully completed......................................
2025-03-22 18:36:41,289:INFO:Initializing save_model()
2025-03-22 18:36:41,290:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=lr_task1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 18:36:41,290:INFO:Adding model into prep_pipe
2025-03-22 18:36:41,299:INFO:lr_task1.pkl saved in current working directory
2025-03-22 18:36:41,304:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'feature_17', 'feature_18',
                                             'feature_19', 'feat...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-03-22 18:36:41,304:INFO:save_model() successfully completed......................................
2025-03-22 21:41:32,789:INFO:Initializing plot_model()
2025-03-22 21:41:32,790:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 21:41:32,790:INFO:Checking exceptions
2025-03-22 21:41:32,812:INFO:Preloading libraries
2025-03-22 21:41:32,812:INFO:Copying training dataset
2025-03-22 21:41:32,812:INFO:Plot type: confusion_matrix
2025-03-22 21:41:33,286:INFO:Fitting Model
2025-03-22 21:41:33,286:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 21:41:33,286:INFO:Scoring test/hold-out set
2025-03-22 21:41:33,363:INFO:Visual Rendered Successfully
2025-03-22 21:41:33,528:INFO:plot_model() successfully completed......................................
2025-03-22 21:42:07,036:INFO:Initializing create_model()
2025-03-22 21:42:07,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 21:42:07,037:INFO:Checking exceptions
2025-03-22 21:42:07,046:INFO:Importing libraries
2025-03-22 21:42:07,046:INFO:Copying training dataset
2025-03-22 21:42:07,094:INFO:Defining folds
2025-03-22 21:42:07,094:INFO:Declaring metric variables
2025-03-22 21:42:07,097:INFO:Importing untrained model
2025-03-22 21:42:07,099:INFO:Logistic Regression Imported successfully
2025-03-22 21:42:07,103:INFO:Starting cross validation
2025-03-22 21:42:07,104:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 21:42:09,566:INFO:Calculating mean and std
2025-03-22 21:42:09,567:INFO:Creating metrics dataframe
2025-03-22 21:42:09,571:INFO:Finalizing model
2025-03-22 21:42:09,651:INFO:Creating Dashboard logs
2025-03-22 21:42:09,653:INFO:Model: Logistic Regression
2025-03-22 21:42:09,704:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 21:42:09,808:INFO:Initializing predict_model()
2025-03-22 21:42:09,808:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F819EE200>)
2025-03-22 21:42:09,808:INFO:Checking exceptions
2025-03-22 21:42:09,808:INFO:Preloading libraries
2025-03-22 21:42:10,553:INFO:Uploading results into container
2025-03-22 21:42:10,554:INFO:Uploading model into container now
2025-03-22 21:42:10,560:INFO:_master_model_container: 16
2025-03-22 21:42:10,560:INFO:_display_container: 4
2025-03-22 21:42:10,560:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 21:42:10,561:INFO:create_model() successfully completed......................................
2025-03-22 21:42:19,005:INFO:Initializing plot_model()
2025-03-22 21:42:19,005:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F122A7FD0>, system=True)
2025-03-22 21:42:19,005:INFO:Checking exceptions
2025-03-22 21:42:19,025:INFO:Preloading libraries
2025-03-22 21:42:19,026:INFO:Copying training dataset
2025-03-22 21:42:19,026:INFO:Plot type: confusion_matrix
2025-03-22 21:42:19,509:INFO:Fitting Model
2025-03-22 21:42:19,509:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 21:42:19,510:INFO:Scoring test/hold-out set
2025-03-22 21:42:19,583:INFO:Visual Rendered Successfully
2025-03-22 21:42:19,696:INFO:plot_model() successfully completed......................................
2025-03-22 21:56:08,838:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_350ca7daf9614a5d9dd6911e2cd3824d
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,838:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_709ec6ced727489eab90defb1ad4aaab_58bc9522ee8846b694342d3fd8f558f2
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,838:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_b34c03500de3423ab60f52488aa43614
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,838:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_1fd7882deee44e85946edeee52f227c3_81915793de294e90a119da9ec0a27ad0
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,838:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_4d4d1a98662b408582abf19334c39fa0
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,839:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_936086a6b9d145c9807cf1980b0402ba_01aeffb4852d4242a551ba14e9913909
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,839:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_09c246914059405c8f571c062eeca5bb
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,839:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_cdcf2fa530ae4674b75e9e1fcf543a17_93970d987067450d8140e0a2840ea930
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,839:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_f68b1bd273ae4eb5bbc3a618107c2ad5
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,839:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_5628070c011b461783ca6d143480811a_3abb63cf73814f21a7e3b36028a54542
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,839:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_a5484ed3c2714a82a7444bb0452f3afd
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,839:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_492d67ba6919478f9842c4ac693338fd_ff9d1931cce04331a36ec028f4020314
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,839:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_e197111f31cc43f0a542c485533ca435
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,839:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_eb419cd86f8542fda5b86c2a7056bbae_087fb1adb491439a83e60720c09a644a
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,839:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_b986371f714a471888477063c6337b11
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,839:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_019a9f3b98a94090af5e48ebe27c8a5e_504a829e1e7a46a1afa3a1f28af0475c
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_ce0289a1bf33439fad89376b4b6056cb
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_554bfd3898b74a35be859175b9a992db_a78ac37be51a4a4f80b33257f2c76362
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_dabae890ef844cb39eb1ddeb7601f4f0
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_1c1f33d5152848369676822a3e0adf36_6aebeef883514db88775b6c982a12181
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_1dd437ef08614a91abab26ca9bad18ac
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_8eeb5de860ca426fbd4cc394d2d34e9b_98770f795839496cb6e2c5633e1b2fe4
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_4c7389843b2f4246b186a8e02c536ff1
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_aefc0c375a634e119eb1c1394bac8e31_3a05f1b7ed874aacababab3e2274e015
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_d0c4f398d59848a88008f85aaa53d55c
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_b5380d41c65e4d6d9406291252c3a268_029f56a4fde44690b7d0832450602424
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_907c1e609dd34edf95888b3b2c13d69f
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_5b07eb56a0c04ab192ae0b86622dd483_8c4e466c5c334f7eb7b4263cc8b96655
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_fbbf439950a64968b1fc34cedd72d4ea
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,840:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_9daea6acfde144858684994bc359cac9_f0d4a230b9504b3988236029f0316787
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,841:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_85d1ee86407a4db896bc3e04c57b7106
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:08,841:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_22704_4527068e3dcb4a0187b895c99ec0c9e5_4c6b4bbf01de4cf39eecb89d7324837b
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 21:56:59,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 21:56:59,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 21:56:59,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 21:56:59,352:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 21:59:43,865:INFO:PyCaret ClassificationExperiment
2025-03-22 21:59:43,865:INFO:Logging name: Mentalrisk_task1
2025-03-22 21:59:43,865:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-22 21:59:43,865:INFO:version 3.3.2
2025-03-22 21:59:43,865:INFO:Initializing setup()
2025-03-22 21:59:43,865:INFO:self.USI: 6355
2025-03-22 21:59:43,865:INFO:self._variable_keys: {'memory', 'X', 'fold_generator', 'fix_imbalance', 'fold_shuffle_param', 'X_train', 'gpu_param', 'html_param', 'X_test', 'n_jobs_param', 'is_multiclass', 'log_plots_param', 'exp_id', 'gpu_n_jobs_param', '_ml_usecase', 'idx', 'seed', '_available_plots', 'pipeline', 'data', 'y', 'target_param', 'y_train', 'logging_param', 'fold_groups_param', 'USI', 'exp_name_log', 'y_test'}
2025-03-22 21:59:43,866:INFO:Checking environment
2025-03-22 21:59:43,866:INFO:python_version: 3.10.11
2025-03-22 21:59:43,866:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-03-22 21:59:43,866:INFO:machine: AMD64
2025-03-22 21:59:43,866:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-22 21:59:43,869:INFO:Memory: svmem(total=34188517376, available=19075497984, percent=44.2, used=15113019392, free=19075497984)
2025-03-22 21:59:43,869:INFO:Physical Core: 12
2025-03-22 21:59:43,869:INFO:Logical Core: 20
2025-03-22 21:59:43,869:INFO:Checking libraries
2025-03-22 21:59:43,869:INFO:System:
2025-03-22 21:59:43,869:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-03-22 21:59:43,869:INFO:executable: C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\Scripts\python.exe
2025-03-22 21:59:43,869:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-22 21:59:43,869:INFO:PyCaret required dependencies:
2025-03-22 21:59:43,914:INFO:                 pip: 24.2
2025-03-22 21:59:43,914:INFO:          setuptools: 73.0.1
2025-03-22 21:59:43,914:INFO:             pycaret: 3.3.2
2025-03-22 21:59:43,914:INFO:             IPython: 8.34.0
2025-03-22 21:59:43,914:INFO:          ipywidgets: 8.1.5
2025-03-22 21:59:43,914:INFO:                tqdm: 4.67.1
2025-03-22 21:59:43,914:INFO:               numpy: 1.26.4
2025-03-22 21:59:43,914:INFO:              pandas: 2.1.4
2025-03-22 21:59:43,914:INFO:              jinja2: 3.1.6
2025-03-22 21:59:43,914:INFO:               scipy: 1.11.4
2025-03-22 21:59:43,914:INFO:              joblib: 1.3.2
2025-03-22 21:59:43,914:INFO:             sklearn: 1.4.2
2025-03-22 21:59:43,914:INFO:                pyod: 2.0.3
2025-03-22 21:59:43,914:INFO:            imblearn: 0.13.0
2025-03-22 21:59:43,914:INFO:   category_encoders: 2.7.0
2025-03-22 21:59:43,914:INFO:            lightgbm: 4.6.0
2025-03-22 21:59:43,914:INFO:               numba: 0.61.0
2025-03-22 21:59:43,914:INFO:            requests: 2.32.3
2025-03-22 21:59:43,914:INFO:          matplotlib: 3.7.5
2025-03-22 21:59:43,914:INFO:          scikitplot: 0.3.7
2025-03-22 21:59:43,914:INFO:         yellowbrick: 1.5
2025-03-22 21:59:43,914:INFO:              plotly: 5.24.1
2025-03-22 21:59:43,914:INFO:    plotly-resampler: Not installed
2025-03-22 21:59:43,914:INFO:             kaleido: 0.2.1
2025-03-22 21:59:43,914:INFO:           schemdraw: 0.15
2025-03-22 21:59:43,914:INFO:         statsmodels: 0.14.4
2025-03-22 21:59:43,915:INFO:              sktime: 0.26.0
2025-03-22 21:59:43,915:INFO:               tbats: 1.1.3
2025-03-22 21:59:43,915:INFO:            pmdarima: 2.0.4
2025-03-22 21:59:43,915:INFO:              psutil: 7.0.0
2025-03-22 21:59:43,915:INFO:          markupsafe: 3.0.2
2025-03-22 21:59:43,915:INFO:             pickle5: Not installed
2025-03-22 21:59:43,915:INFO:         cloudpickle: 3.1.1
2025-03-22 21:59:43,915:INFO:         deprecation: 2.1.0
2025-03-22 21:59:43,915:INFO:              xxhash: 3.5.0
2025-03-22 21:59:43,915:INFO:           wurlitzer: Not installed
2025-03-22 21:59:43,915:INFO:PyCaret optional dependencies:
2025-03-22 21:59:43,926:INFO:                shap: Not installed
2025-03-22 21:59:43,926:INFO:           interpret: Not installed
2025-03-22 21:59:43,926:INFO:                umap: Not installed
2025-03-22 21:59:43,926:INFO:     ydata_profiling: Not installed
2025-03-22 21:59:43,926:INFO:  explainerdashboard: Not installed
2025-03-22 21:59:43,926:INFO:             autoviz: Not installed
2025-03-22 21:59:43,926:INFO:           fairlearn: Not installed
2025-03-22 21:59:43,926:INFO:          deepchecks: Not installed
2025-03-22 21:59:43,926:INFO:             xgboost: Not installed
2025-03-22 21:59:43,926:INFO:            catboost: Not installed
2025-03-22 21:59:43,926:INFO:              kmodes: Not installed
2025-03-22 21:59:43,926:INFO:             mlxtend: Not installed
2025-03-22 21:59:43,926:INFO:       statsforecast: Not installed
2025-03-22 21:59:43,926:INFO:        tune_sklearn: Not installed
2025-03-22 21:59:43,926:INFO:                 ray: Not installed
2025-03-22 21:59:43,926:INFO:            hyperopt: Not installed
2025-03-22 21:59:43,927:INFO:              optuna: Not installed
2025-03-22 21:59:43,927:INFO:               skopt: Not installed
2025-03-22 21:59:43,927:INFO:              mlflow: 2.16.0
2025-03-22 21:59:43,927:INFO:              gradio: Not installed
2025-03-22 21:59:43,927:INFO:             fastapi: Not installed
2025-03-22 21:59:43,927:INFO:             uvicorn: Not installed
2025-03-22 21:59:43,927:INFO:              m2cgen: Not installed
2025-03-22 21:59:43,927:INFO:           evidently: Not installed
2025-03-22 21:59:43,927:INFO:               fugue: Not installed
2025-03-22 21:59:43,927:INFO:           streamlit: Not installed
2025-03-22 21:59:43,927:INFO:             prophet: Not installed
2025-03-22 21:59:43,927:INFO:None
2025-03-22 21:59:43,927:INFO:Set up data.
2025-03-22 22:00:01,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:00:01,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:00:01,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:00:01,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:00:37,706:INFO:PyCaret ClassificationExperiment
2025-03-22 22:00:37,706:INFO:Logging name: Mentalrisk_task1
2025-03-22 22:00:37,707:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-22 22:00:37,707:INFO:version 3.3.2
2025-03-22 22:00:37,707:INFO:Initializing setup()
2025-03-22 22:00:37,707:INFO:self.USI: da38
2025-03-22 22:00:37,707:INFO:self._variable_keys: {'USI', 'fold_shuffle_param', 'gpu_n_jobs_param', '_ml_usecase', 'html_param', 'idx', 'fix_imbalance', '_available_plots', 'is_multiclass', 'X_train', 'logging_param', 'gpu_param', 'X', 'seed', 'y_train', 'fold_generator', 'fold_groups_param', 'y', 'pipeline', 'log_plots_param', 'n_jobs_param', 'exp_name_log', 'exp_id', 'data', 'X_test', 'target_param', 'memory', 'y_test'}
2025-03-22 22:00:37,707:INFO:Checking environment
2025-03-22 22:00:37,707:INFO:python_version: 3.10.11
2025-03-22 22:00:37,707:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-03-22 22:00:37,707:INFO:machine: AMD64
2025-03-22 22:00:37,707:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-22 22:00:37,710:INFO:Memory: svmem(total=34188517376, available=19098873856, percent=44.1, used=15089643520, free=19098873856)
2025-03-22 22:00:37,710:INFO:Physical Core: 12
2025-03-22 22:00:37,710:INFO:Logical Core: 20
2025-03-22 22:00:37,710:INFO:Checking libraries
2025-03-22 22:00:37,710:INFO:System:
2025-03-22 22:00:37,710:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-03-22 22:00:37,710:INFO:executable: C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\Scripts\python.exe
2025-03-22 22:00:37,710:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-22 22:00:37,710:INFO:PyCaret required dependencies:
2025-03-22 22:00:37,746:INFO:                 pip: 24.2
2025-03-22 22:00:37,746:INFO:          setuptools: 73.0.1
2025-03-22 22:00:37,746:INFO:             pycaret: 3.3.2
2025-03-22 22:00:37,746:INFO:             IPython: 8.34.0
2025-03-22 22:00:37,746:INFO:          ipywidgets: 8.1.5
2025-03-22 22:00:37,746:INFO:                tqdm: 4.67.1
2025-03-22 22:00:37,746:INFO:               numpy: 1.26.4
2025-03-22 22:00:37,746:INFO:              pandas: 2.1.4
2025-03-22 22:00:37,746:INFO:              jinja2: 3.1.6
2025-03-22 22:00:37,746:INFO:               scipy: 1.11.4
2025-03-22 22:00:37,746:INFO:              joblib: 1.3.2
2025-03-22 22:00:37,746:INFO:             sklearn: 1.4.2
2025-03-22 22:00:37,746:INFO:                pyod: 2.0.3
2025-03-22 22:00:37,746:INFO:            imblearn: 0.13.0
2025-03-22 22:00:37,746:INFO:   category_encoders: 2.7.0
2025-03-22 22:00:37,746:INFO:            lightgbm: 4.6.0
2025-03-22 22:00:37,746:INFO:               numba: 0.61.0
2025-03-22 22:00:37,746:INFO:            requests: 2.32.3
2025-03-22 22:00:37,746:INFO:          matplotlib: 3.7.5
2025-03-22 22:00:37,746:INFO:          scikitplot: 0.3.7
2025-03-22 22:00:37,746:INFO:         yellowbrick: 1.5
2025-03-22 22:00:37,746:INFO:              plotly: 5.24.1
2025-03-22 22:00:37,746:INFO:    plotly-resampler: Not installed
2025-03-22 22:00:37,746:INFO:             kaleido: 0.2.1
2025-03-22 22:00:37,746:INFO:           schemdraw: 0.15
2025-03-22 22:00:37,746:INFO:         statsmodels: 0.14.4
2025-03-22 22:00:37,746:INFO:              sktime: 0.26.0
2025-03-22 22:00:37,746:INFO:               tbats: 1.1.3
2025-03-22 22:00:37,746:INFO:            pmdarima: 2.0.4
2025-03-22 22:00:37,746:INFO:              psutil: 7.0.0
2025-03-22 22:00:37,746:INFO:          markupsafe: 3.0.2
2025-03-22 22:00:37,746:INFO:             pickle5: Not installed
2025-03-22 22:00:37,746:INFO:         cloudpickle: 3.1.1
2025-03-22 22:00:37,746:INFO:         deprecation: 2.1.0
2025-03-22 22:00:37,746:INFO:              xxhash: 3.5.0
2025-03-22 22:00:37,746:INFO:           wurlitzer: Not installed
2025-03-22 22:00:37,746:INFO:PyCaret optional dependencies:
2025-03-22 22:00:37,758:INFO:                shap: Not installed
2025-03-22 22:00:37,758:INFO:           interpret: Not installed
2025-03-22 22:00:37,758:INFO:                umap: Not installed
2025-03-22 22:00:37,758:INFO:     ydata_profiling: Not installed
2025-03-22 22:00:37,758:INFO:  explainerdashboard: Not installed
2025-03-22 22:00:37,758:INFO:             autoviz: Not installed
2025-03-22 22:00:37,758:INFO:           fairlearn: Not installed
2025-03-22 22:00:37,758:INFO:          deepchecks: Not installed
2025-03-22 22:00:37,758:INFO:             xgboost: Not installed
2025-03-22 22:00:37,758:INFO:            catboost: Not installed
2025-03-22 22:00:37,758:INFO:              kmodes: Not installed
2025-03-22 22:00:37,758:INFO:             mlxtend: Not installed
2025-03-22 22:00:37,758:INFO:       statsforecast: Not installed
2025-03-22 22:00:37,758:INFO:        tune_sklearn: Not installed
2025-03-22 22:00:37,758:INFO:                 ray: Not installed
2025-03-22 22:00:37,758:INFO:            hyperopt: Not installed
2025-03-22 22:00:37,758:INFO:              optuna: Not installed
2025-03-22 22:00:37,758:INFO:               skopt: Not installed
2025-03-22 22:00:37,758:INFO:              mlflow: 2.16.0
2025-03-22 22:00:37,758:INFO:              gradio: Not installed
2025-03-22 22:00:37,758:INFO:             fastapi: Not installed
2025-03-22 22:00:37,758:INFO:             uvicorn: Not installed
2025-03-22 22:00:37,759:INFO:              m2cgen: Not installed
2025-03-22 22:00:37,759:INFO:           evidently: Not installed
2025-03-22 22:00:37,759:INFO:               fugue: Not installed
2025-03-22 22:00:37,759:INFO:           streamlit: Not installed
2025-03-22 22:00:37,759:INFO:             prophet: Not installed
2025-03-22 22:00:37,759:INFO:None
2025-03-22 22:00:37,759:INFO:Set up data.
2025-03-22 22:00:37,816:INFO:Set up folding strategy.
2025-03-22 22:00:37,816:INFO:Set up train/test split.
2025-03-22 22:00:37,855:INFO:Set up index.
2025-03-22 22:00:37,856:INFO:Assigning column types.
2025-03-22 22:00:37,998:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-22 22:00:38,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 22:00:38,023:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:00:38,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 22:00:38,065:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:00:38,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,079:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-22 22:00:38,100:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:00:38,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,137:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:00:38,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,151:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-22 22:00:38,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:38,224:INFO:Preparing preprocessing pipeline...
2025-03-22 22:00:38,231:INFO:Set up simple imputation.
2025-03-22 22:00:38,389:INFO:Finished creating preprocessing pipeline.
2025-03-22 22:00:38,393:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 22:00:38,393:INFO:Creating final display dataframe.
2025-03-22 22:00:38,958:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             level
2                   Target type            Binary
3           Original data shape        (462, 769)
4        Transformed data shape        (462, 769)
5   Transformed train set shape        (369, 769)
6    Transformed test set shape         (93, 769)
7              Numeric features               768
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment      MlflowLogger
17              Experiment Name  Mentalrisk_task1
18                          USI              da38
2025-03-22 22:00:39,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:39,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:39,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:39,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:00:39,038:INFO:Logging experiment in loggers
2025-03-22 22:00:39,212:INFO:SubProcess save_model() called ==================================
2025-03-22 22:00:39,219:INFO:Initializing save_model()
2025-03-22 22:00:39,219:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\jeiso\AppData\Local\Temp\tmpww4k610o\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 22:00:39,219:INFO:Adding model into prep_pipe
2025-03-22 22:00:39,219:WARNING:Only Model saved as it was a pipeline.
2025-03-22 22:00:39,224:INFO:C:\Users\jeiso\AppData\Local\Temp\tmpww4k610o\Transformation Pipeline.pkl saved in current working directory
2025-03-22 22:00:39,227:INFO:Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 22:00:39,227:INFO:save_model() successfully completed......................................
2025-03-22 22:00:39,333:INFO:SubProcess save_model() end ==================================
2025-03-22 22:00:39,379:INFO:setup() successfully completed in 1.33s...............
2025-03-22 22:00:54,009:INFO:Initializing compare_models()
2025-03-22 22:00:54,009:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, include=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-22 22:00:54,009:INFO:Checking exceptions
2025-03-22 22:00:54,039:INFO:Preparing display monitor
2025-03-22 22:00:54,054:INFO:Initializing Logistic Regression
2025-03-22 22:00:54,054:INFO:Total runtime is 0.0 minutes
2025-03-22 22:00:54,056:INFO:SubProcess create_model() called ==================================
2025-03-22 22:00:54,056:INFO:Initializing create_model()
2025-03-22 22:00:54,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:00:54,056:INFO:Checking exceptions
2025-03-22 22:00:54,056:INFO:Importing libraries
2025-03-22 22:00:54,056:INFO:Copying training dataset
2025-03-22 22:00:54,105:INFO:Defining folds
2025-03-22 22:00:54,105:INFO:Declaring metric variables
2025-03-22 22:00:54,107:INFO:Importing untrained model
2025-03-22 22:00:54,109:INFO:Logistic Regression Imported successfully
2025-03-22 22:00:54,113:INFO:Starting cross validation
2025-03-22 22:00:54,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:00:56,623:INFO:Calculating mean and std
2025-03-22 22:00:56,625:INFO:Creating metrics dataframe
2025-03-22 22:00:56,626:INFO:Uploading results into container
2025-03-22 22:00:56,626:INFO:Uploading model into container now
2025-03-22 22:00:56,627:INFO:_master_model_container: 1
2025-03-22 22:00:56,627:INFO:_display_container: 2
2025-03-22 22:00:56,627:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 22:00:56,627:INFO:create_model() successfully completed......................................
2025-03-22 22:00:56,733:INFO:SubProcess create_model() end ==================================
2025-03-22 22:00:56,733:INFO:Creating metrics dataframe
2025-03-22 22:00:56,738:INFO:Initializing K Neighbors Classifier
2025-03-22 22:00:56,738:INFO:Total runtime is 0.04472259283065796 minutes
2025-03-22 22:00:56,740:INFO:SubProcess create_model() called ==================================
2025-03-22 22:00:56,740:INFO:Initializing create_model()
2025-03-22 22:00:56,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:00:56,740:INFO:Checking exceptions
2025-03-22 22:00:56,740:INFO:Importing libraries
2025-03-22 22:00:56,740:INFO:Copying training dataset
2025-03-22 22:00:56,788:INFO:Defining folds
2025-03-22 22:00:56,788:INFO:Declaring metric variables
2025-03-22 22:00:56,791:INFO:Importing untrained model
2025-03-22 22:00:56,793:INFO:K Neighbors Classifier Imported successfully
2025-03-22 22:00:56,797:INFO:Starting cross validation
2025-03-22 22:00:56,799:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:00:58,765:INFO:Calculating mean and std
2025-03-22 22:00:58,766:INFO:Creating metrics dataframe
2025-03-22 22:00:58,768:INFO:Uploading results into container
2025-03-22 22:00:58,768:INFO:Uploading model into container now
2025-03-22 22:00:58,768:INFO:_master_model_container: 2
2025-03-22 22:00:58,769:INFO:_display_container: 2
2025-03-22 22:00:58,769:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-22 22:00:58,769:INFO:create_model() successfully completed......................................
2025-03-22 22:00:58,880:INFO:SubProcess create_model() end ==================================
2025-03-22 22:00:58,880:INFO:Creating metrics dataframe
2025-03-22 22:00:58,885:INFO:Initializing Naive Bayes
2025-03-22 22:00:58,885:INFO:Total runtime is 0.08050456444422405 minutes
2025-03-22 22:00:58,887:INFO:SubProcess create_model() called ==================================
2025-03-22 22:00:58,887:INFO:Initializing create_model()
2025-03-22 22:00:58,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:00:58,887:INFO:Checking exceptions
2025-03-22 22:00:58,887:INFO:Importing libraries
2025-03-22 22:00:58,887:INFO:Copying training dataset
2025-03-22 22:00:58,938:INFO:Defining folds
2025-03-22 22:00:58,938:INFO:Declaring metric variables
2025-03-22 22:00:58,941:INFO:Importing untrained model
2025-03-22 22:00:58,943:INFO:Naive Bayes Imported successfully
2025-03-22 22:00:58,947:INFO:Starting cross validation
2025-03-22 22:00:58,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:00:59,132:INFO:Calculating mean and std
2025-03-22 22:00:59,133:INFO:Creating metrics dataframe
2025-03-22 22:00:59,134:INFO:Uploading results into container
2025-03-22 22:00:59,134:INFO:Uploading model into container now
2025-03-22 22:00:59,135:INFO:_master_model_container: 3
2025-03-22 22:00:59,135:INFO:_display_container: 2
2025-03-22 22:00:59,135:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-22 22:00:59,135:INFO:create_model() successfully completed......................................
2025-03-22 22:00:59,242:INFO:SubProcess create_model() end ==================================
2025-03-22 22:00:59,242:INFO:Creating metrics dataframe
2025-03-22 22:00:59,246:INFO:Initializing Decision Tree Classifier
2025-03-22 22:00:59,246:INFO:Total runtime is 0.08652190367380778 minutes
2025-03-22 22:00:59,248:INFO:SubProcess create_model() called ==================================
2025-03-22 22:00:59,248:INFO:Initializing create_model()
2025-03-22 22:00:59,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:00:59,249:INFO:Checking exceptions
2025-03-22 22:00:59,249:INFO:Importing libraries
2025-03-22 22:00:59,249:INFO:Copying training dataset
2025-03-22 22:00:59,296:INFO:Defining folds
2025-03-22 22:00:59,296:INFO:Declaring metric variables
2025-03-22 22:00:59,299:INFO:Importing untrained model
2025-03-22 22:00:59,301:INFO:Decision Tree Classifier Imported successfully
2025-03-22 22:00:59,305:INFO:Starting cross validation
2025-03-22 22:00:59,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:00:59,622:INFO:Calculating mean and std
2025-03-22 22:00:59,623:INFO:Creating metrics dataframe
2025-03-22 22:00:59,625:INFO:Uploading results into container
2025-03-22 22:00:59,625:INFO:Uploading model into container now
2025-03-22 22:00:59,626:INFO:_master_model_container: 4
2025-03-22 22:00:59,626:INFO:_display_container: 2
2025-03-22 22:00:59,626:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-03-22 22:00:59,626:INFO:create_model() successfully completed......................................
2025-03-22 22:00:59,734:INFO:SubProcess create_model() end ==================================
2025-03-22 22:00:59,734:INFO:Creating metrics dataframe
2025-03-22 22:00:59,739:INFO:Initializing SVM - Linear Kernel
2025-03-22 22:00:59,739:INFO:Total runtime is 0.09474269151687623 minutes
2025-03-22 22:00:59,741:INFO:SubProcess create_model() called ==================================
2025-03-22 22:00:59,741:INFO:Initializing create_model()
2025-03-22 22:00:59,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:00:59,741:INFO:Checking exceptions
2025-03-22 22:00:59,742:INFO:Importing libraries
2025-03-22 22:00:59,742:INFO:Copying training dataset
2025-03-22 22:00:59,790:INFO:Defining folds
2025-03-22 22:00:59,790:INFO:Declaring metric variables
2025-03-22 22:00:59,793:INFO:Importing untrained model
2025-03-22 22:00:59,795:INFO:SVM - Linear Kernel Imported successfully
2025-03-22 22:00:59,799:INFO:Starting cross validation
2025-03-22 22:00:59,800:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:00:59,988:INFO:Calculating mean and std
2025-03-22 22:00:59,989:INFO:Creating metrics dataframe
2025-03-22 22:00:59,991:INFO:Uploading results into container
2025-03-22 22:00:59,991:INFO:Uploading model into container now
2025-03-22 22:00:59,991:INFO:_master_model_container: 5
2025-03-22 22:00:59,991:INFO:_display_container: 2
2025-03-22 22:00:59,992:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-22 22:00:59,992:INFO:create_model() successfully completed......................................
2025-03-22 22:01:00,100:INFO:SubProcess create_model() end ==================================
2025-03-22 22:01:00,100:INFO:Creating metrics dataframe
2025-03-22 22:01:00,104:INFO:Initializing Ridge Classifier
2025-03-22 22:01:00,104:INFO:Total runtime is 0.10082669655481975 minutes
2025-03-22 22:01:00,106:INFO:SubProcess create_model() called ==================================
2025-03-22 22:01:00,106:INFO:Initializing create_model()
2025-03-22 22:01:00,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:01:00,106:INFO:Checking exceptions
2025-03-22 22:01:00,106:INFO:Importing libraries
2025-03-22 22:01:00,106:INFO:Copying training dataset
2025-03-22 22:01:00,155:INFO:Defining folds
2025-03-22 22:01:00,155:INFO:Declaring metric variables
2025-03-22 22:01:00,158:INFO:Importing untrained model
2025-03-22 22:01:00,161:INFO:Ridge Classifier Imported successfully
2025-03-22 22:01:00,165:INFO:Starting cross validation
2025-03-22 22:01:00,166:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:01:00,352:INFO:Calculating mean and std
2025-03-22 22:01:00,353:INFO:Creating metrics dataframe
2025-03-22 22:01:00,354:INFO:Uploading results into container
2025-03-22 22:01:00,355:INFO:Uploading model into container now
2025-03-22 22:01:00,355:INFO:_master_model_container: 6
2025-03-22 22:01:00,355:INFO:_display_container: 2
2025-03-22 22:01:00,355:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-03-22 22:01:00,355:INFO:create_model() successfully completed......................................
2025-03-22 22:01:00,465:INFO:SubProcess create_model() end ==================================
2025-03-22 22:01:00,465:INFO:Creating metrics dataframe
2025-03-22 22:01:00,469:INFO:Initializing Random Forest Classifier
2025-03-22 22:01:00,469:INFO:Total runtime is 0.10690220991770427 minutes
2025-03-22 22:01:00,471:INFO:SubProcess create_model() called ==================================
2025-03-22 22:01:00,471:INFO:Initializing create_model()
2025-03-22 22:01:00,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:01:00,472:INFO:Checking exceptions
2025-03-22 22:01:00,472:INFO:Importing libraries
2025-03-22 22:01:00,472:INFO:Copying training dataset
2025-03-22 22:01:00,522:INFO:Defining folds
2025-03-22 22:01:00,523:INFO:Declaring metric variables
2025-03-22 22:01:00,525:INFO:Importing untrained model
2025-03-22 22:01:00,527:INFO:Random Forest Classifier Imported successfully
2025-03-22 22:01:00,531:INFO:Starting cross validation
2025-03-22 22:01:00,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:01:01,141:INFO:Calculating mean and std
2025-03-22 22:01:01,142:INFO:Creating metrics dataframe
2025-03-22 22:01:01,143:INFO:Uploading results into container
2025-03-22 22:01:01,144:INFO:Uploading model into container now
2025-03-22 22:01:01,144:INFO:_master_model_container: 7
2025-03-22 22:01:01,144:INFO:_display_container: 2
2025-03-22 22:01:01,144:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 22:01:01,144:INFO:create_model() successfully completed......................................
2025-03-22 22:01:01,249:INFO:SubProcess create_model() end ==================================
2025-03-22 22:01:01,249:INFO:Creating metrics dataframe
2025-03-22 22:01:01,254:INFO:Initializing Quadratic Discriminant Analysis
2025-03-22 22:01:01,254:INFO:Total runtime is 0.11999951601028443 minutes
2025-03-22 22:01:01,256:INFO:SubProcess create_model() called ==================================
2025-03-22 22:01:01,256:INFO:Initializing create_model()
2025-03-22 22:01:01,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:01:01,256:INFO:Checking exceptions
2025-03-22 22:01:01,256:INFO:Importing libraries
2025-03-22 22:01:01,257:INFO:Copying training dataset
2025-03-22 22:01:01,309:INFO:Defining folds
2025-03-22 22:01:01,309:INFO:Declaring metric variables
2025-03-22 22:01:01,311:INFO:Importing untrained model
2025-03-22 22:01:01,313:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-22 22:01:01,318:INFO:Starting cross validation
2025-03-22 22:01:01,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:01:01,450:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:01:01,458:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:01:01,471:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:01:01,493:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:01:01,501:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:01:01,507:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:01:01,525:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:01:01,528:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:01:01,536:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:01:01,552:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:01:01,585:INFO:Calculating mean and std
2025-03-22 22:01:01,586:INFO:Creating metrics dataframe
2025-03-22 22:01:01,587:INFO:Uploading results into container
2025-03-22 22:01:01,588:INFO:Uploading model into container now
2025-03-22 22:01:01,588:INFO:_master_model_container: 8
2025-03-22 22:01:01,588:INFO:_display_container: 2
2025-03-22 22:01:01,588:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-22 22:01:01,588:INFO:create_model() successfully completed......................................
2025-03-22 22:01:01,695:INFO:SubProcess create_model() end ==================================
2025-03-22 22:01:01,695:INFO:Creating metrics dataframe
2025-03-22 22:01:01,700:INFO:Initializing Ada Boost Classifier
2025-03-22 22:01:01,700:INFO:Total runtime is 0.12742607593536376 minutes
2025-03-22 22:01:01,702:INFO:SubProcess create_model() called ==================================
2025-03-22 22:01:01,702:INFO:Initializing create_model()
2025-03-22 22:01:01,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:01:01,702:INFO:Checking exceptions
2025-03-22 22:01:01,702:INFO:Importing libraries
2025-03-22 22:01:01,703:INFO:Copying training dataset
2025-03-22 22:01:01,752:INFO:Defining folds
2025-03-22 22:01:01,753:INFO:Declaring metric variables
2025-03-22 22:01:01,755:INFO:Importing untrained model
2025-03-22 22:01:01,758:INFO:Ada Boost Classifier Imported successfully
2025-03-22 22:01:01,762:INFO:Starting cross validation
2025-03-22 22:01:01,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:01:01,831:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:01:01,838:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:01:01,847:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:01:01,857:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:01:01,865:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:01:01,879:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:01:01,891:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:01:01,899:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:01:01,917:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:01:01,935:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:01:03,174:INFO:Calculating mean and std
2025-03-22 22:01:03,175:INFO:Creating metrics dataframe
2025-03-22 22:01:03,176:INFO:Uploading results into container
2025-03-22 22:01:03,177:INFO:Uploading model into container now
2025-03-22 22:01:03,177:INFO:_master_model_container: 9
2025-03-22 22:01:03,177:INFO:_display_container: 2
2025-03-22 22:01:03,177:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-03-22 22:01:03,177:INFO:create_model() successfully completed......................................
2025-03-22 22:01:03,291:INFO:SubProcess create_model() end ==================================
2025-03-22 22:01:03,291:INFO:Creating metrics dataframe
2025-03-22 22:01:03,296:INFO:Initializing Gradient Boosting Classifier
2025-03-22 22:01:03,297:INFO:Total runtime is 0.15403799215952554 minutes
2025-03-22 22:01:03,299:INFO:SubProcess create_model() called ==================================
2025-03-22 22:01:03,299:INFO:Initializing create_model()
2025-03-22 22:01:03,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:01:03,299:INFO:Checking exceptions
2025-03-22 22:01:03,299:INFO:Importing libraries
2025-03-22 22:01:03,299:INFO:Copying training dataset
2025-03-22 22:01:03,348:INFO:Defining folds
2025-03-22 22:01:03,348:INFO:Declaring metric variables
2025-03-22 22:01:03,350:INFO:Importing untrained model
2025-03-22 22:01:03,353:INFO:Gradient Boosting Classifier Imported successfully
2025-03-22 22:01:03,357:INFO:Starting cross validation
2025-03-22 22:01:03,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:01:09,658:INFO:Calculating mean and std
2025-03-22 22:01:09,659:INFO:Creating metrics dataframe
2025-03-22 22:01:09,660:INFO:Uploading results into container
2025-03-22 22:01:09,661:INFO:Uploading model into container now
2025-03-22 22:01:09,661:INFO:_master_model_container: 10
2025-03-22 22:01:09,661:INFO:_display_container: 2
2025-03-22 22:01:09,662:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-22 22:01:09,662:INFO:create_model() successfully completed......................................
2025-03-22 22:01:09,766:INFO:SubProcess create_model() end ==================================
2025-03-22 22:01:09,766:INFO:Creating metrics dataframe
2025-03-22 22:01:09,772:INFO:Initializing Linear Discriminant Analysis
2025-03-22 22:01:09,772:INFO:Total runtime is 0.26195367574691775 minutes
2025-03-22 22:01:09,774:INFO:SubProcess create_model() called ==================================
2025-03-22 22:01:09,774:INFO:Initializing create_model()
2025-03-22 22:01:09,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:01:09,774:INFO:Checking exceptions
2025-03-22 22:01:09,774:INFO:Importing libraries
2025-03-22 22:01:09,774:INFO:Copying training dataset
2025-03-22 22:01:09,826:INFO:Defining folds
2025-03-22 22:01:09,826:INFO:Declaring metric variables
2025-03-22 22:01:09,828:INFO:Importing untrained model
2025-03-22 22:01:09,831:INFO:Linear Discriminant Analysis Imported successfully
2025-03-22 22:01:09,835:INFO:Starting cross validation
2025-03-22 22:01:09,837:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:01:10,051:INFO:Calculating mean and std
2025-03-22 22:01:10,052:INFO:Creating metrics dataframe
2025-03-22 22:01:10,055:INFO:Uploading results into container
2025-03-22 22:01:10,055:INFO:Uploading model into container now
2025-03-22 22:01:10,056:INFO:_master_model_container: 11
2025-03-22 22:01:10,056:INFO:_display_container: 2
2025-03-22 22:01:10,056:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-22 22:01:10,056:INFO:create_model() successfully completed......................................
2025-03-22 22:01:10,161:INFO:SubProcess create_model() end ==================================
2025-03-22 22:01:10,161:INFO:Creating metrics dataframe
2025-03-22 22:01:10,168:INFO:Initializing Extra Trees Classifier
2025-03-22 22:01:10,168:INFO:Total runtime is 0.2685522516568502 minutes
2025-03-22 22:01:10,170:INFO:SubProcess create_model() called ==================================
2025-03-22 22:01:10,170:INFO:Initializing create_model()
2025-03-22 22:01:10,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:01:10,170:INFO:Checking exceptions
2025-03-22 22:01:10,171:INFO:Importing libraries
2025-03-22 22:01:10,171:INFO:Copying training dataset
2025-03-22 22:01:10,222:INFO:Defining folds
2025-03-22 22:01:10,222:INFO:Declaring metric variables
2025-03-22 22:01:10,224:INFO:Importing untrained model
2025-03-22 22:01:10,227:INFO:Extra Trees Classifier Imported successfully
2025-03-22 22:01:10,231:INFO:Starting cross validation
2025-03-22 22:01:10,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:01:10,592:INFO:Calculating mean and std
2025-03-22 22:01:10,593:INFO:Creating metrics dataframe
2025-03-22 22:01:10,594:INFO:Uploading results into container
2025-03-22 22:01:10,594:INFO:Uploading model into container now
2025-03-22 22:01:10,595:INFO:_master_model_container: 12
2025-03-22 22:01:10,595:INFO:_display_container: 2
2025-03-22 22:01:10,595:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-03-22 22:01:10,595:INFO:create_model() successfully completed......................................
2025-03-22 22:01:10,701:INFO:SubProcess create_model() end ==================================
2025-03-22 22:01:10,701:INFO:Creating metrics dataframe
2025-03-22 22:01:10,708:INFO:Initializing Light Gradient Boosting Machine
2025-03-22 22:01:10,708:INFO:Total runtime is 0.27755381266276047 minutes
2025-03-22 22:01:10,710:INFO:SubProcess create_model() called ==================================
2025-03-22 22:01:10,710:INFO:Initializing create_model()
2025-03-22 22:01:10,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:01:10,710:INFO:Checking exceptions
2025-03-22 22:01:10,710:INFO:Importing libraries
2025-03-22 22:01:10,710:INFO:Copying training dataset
2025-03-22 22:01:10,757:INFO:Defining folds
2025-03-22 22:01:10,757:INFO:Declaring metric variables
2025-03-22 22:01:10,760:INFO:Importing untrained model
2025-03-22 22:01:10,762:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-22 22:01:10,766:INFO:Starting cross validation
2025-03-22 22:01:10,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:01:12,054:INFO:Calculating mean and std
2025-03-22 22:01:12,056:INFO:Creating metrics dataframe
2025-03-22 22:01:12,058:INFO:Uploading results into container
2025-03-22 22:01:12,058:INFO:Uploading model into container now
2025-03-22 22:01:12,059:INFO:_master_model_container: 13
2025-03-22 22:01:12,059:INFO:_display_container: 2
2025-03-22 22:01:12,060:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-22 22:01:12,060:INFO:create_model() successfully completed......................................
2025-03-22 22:01:12,193:INFO:SubProcess create_model() end ==================================
2025-03-22 22:01:12,193:INFO:Creating metrics dataframe
2025-03-22 22:01:12,198:INFO:Initializing Dummy Classifier
2025-03-22 22:01:12,198:INFO:Total runtime is 0.30239989360173547 minutes
2025-03-22 22:01:12,200:INFO:SubProcess create_model() called ==================================
2025-03-22 22:01:12,201:INFO:Initializing create_model()
2025-03-22 22:01:12,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021B03C4BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:01:12,201:INFO:Checking exceptions
2025-03-22 22:01:12,201:INFO:Importing libraries
2025-03-22 22:01:12,201:INFO:Copying training dataset
2025-03-22 22:01:12,252:INFO:Defining folds
2025-03-22 22:01:12,252:INFO:Declaring metric variables
2025-03-22 22:01:12,254:INFO:Importing untrained model
2025-03-22 22:01:12,256:INFO:Dummy Classifier Imported successfully
2025-03-22 22:01:12,260:INFO:Starting cross validation
2025-03-22 22:01:12,262:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:01:12,387:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:01:12,396:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:01:12,406:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:01:12,427:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:01:12,430:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:01:12,482:INFO:Calculating mean and std
2025-03-22 22:01:12,483:INFO:Creating metrics dataframe
2025-03-22 22:01:12,484:INFO:Uploading results into container
2025-03-22 22:01:12,484:INFO:Uploading model into container now
2025-03-22 22:01:12,485:INFO:_master_model_container: 14
2025-03-22 22:01:12,485:INFO:_display_container: 2
2025-03-22 22:01:12,485:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-03-22 22:01:12,485:INFO:create_model() successfully completed......................................
2025-03-22 22:01:12,592:INFO:SubProcess create_model() end ==================================
2025-03-22 22:01:12,592:INFO:Creating metrics dataframe
2025-03-22 22:01:12,601:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-22 22:01:12,606:INFO:Initializing create_model()
2025-03-22 22:01:12,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:01:12,606:INFO:Checking exceptions
2025-03-22 22:01:12,607:INFO:Importing libraries
2025-03-22 22:01:12,607:INFO:Copying training dataset
2025-03-22 22:01:12,656:INFO:Defining folds
2025-03-22 22:01:12,656:INFO:Declaring metric variables
2025-03-22 22:01:12,657:INFO:Importing untrained model
2025-03-22 22:01:12,657:INFO:Declaring custom model
2025-03-22 22:01:12,657:INFO:Logistic Regression Imported successfully
2025-03-22 22:01:12,658:INFO:Cross validation set to False
2025-03-22 22:01:12,658:INFO:Fitting Model
2025-03-22 22:01:12,727:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 22:01:12,727:INFO:create_model() successfully completed......................................
2025-03-22 22:01:12,836:INFO:Creating Dashboard logs
2025-03-22 22:01:12,839:INFO:Model: Logistic Regression
2025-03-22 22:01:12,882:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 22:01:12,984:INFO:Initializing predict_model()
2025-03-22 22:01:12,984:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021B14474160>)
2025-03-22 22:01:12,984:INFO:Checking exceptions
2025-03-22 22:01:12,984:INFO:Preloading libraries
2025-03-22 22:01:14,410:INFO:Creating Dashboard logs
2025-03-22 22:01:14,412:INFO:Model: Ridge Classifier
2025-03-22 22:01:14,448:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2025-03-22 22:01:14,679:INFO:Creating Dashboard logs
2025-03-22 22:01:14,681:INFO:Model: Light Gradient Boosting Machine
2025-03-22 22:01:14,713:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-22 22:01:14,955:INFO:Creating Dashboard logs
2025-03-22 22:01:14,957:INFO:Model: Extra Trees Classifier
2025-03-22 22:01:14,996:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 22:01:15,233:INFO:Creating Dashboard logs
2025-03-22 22:01:15,235:INFO:Model: Random Forest Classifier
2025-03-22 22:01:15,271:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 22:01:15,514:INFO:Creating Dashboard logs
2025-03-22 22:01:15,516:INFO:Model: Ada Boost Classifier
2025-03-22 22:01:15,548:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 123}
2025-03-22 22:01:15,776:INFO:Creating Dashboard logs
2025-03-22 22:01:15,778:INFO:Model: Gradient Boosting Classifier
2025-03-22 22:01:15,815:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 22:01:16,054:INFO:Creating Dashboard logs
2025-03-22 22:01:16,056:INFO:Model: SVM - Linear Kernel
2025-03-22 22:01:16,089:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 22:01:16,331:INFO:Creating Dashboard logs
2025-03-22 22:01:16,334:INFO:Model: Linear Discriminant Analysis
2025-03-22 22:01:16,369:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-03-22 22:01:16,595:INFO:Creating Dashboard logs
2025-03-22 22:01:16,597:INFO:Model: K Neighbors Classifier
2025-03-22 22:01:16,629:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-22 22:01:16,859:INFO:Creating Dashboard logs
2025-03-22 22:01:16,861:INFO:Model: Decision Tree Classifier
2025-03-22 22:01:16,896:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 123, 'splitter': 'best'}
2025-03-22 22:01:17,126:INFO:Creating Dashboard logs
2025-03-22 22:01:17,128:INFO:Model: Quadratic Discriminant Analysis
2025-03-22 22:01:17,163:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-03-22 22:01:17,389:INFO:Creating Dashboard logs
2025-03-22 22:01:17,391:INFO:Model: Naive Bayes
2025-03-22 22:01:17,427:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-03-22 22:01:17,651:INFO:Creating Dashboard logs
2025-03-22 22:01:17,653:INFO:Model: Dummy Classifier
2025-03-22 22:01:17,685:INFO:Logged params: {'constant': None, 'random_state': 123, 'strategy': 'prior'}
2025-03-22 22:01:17,912:INFO:_master_model_container: 14
2025-03-22 22:01:17,912:INFO:_display_container: 2
2025-03-22 22:01:17,912:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 22:01:17,912:INFO:compare_models() successfully completed......................................
2025-03-22 22:01:36,916:INFO:Initializing create_model()
2025-03-22 22:01:36,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:01:36,916:INFO:Checking exceptions
2025-03-22 22:01:36,925:INFO:Importing libraries
2025-03-22 22:01:36,925:INFO:Copying training dataset
2025-03-22 22:01:36,970:INFO:Defining folds
2025-03-22 22:01:36,970:INFO:Declaring metric variables
2025-03-22 22:01:36,972:INFO:Importing untrained model
2025-03-22 22:01:36,974:INFO:Logistic Regression Imported successfully
2025-03-22 22:01:36,977:INFO:Starting cross validation
2025-03-22 22:01:36,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:01:37,216:INFO:Calculating mean and std
2025-03-22 22:01:37,217:INFO:Creating metrics dataframe
2025-03-22 22:01:37,220:INFO:Finalizing model
2025-03-22 22:01:37,297:INFO:Creating Dashboard logs
2025-03-22 22:01:37,299:INFO:Model: Logistic Regression
2025-03-22 22:01:37,345:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 22:01:37,442:INFO:Initializing predict_model()
2025-03-22 22:01:37,443:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021B14627AC0>)
2025-03-22 22:01:37,443:INFO:Checking exceptions
2025-03-22 22:01:37,443:INFO:Preloading libraries
2025-03-22 22:01:38,161:INFO:Uploading results into container
2025-03-22 22:01:38,161:INFO:Uploading model into container now
2025-03-22 22:01:38,167:INFO:_master_model_container: 15
2025-03-22 22:01:38,167:INFO:_display_container: 3
2025-03-22 22:01:38,168:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 22:01:38,168:INFO:create_model() successfully completed......................................
2025-03-22 22:01:50,507:INFO:Initializing plot_model()
2025-03-22 22:01:50,507:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, system=True)
2025-03-22 22:01:50,507:INFO:Checking exceptions
2025-03-22 22:01:50,529:INFO:Preloading libraries
2025-03-22 22:01:50,529:INFO:Copying training dataset
2025-03-22 22:01:50,529:INFO:Plot type: confusion_matrix
2025-03-22 22:01:51,038:INFO:Fitting Model
2025-03-22 22:01:51,038:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 22:01:51,039:INFO:Scoring test/hold-out set
2025-03-22 22:01:51,140:INFO:Visual Rendered Successfully
2025-03-22 22:01:51,247:INFO:plot_model() successfully completed......................................
2025-03-22 22:02:02,219:INFO:Initializing evaluate_model()
2025-03-22 22:02:02,219:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-22 22:02:02,248:INFO:Initializing plot_model()
2025-03-22 22:02:02,248:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, system=True)
2025-03-22 22:02:02,248:INFO:Checking exceptions
2025-03-22 22:02:02,264:INFO:Preloading libraries
2025-03-22 22:02:02,264:INFO:Copying training dataset
2025-03-22 22:02:02,265:INFO:Plot type: pipeline
2025-03-22 22:02:02,317:INFO:Visual Rendered Successfully
2025-03-22 22:02:02,422:INFO:plot_model() successfully completed......................................
2025-03-22 22:02:04,863:INFO:Initializing plot_model()
2025-03-22 22:02:04,863:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, system=True)
2025-03-22 22:02:04,863:INFO:Checking exceptions
2025-03-22 22:02:04,881:INFO:Preloading libraries
2025-03-22 22:02:04,881:INFO:Copying training dataset
2025-03-22 22:02:04,881:INFO:Plot type: auc
2025-03-22 22:02:05,336:INFO:Fitting Model
2025-03-22 22:02:05,336:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 22:02:05,336:INFO:Scoring test/hold-out set
2025-03-22 22:02:05,440:INFO:Visual Rendered Successfully
2025-03-22 22:02:05,543:INFO:plot_model() successfully completed......................................
2025-03-22 22:02:07,160:INFO:Initializing plot_model()
2025-03-22 22:02:07,160:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021A9219F8B0>, system=True)
2025-03-22 22:02:07,160:INFO:Checking exceptions
2025-03-22 22:02:07,177:INFO:Preloading libraries
2025-03-22 22:02:07,177:INFO:Copying training dataset
2025-03-22 22:02:07,177:INFO:Plot type: confusion_matrix
2025-03-22 22:02:07,625:INFO:Fitting Model
2025-03-22 22:02:07,625:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-03-22 22:02:07,625:INFO:Scoring test/hold-out set
2025-03-22 22:02:07,696:INFO:Visual Rendered Successfully
2025-03-22 22:02:07,803:INFO:plot_model() successfully completed......................................
2025-03-22 22:05:52,422:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_9a007f462e1c4d27a289a6b6a2567840
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,422:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_b83b83b605164e789209646ae641bc06_ebea63fe2e62475db69ad96bd8d44ed9
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,422:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_ae1fccab0d2e4adab339801b5f58aede
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,422:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_1bbdc92f401e434d84858c68c3ee9d66_6da77aa9e34542468ab8e32995550774
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,423:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_83cc7282cc754b3089c1b0babe5da0aa
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,423:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_83660e9d4ae64aa2a4f1764a1d791039_ea3d4a36e2884f64900da802af9933a7
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,423:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_1006289f1a7b418589db894ec6ca40ce
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,423:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_e416040cb7924f88a95cbb231183212d_a9b3e48fc7ca41bf9b71886964080222
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,423:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_b6494e4d787541119b0888c01da9f1ad
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,424:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_7c8a75ea13934e488e149b08a69a2790_93a39ea3af134b4c840ce415be926bcb
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,424:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_cb1861a35e33488199d80b845d8faa0d
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,424:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_4f085549f16048b5b3e4c673ff2aa941_c49ba12ae7d441bf87d8902a06c1c73f
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,424:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_0c52ed497b9546f08ebe160158db8649
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,424:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_c021decf93be40d18cbfec1cbf0f99ff_6cfe917a1fb14796bdf8ec4adb1f606e
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,424:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_10220e18d299464194781e93b284930d
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,425:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_bb174dafccb64a948ddfa872332d7dbb_7c366aca973f42ddbe7a0a943c37e370
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,425:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_feccc11a9b174be59fb5ab2569b74bd9
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,425:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_5a66586b04994c5093cdac1c8081e475_74eef7d6ec3f4c93a8642886ddcdda9f
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,425:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_60cf093158d44d53b267b3656b4839ba
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,425:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_b65f0738eff341299ca04ad5bfad5308_7efb943f63234a70a6fc2ba3360fe749
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,425:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_01b372ea126142218e640c5e41add3a4
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,425:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_b06ae24fdecb406fb779aa4d310d10ad_ab7fc590a86d40959fa10b8099e92d5e
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,426:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_0bfff3a40ce24c97b91061d1ca84606e
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,426:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_312c44ea085443cfa639735e45638827_7b0758a3755f4ebf978f9429a9e82844
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,426:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_b343c61e744f410b8095c45d0fbcf52f
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,426:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_52ec592771aa4532988844aa4b1878a8_2f745379449c42789f82be3dbd8fa9ad
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,426:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_ee0c12bb9c034601849a6c846f4c61a1
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,426:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_0f2ee659944142aea47803731ba85086_51acaa6d9063401d91c319216e3b7982
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,426:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_87fd85fd87cd477a912ab18ce81130b9
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:05:52,427:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\jeiso\AppData\Local\Temp\joblib_memmapping_folder_18300_24d803c1ed2e4ed39335c4398fdf9ed2_864c75f6268146629c7af2f9c76f60e2
  warnings.warn("Failed to delete temporary folder: {}"

2025-03-22 22:06:03,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:06:03,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:06:03,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:06:03,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:09:46,163:INFO:PyCaret ClassificationExperiment
2025-03-22 22:09:46,163:INFO:Logging name: Mentalrisk_task1
2025-03-22 22:09:46,163:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-22 22:09:46,163:INFO:version 3.3.2
2025-03-22 22:09:46,163:INFO:Initializing setup()
2025-03-22 22:09:46,163:INFO:self.USI: ce8b
2025-03-22 22:09:46,163:INFO:self._variable_keys: {'is_multiclass', 'memory', 'n_jobs_param', 'log_plots_param', 'data', 'X_train', 'exp_id', 'seed', 'target_param', 'fold_shuffle_param', 'html_param', 'fix_imbalance', 'fold_generator', 'y', 'gpu_param', 'y_test', 'idx', 'pipeline', 'logging_param', 'gpu_n_jobs_param', '_ml_usecase', 'USI', 'X_test', 'X', 'fold_groups_param', '_available_plots', 'y_train', 'exp_name_log'}
2025-03-22 22:09:46,163:INFO:Checking environment
2025-03-22 22:09:46,163:INFO:python_version: 3.10.11
2025-03-22 22:09:46,163:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-03-22 22:09:46,163:INFO:machine: AMD64
2025-03-22 22:09:46,164:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-22 22:09:46,167:INFO:Memory: svmem(total=34188517376, available=17879986176, percent=47.7, used=16308531200, free=17879986176)
2025-03-22 22:09:46,167:INFO:Physical Core: 12
2025-03-22 22:09:46,167:INFO:Logical Core: 20
2025-03-22 22:09:46,167:INFO:Checking libraries
2025-03-22 22:09:46,167:INFO:System:
2025-03-22 22:09:46,167:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-03-22 22:09:46,167:INFO:executable: C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\Scripts\python.exe
2025-03-22 22:09:46,167:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-22 22:09:46,167:INFO:PyCaret required dependencies:
2025-03-22 22:09:46,205:INFO:                 pip: 24.2
2025-03-22 22:09:46,205:INFO:          setuptools: 73.0.1
2025-03-22 22:09:46,205:INFO:             pycaret: 3.3.2
2025-03-22 22:09:46,205:INFO:             IPython: 8.34.0
2025-03-22 22:09:46,205:INFO:          ipywidgets: 8.1.5
2025-03-22 22:09:46,205:INFO:                tqdm: 4.67.1
2025-03-22 22:09:46,205:INFO:               numpy: 1.26.4
2025-03-22 22:09:46,205:INFO:              pandas: 2.1.4
2025-03-22 22:09:46,205:INFO:              jinja2: 3.1.6
2025-03-22 22:09:46,205:INFO:               scipy: 1.11.4
2025-03-22 22:09:46,205:INFO:              joblib: 1.3.2
2025-03-22 22:09:46,205:INFO:             sklearn: 1.4.2
2025-03-22 22:09:46,205:INFO:                pyod: 2.0.3
2025-03-22 22:09:46,205:INFO:            imblearn: 0.13.0
2025-03-22 22:09:46,205:INFO:   category_encoders: 2.7.0
2025-03-22 22:09:46,205:INFO:            lightgbm: 4.6.0
2025-03-22 22:09:46,205:INFO:               numba: 0.61.0
2025-03-22 22:09:46,205:INFO:            requests: 2.32.3
2025-03-22 22:09:46,205:INFO:          matplotlib: 3.7.5
2025-03-22 22:09:46,205:INFO:          scikitplot: 0.3.7
2025-03-22 22:09:46,205:INFO:         yellowbrick: 1.5
2025-03-22 22:09:46,205:INFO:              plotly: 5.24.1
2025-03-22 22:09:46,205:INFO:    plotly-resampler: Not installed
2025-03-22 22:09:46,205:INFO:             kaleido: 0.2.1
2025-03-22 22:09:46,205:INFO:           schemdraw: 0.15
2025-03-22 22:09:46,205:INFO:         statsmodels: 0.14.4
2025-03-22 22:09:46,205:INFO:              sktime: 0.26.0
2025-03-22 22:09:46,205:INFO:               tbats: 1.1.3
2025-03-22 22:09:46,205:INFO:            pmdarima: 2.0.4
2025-03-22 22:09:46,205:INFO:              psutil: 7.0.0
2025-03-22 22:09:46,205:INFO:          markupsafe: 3.0.2
2025-03-22 22:09:46,205:INFO:             pickle5: Not installed
2025-03-22 22:09:46,205:INFO:         cloudpickle: 3.1.1
2025-03-22 22:09:46,205:INFO:         deprecation: 2.1.0
2025-03-22 22:09:46,205:INFO:              xxhash: 3.5.0
2025-03-22 22:09:46,205:INFO:           wurlitzer: Not installed
2025-03-22 22:09:46,205:INFO:PyCaret optional dependencies:
2025-03-22 22:09:46,216:INFO:                shap: Not installed
2025-03-22 22:09:46,217:INFO:           interpret: Not installed
2025-03-22 22:09:46,217:INFO:                umap: Not installed
2025-03-22 22:09:46,217:INFO:     ydata_profiling: Not installed
2025-03-22 22:09:46,217:INFO:  explainerdashboard: Not installed
2025-03-22 22:09:46,217:INFO:             autoviz: Not installed
2025-03-22 22:09:46,217:INFO:           fairlearn: Not installed
2025-03-22 22:09:46,217:INFO:          deepchecks: Not installed
2025-03-22 22:09:46,217:INFO:             xgboost: Not installed
2025-03-22 22:09:46,217:INFO:            catboost: Not installed
2025-03-22 22:09:46,217:INFO:              kmodes: Not installed
2025-03-22 22:09:46,217:INFO:             mlxtend: Not installed
2025-03-22 22:09:46,217:INFO:       statsforecast: Not installed
2025-03-22 22:09:46,217:INFO:        tune_sklearn: Not installed
2025-03-22 22:09:46,217:INFO:                 ray: Not installed
2025-03-22 22:09:46,217:INFO:            hyperopt: Not installed
2025-03-22 22:09:46,217:INFO:              optuna: Not installed
2025-03-22 22:09:46,217:INFO:               skopt: Not installed
2025-03-22 22:09:46,217:INFO:              mlflow: 2.16.0
2025-03-22 22:09:46,217:INFO:              gradio: Not installed
2025-03-22 22:09:46,217:INFO:             fastapi: Not installed
2025-03-22 22:09:46,217:INFO:             uvicorn: Not installed
2025-03-22 22:09:46,217:INFO:              m2cgen: Not installed
2025-03-22 22:09:46,217:INFO:           evidently: Not installed
2025-03-22 22:09:46,217:INFO:               fugue: Not installed
2025-03-22 22:09:46,217:INFO:           streamlit: Not installed
2025-03-22 22:09:46,217:INFO:             prophet: Not installed
2025-03-22 22:09:46,217:INFO:None
2025-03-22 22:09:46,217:INFO:Set up data.
2025-03-22 22:09:46,277:INFO:Set up folding strategy.
2025-03-22 22:09:46,277:INFO:Set up train/test split.
2025-03-22 22:09:46,312:INFO:Set up index.
2025-03-22 22:09:46,312:INFO:Assigning column types.
2025-03-22 22:09:46,349:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-22 22:09:46,370:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 22:09:46,372:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:09:46,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 22:09:46,412:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:09:46,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,425:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-22 22:09:46,448:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:09:46,463:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,486:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:09:46,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,499:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-22 22:09:46,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:46,572:INFO:Preparing preprocessing pipeline...
2025-03-22 22:09:46,577:INFO:Set up simple imputation.
2025-03-22 22:09:46,850:INFO:Finished creating preprocessing pipeline.
2025-03-22 22:09:46,854:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 22:09:46,854:INFO:Creating final display dataframe.
2025-03-22 22:09:47,536:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             level
2                   Target type            Binary
3           Original data shape        (462, 769)
4        Transformed data shape        (462, 769)
5   Transformed train set shape        (369, 769)
6    Transformed test set shape         (93, 769)
7              Numeric features               768
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment      MlflowLogger
17              Experiment Name  Mentalrisk_task1
18                          USI              ce8b
2025-03-22 22:09:47,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:47,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:47,615:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:47,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:09:47,616:INFO:Logging experiment in loggers
2025-03-22 22:09:47,785:INFO:SubProcess save_model() called ==================================
2025-03-22 22:09:47,792:INFO:Initializing save_model()
2025-03-22 22:09:47,793:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\jeiso\AppData\Local\Temp\tmp4s0e0hu1\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 22:09:47,793:INFO:Adding model into prep_pipe
2025-03-22 22:09:47,793:WARNING:Only Model saved as it was a pipeline.
2025-03-22 22:09:47,798:INFO:C:\Users\jeiso\AppData\Local\Temp\tmp4s0e0hu1\Transformation Pipeline.pkl saved in current working directory
2025-03-22 22:09:47,801:INFO:Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 22:09:47,801:INFO:save_model() successfully completed......................................
2025-03-22 22:09:47,907:INFO:SubProcess save_model() end ==================================
2025-03-22 22:09:47,931:INFO:setup() successfully completed in 1.45s...............
2025-03-22 22:09:53,691:INFO:Initializing compare_models()
2025-03-22 22:09:53,691:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, include=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-22 22:09:53,691:INFO:Checking exceptions
2025-03-22 22:09:53,721:INFO:Preparing display monitor
2025-03-22 22:09:53,735:INFO:Initializing Logistic Regression
2025-03-22 22:09:53,735:INFO:Total runtime is 0.0 minutes
2025-03-22 22:09:53,737:INFO:SubProcess create_model() called ==================================
2025-03-22 22:09:53,738:INFO:Initializing create_model()
2025-03-22 22:09:53,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:09:53,738:INFO:Checking exceptions
2025-03-22 22:09:53,738:INFO:Importing libraries
2025-03-22 22:09:53,738:INFO:Copying training dataset
2025-03-22 22:09:53,782:INFO:Defining folds
2025-03-22 22:09:53,782:INFO:Declaring metric variables
2025-03-22 22:09:53,785:INFO:Importing untrained model
2025-03-22 22:09:53,787:INFO:Logistic Regression Imported successfully
2025-03-22 22:09:53,791:INFO:Starting cross validation
2025-03-22 22:09:53,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:09:56,218:INFO:Calculating mean and std
2025-03-22 22:09:56,219:INFO:Creating metrics dataframe
2025-03-22 22:09:56,220:INFO:Uploading results into container
2025-03-22 22:09:56,221:INFO:Uploading model into container now
2025-03-22 22:09:56,221:INFO:_master_model_container: 1
2025-03-22 22:09:56,221:INFO:_display_container: 2
2025-03-22 22:09:56,221:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 22:09:56,221:INFO:create_model() successfully completed......................................
2025-03-22 22:09:56,324:INFO:SubProcess create_model() end ==================================
2025-03-22 22:09:56,324:INFO:Creating metrics dataframe
2025-03-22 22:09:56,328:INFO:Initializing K Neighbors Classifier
2025-03-22 22:09:56,328:INFO:Total runtime is 0.04322717984517415 minutes
2025-03-22 22:09:56,331:INFO:SubProcess create_model() called ==================================
2025-03-22 22:09:56,331:INFO:Initializing create_model()
2025-03-22 22:09:56,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:09:56,331:INFO:Checking exceptions
2025-03-22 22:09:56,331:INFO:Importing libraries
2025-03-22 22:09:56,331:INFO:Copying training dataset
2025-03-22 22:09:56,379:INFO:Defining folds
2025-03-22 22:09:56,379:INFO:Declaring metric variables
2025-03-22 22:09:56,382:INFO:Importing untrained model
2025-03-22 22:09:56,384:INFO:K Neighbors Classifier Imported successfully
2025-03-22 22:09:56,389:INFO:Starting cross validation
2025-03-22 22:09:56,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:09:58,373:INFO:Calculating mean and std
2025-03-22 22:09:58,374:INFO:Creating metrics dataframe
2025-03-22 22:09:58,375:INFO:Uploading results into container
2025-03-22 22:09:58,376:INFO:Uploading model into container now
2025-03-22 22:09:58,376:INFO:_master_model_container: 2
2025-03-22 22:09:58,376:INFO:_display_container: 2
2025-03-22 22:09:58,377:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-22 22:09:58,377:INFO:create_model() successfully completed......................................
2025-03-22 22:09:58,484:INFO:SubProcess create_model() end ==================================
2025-03-22 22:09:58,484:INFO:Creating metrics dataframe
2025-03-22 22:09:58,488:INFO:Initializing Naive Bayes
2025-03-22 22:09:58,488:INFO:Total runtime is 0.07921713590621948 minutes
2025-03-22 22:09:58,490:INFO:SubProcess create_model() called ==================================
2025-03-22 22:09:58,490:INFO:Initializing create_model()
2025-03-22 22:09:58,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:09:58,491:INFO:Checking exceptions
2025-03-22 22:09:58,491:INFO:Importing libraries
2025-03-22 22:09:58,491:INFO:Copying training dataset
2025-03-22 22:09:58,544:INFO:Defining folds
2025-03-22 22:09:58,544:INFO:Declaring metric variables
2025-03-22 22:09:58,547:INFO:Importing untrained model
2025-03-22 22:09:58,549:INFO:Naive Bayes Imported successfully
2025-03-22 22:09:58,553:INFO:Starting cross validation
2025-03-22 22:09:58,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:09:58,737:INFO:Calculating mean and std
2025-03-22 22:09:58,738:INFO:Creating metrics dataframe
2025-03-22 22:09:58,739:INFO:Uploading results into container
2025-03-22 22:09:58,739:INFO:Uploading model into container now
2025-03-22 22:09:58,740:INFO:_master_model_container: 3
2025-03-22 22:09:58,740:INFO:_display_container: 2
2025-03-22 22:09:58,740:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-22 22:09:58,740:INFO:create_model() successfully completed......................................
2025-03-22 22:09:58,843:INFO:SubProcess create_model() end ==================================
2025-03-22 22:09:58,843:INFO:Creating metrics dataframe
2025-03-22 22:09:58,847:INFO:Initializing Decision Tree Classifier
2025-03-22 22:09:58,847:INFO:Total runtime is 0.08520809014638266 minutes
2025-03-22 22:09:58,850:INFO:SubProcess create_model() called ==================================
2025-03-22 22:09:58,850:INFO:Initializing create_model()
2025-03-22 22:09:58,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:09:58,850:INFO:Checking exceptions
2025-03-22 22:09:58,850:INFO:Importing libraries
2025-03-22 22:09:58,850:INFO:Copying training dataset
2025-03-22 22:09:58,899:INFO:Defining folds
2025-03-22 22:09:58,899:INFO:Declaring metric variables
2025-03-22 22:09:58,902:INFO:Importing untrained model
2025-03-22 22:09:58,904:INFO:Decision Tree Classifier Imported successfully
2025-03-22 22:09:58,907:INFO:Starting cross validation
2025-03-22 22:09:58,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:09:59,226:INFO:Calculating mean and std
2025-03-22 22:09:59,227:INFO:Creating metrics dataframe
2025-03-22 22:09:59,228:INFO:Uploading results into container
2025-03-22 22:09:59,228:INFO:Uploading model into container now
2025-03-22 22:09:59,229:INFO:_master_model_container: 4
2025-03-22 22:09:59,229:INFO:_display_container: 2
2025-03-22 22:09:59,229:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-03-22 22:09:59,229:INFO:create_model() successfully completed......................................
2025-03-22 22:09:59,332:INFO:SubProcess create_model() end ==================================
2025-03-22 22:09:59,332:INFO:Creating metrics dataframe
2025-03-22 22:09:59,336:INFO:Initializing SVM - Linear Kernel
2025-03-22 22:09:59,336:INFO:Total runtime is 0.09336169560750326 minutes
2025-03-22 22:09:59,338:INFO:SubProcess create_model() called ==================================
2025-03-22 22:09:59,339:INFO:Initializing create_model()
2025-03-22 22:09:59,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:09:59,339:INFO:Checking exceptions
2025-03-22 22:09:59,339:INFO:Importing libraries
2025-03-22 22:09:59,339:INFO:Copying training dataset
2025-03-22 22:09:59,389:INFO:Defining folds
2025-03-22 22:09:59,389:INFO:Declaring metric variables
2025-03-22 22:09:59,391:INFO:Importing untrained model
2025-03-22 22:09:59,393:INFO:SVM - Linear Kernel Imported successfully
2025-03-22 22:09:59,397:INFO:Starting cross validation
2025-03-22 22:09:59,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:09:59,523:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:09:59,536:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:09:59,546:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:09:59,599:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:09:59,607:INFO:Calculating mean and std
2025-03-22 22:09:59,608:INFO:Creating metrics dataframe
2025-03-22 22:09:59,609:INFO:Uploading results into container
2025-03-22 22:09:59,609:INFO:Uploading model into container now
2025-03-22 22:09:59,610:INFO:_master_model_container: 5
2025-03-22 22:09:59,610:INFO:_display_container: 2
2025-03-22 22:09:59,610:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-22 22:09:59,610:INFO:create_model() successfully completed......................................
2025-03-22 22:09:59,719:INFO:SubProcess create_model() end ==================================
2025-03-22 22:09:59,719:INFO:Creating metrics dataframe
2025-03-22 22:09:59,723:INFO:Initializing Ridge Classifier
2025-03-22 22:09:59,723:INFO:Total runtime is 0.09981267054875692 minutes
2025-03-22 22:09:59,725:INFO:SubProcess create_model() called ==================================
2025-03-22 22:09:59,726:INFO:Initializing create_model()
2025-03-22 22:09:59,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:09:59,726:INFO:Checking exceptions
2025-03-22 22:09:59,726:INFO:Importing libraries
2025-03-22 22:09:59,726:INFO:Copying training dataset
2025-03-22 22:09:59,773:INFO:Defining folds
2025-03-22 22:09:59,773:INFO:Declaring metric variables
2025-03-22 22:09:59,775:INFO:Importing untrained model
2025-03-22 22:09:59,778:INFO:Ridge Classifier Imported successfully
2025-03-22 22:09:59,782:INFO:Starting cross validation
2025-03-22 22:09:59,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:09:59,971:INFO:Calculating mean and std
2025-03-22 22:09:59,972:INFO:Creating metrics dataframe
2025-03-22 22:09:59,973:INFO:Uploading results into container
2025-03-22 22:09:59,974:INFO:Uploading model into container now
2025-03-22 22:09:59,974:INFO:_master_model_container: 6
2025-03-22 22:09:59,974:INFO:_display_container: 2
2025-03-22 22:09:59,974:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-03-22 22:09:59,975:INFO:create_model() successfully completed......................................
2025-03-22 22:10:00,078:INFO:SubProcess create_model() end ==================================
2025-03-22 22:10:00,079:INFO:Creating metrics dataframe
2025-03-22 22:10:00,083:INFO:Initializing Random Forest Classifier
2025-03-22 22:10:00,084:INFO:Total runtime is 0.10581354300181071 minutes
2025-03-22 22:10:00,086:INFO:SubProcess create_model() called ==================================
2025-03-22 22:10:00,086:INFO:Initializing create_model()
2025-03-22 22:10:00,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:10:00,086:INFO:Checking exceptions
2025-03-22 22:10:00,086:INFO:Importing libraries
2025-03-22 22:10:00,086:INFO:Copying training dataset
2025-03-22 22:10:00,133:INFO:Defining folds
2025-03-22 22:10:00,133:INFO:Declaring metric variables
2025-03-22 22:10:00,136:INFO:Importing untrained model
2025-03-22 22:10:00,138:INFO:Random Forest Classifier Imported successfully
2025-03-22 22:10:00,141:INFO:Starting cross validation
2025-03-22 22:10:00,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:10:00,713:INFO:Calculating mean and std
2025-03-22 22:10:00,714:INFO:Creating metrics dataframe
2025-03-22 22:10:00,715:INFO:Uploading results into container
2025-03-22 22:10:00,716:INFO:Uploading model into container now
2025-03-22 22:10:00,716:INFO:_master_model_container: 7
2025-03-22 22:10:00,716:INFO:_display_container: 2
2025-03-22 22:10:00,716:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 22:10:00,716:INFO:create_model() successfully completed......................................
2025-03-22 22:10:00,820:INFO:SubProcess create_model() end ==================================
2025-03-22 22:10:00,820:INFO:Creating metrics dataframe
2025-03-22 22:10:00,825:INFO:Initializing Quadratic Discriminant Analysis
2025-03-22 22:10:00,825:INFO:Total runtime is 0.11817052761713664 minutes
2025-03-22 22:10:00,827:INFO:SubProcess create_model() called ==================================
2025-03-22 22:10:00,827:INFO:Initializing create_model()
2025-03-22 22:10:00,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:10:00,827:INFO:Checking exceptions
2025-03-22 22:10:00,828:INFO:Importing libraries
2025-03-22 22:10:00,828:INFO:Copying training dataset
2025-03-22 22:10:00,875:INFO:Defining folds
2025-03-22 22:10:00,875:INFO:Declaring metric variables
2025-03-22 22:10:00,877:INFO:Importing untrained model
2025-03-22 22:10:00,879:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-22 22:10:00,883:INFO:Starting cross validation
2025-03-22 22:10:00,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:10:01,015:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:10:01,026:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:10:01,040:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:10:01,046:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:10:01,067:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:10:01,068:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:10:01,083:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:10:01,094:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:10:01,099:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:10:01,140:INFO:Calculating mean and std
2025-03-22 22:10:01,141:INFO:Creating metrics dataframe
2025-03-22 22:10:01,142:INFO:Uploading results into container
2025-03-22 22:10:01,142:INFO:Uploading model into container now
2025-03-22 22:10:01,143:INFO:_master_model_container: 8
2025-03-22 22:10:01,143:INFO:_display_container: 2
2025-03-22 22:10:01,143:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-22 22:10:01,143:INFO:create_model() successfully completed......................................
2025-03-22 22:10:01,248:INFO:SubProcess create_model() end ==================================
2025-03-22 22:10:01,248:INFO:Creating metrics dataframe
2025-03-22 22:10:01,253:INFO:Initializing Ada Boost Classifier
2025-03-22 22:10:01,253:INFO:Total runtime is 0.1253068486849467 minutes
2025-03-22 22:10:01,255:INFO:SubProcess create_model() called ==================================
2025-03-22 22:10:01,255:INFO:Initializing create_model()
2025-03-22 22:10:01,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:10:01,255:INFO:Checking exceptions
2025-03-22 22:10:01,255:INFO:Importing libraries
2025-03-22 22:10:01,255:INFO:Copying training dataset
2025-03-22 22:10:01,303:INFO:Defining folds
2025-03-22 22:10:01,304:INFO:Declaring metric variables
2025-03-22 22:10:01,306:INFO:Importing untrained model
2025-03-22 22:10:01,308:INFO:Ada Boost Classifier Imported successfully
2025-03-22 22:10:01,313:INFO:Starting cross validation
2025-03-22 22:10:01,314:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:10:01,377:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:10:01,398:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:10:01,405:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:10:01,411:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:10:01,422:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:10:01,431:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:10:01,439:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:10:01,453:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:10:01,465:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:10:01,473:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:10:02,632:INFO:Calculating mean and std
2025-03-22 22:10:02,633:INFO:Creating metrics dataframe
2025-03-22 22:10:02,634:INFO:Uploading results into container
2025-03-22 22:10:02,635:INFO:Uploading model into container now
2025-03-22 22:10:02,635:INFO:_master_model_container: 9
2025-03-22 22:10:02,635:INFO:_display_container: 2
2025-03-22 22:10:02,635:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-03-22 22:10:02,635:INFO:create_model() successfully completed......................................
2025-03-22 22:10:02,735:INFO:SubProcess create_model() end ==================================
2025-03-22 22:10:02,735:INFO:Creating metrics dataframe
2025-03-22 22:10:02,740:INFO:Initializing Gradient Boosting Classifier
2025-03-22 22:10:02,740:INFO:Total runtime is 0.15009658336639406 minutes
2025-03-22 22:10:02,742:INFO:SubProcess create_model() called ==================================
2025-03-22 22:10:02,743:INFO:Initializing create_model()
2025-03-22 22:10:02,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:10:02,743:INFO:Checking exceptions
2025-03-22 22:10:02,743:INFO:Importing libraries
2025-03-22 22:10:02,743:INFO:Copying training dataset
2025-03-22 22:10:02,790:INFO:Defining folds
2025-03-22 22:10:02,790:INFO:Declaring metric variables
2025-03-22 22:10:02,793:INFO:Importing untrained model
2025-03-22 22:10:02,795:INFO:Gradient Boosting Classifier Imported successfully
2025-03-22 22:10:02,798:INFO:Starting cross validation
2025-03-22 22:10:02,800:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:10:08,784:INFO:Calculating mean and std
2025-03-22 22:10:08,785:INFO:Creating metrics dataframe
2025-03-22 22:10:08,786:INFO:Uploading results into container
2025-03-22 22:10:08,787:INFO:Uploading model into container now
2025-03-22 22:10:08,787:INFO:_master_model_container: 10
2025-03-22 22:10:08,787:INFO:_display_container: 2
2025-03-22 22:10:08,787:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-22 22:10:08,787:INFO:create_model() successfully completed......................................
2025-03-22 22:10:08,889:INFO:SubProcess create_model() end ==================================
2025-03-22 22:10:08,890:INFO:Creating metrics dataframe
2025-03-22 22:10:08,895:INFO:Initializing Linear Discriminant Analysis
2025-03-22 22:10:08,895:INFO:Total runtime is 0.2526749809583028 minutes
2025-03-22 22:10:08,897:INFO:SubProcess create_model() called ==================================
2025-03-22 22:10:08,898:INFO:Initializing create_model()
2025-03-22 22:10:08,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:10:08,898:INFO:Checking exceptions
2025-03-22 22:10:08,898:INFO:Importing libraries
2025-03-22 22:10:08,898:INFO:Copying training dataset
2025-03-22 22:10:08,952:INFO:Defining folds
2025-03-22 22:10:08,952:INFO:Declaring metric variables
2025-03-22 22:10:08,955:INFO:Importing untrained model
2025-03-22 22:10:08,957:INFO:Linear Discriminant Analysis Imported successfully
2025-03-22 22:10:08,963:INFO:Starting cross validation
2025-03-22 22:10:08,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:10:09,180:INFO:Calculating mean and std
2025-03-22 22:10:09,181:INFO:Creating metrics dataframe
2025-03-22 22:10:09,182:INFO:Uploading results into container
2025-03-22 22:10:09,183:INFO:Uploading model into container now
2025-03-22 22:10:09,183:INFO:_master_model_container: 11
2025-03-22 22:10:09,183:INFO:_display_container: 2
2025-03-22 22:10:09,183:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-22 22:10:09,183:INFO:create_model() successfully completed......................................
2025-03-22 22:10:09,284:INFO:SubProcess create_model() end ==================================
2025-03-22 22:10:09,284:INFO:Creating metrics dataframe
2025-03-22 22:10:09,289:INFO:Initializing Extra Trees Classifier
2025-03-22 22:10:09,289:INFO:Total runtime is 0.25924318234125776 minutes
2025-03-22 22:10:09,292:INFO:SubProcess create_model() called ==================================
2025-03-22 22:10:09,292:INFO:Initializing create_model()
2025-03-22 22:10:09,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:10:09,292:INFO:Checking exceptions
2025-03-22 22:10:09,292:INFO:Importing libraries
2025-03-22 22:10:09,292:INFO:Copying training dataset
2025-03-22 22:10:09,344:INFO:Defining folds
2025-03-22 22:10:09,344:INFO:Declaring metric variables
2025-03-22 22:10:09,346:INFO:Importing untrained model
2025-03-22 22:10:09,348:INFO:Extra Trees Classifier Imported successfully
2025-03-22 22:10:09,352:INFO:Starting cross validation
2025-03-22 22:10:09,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:10:09,748:INFO:Calculating mean and std
2025-03-22 22:10:09,749:INFO:Creating metrics dataframe
2025-03-22 22:10:09,750:INFO:Uploading results into container
2025-03-22 22:10:09,751:INFO:Uploading model into container now
2025-03-22 22:10:09,751:INFO:_master_model_container: 12
2025-03-22 22:10:09,751:INFO:_display_container: 2
2025-03-22 22:10:09,751:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-03-22 22:10:09,751:INFO:create_model() successfully completed......................................
2025-03-22 22:10:09,859:INFO:SubProcess create_model() end ==================================
2025-03-22 22:10:09,859:INFO:Creating metrics dataframe
2025-03-22 22:10:09,866:INFO:Initializing Light Gradient Boosting Machine
2025-03-22 22:10:09,866:INFO:Total runtime is 0.2688480297724406 minutes
2025-03-22 22:10:09,868:INFO:SubProcess create_model() called ==================================
2025-03-22 22:10:09,868:INFO:Initializing create_model()
2025-03-22 22:10:09,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:10:09,868:INFO:Checking exceptions
2025-03-22 22:10:09,868:INFO:Importing libraries
2025-03-22 22:10:09,868:INFO:Copying training dataset
2025-03-22 22:10:09,917:INFO:Defining folds
2025-03-22 22:10:09,917:INFO:Declaring metric variables
2025-03-22 22:10:09,919:INFO:Importing untrained model
2025-03-22 22:10:09,922:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-22 22:10:09,927:INFO:Starting cross validation
2025-03-22 22:10:09,928:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:10:11,304:INFO:Calculating mean and std
2025-03-22 22:10:11,306:INFO:Creating metrics dataframe
2025-03-22 22:10:11,308:INFO:Uploading results into container
2025-03-22 22:10:11,309:INFO:Uploading model into container now
2025-03-22 22:10:11,309:INFO:_master_model_container: 13
2025-03-22 22:10:11,309:INFO:_display_container: 2
2025-03-22 22:10:11,310:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-22 22:10:11,310:INFO:create_model() successfully completed......................................
2025-03-22 22:10:11,445:INFO:SubProcess create_model() end ==================================
2025-03-22 22:10:11,445:INFO:Creating metrics dataframe
2025-03-22 22:10:11,450:INFO:Initializing Dummy Classifier
2025-03-22 22:10:11,451:INFO:Total runtime is 0.2952727715174357 minutes
2025-03-22 22:10:11,453:INFO:SubProcess create_model() called ==================================
2025-03-22 22:10:11,453:INFO:Initializing create_model()
2025-03-22 22:10:11,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B009F0AD70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:10:11,453:INFO:Checking exceptions
2025-03-22 22:10:11,453:INFO:Importing libraries
2025-03-22 22:10:11,453:INFO:Copying training dataset
2025-03-22 22:10:11,499:INFO:Defining folds
2025-03-22 22:10:11,500:INFO:Declaring metric variables
2025-03-22 22:10:11,502:INFO:Importing untrained model
2025-03-22 22:10:11,504:INFO:Dummy Classifier Imported successfully
2025-03-22 22:10:11,507:INFO:Starting cross validation
2025-03-22 22:10:11,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:10:11,653:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:10:11,655:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:10:11,662:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:10:11,669:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:10:11,680:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:10:11,729:INFO:Calculating mean and std
2025-03-22 22:10:11,730:INFO:Creating metrics dataframe
2025-03-22 22:10:11,731:INFO:Uploading results into container
2025-03-22 22:10:11,732:INFO:Uploading model into container now
2025-03-22 22:10:11,732:INFO:_master_model_container: 14
2025-03-22 22:10:11,732:INFO:_display_container: 2
2025-03-22 22:10:11,732:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-03-22 22:10:11,732:INFO:create_model() successfully completed......................................
2025-03-22 22:10:11,837:INFO:SubProcess create_model() end ==================================
2025-03-22 22:10:11,838:INFO:Creating metrics dataframe
2025-03-22 22:10:11,845:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-22 22:10:11,850:INFO:Initializing create_model()
2025-03-22 22:10:11,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:10:11,850:INFO:Checking exceptions
2025-03-22 22:10:11,852:INFO:Importing libraries
2025-03-22 22:10:11,852:INFO:Copying training dataset
2025-03-22 22:10:11,901:INFO:Defining folds
2025-03-22 22:10:11,901:INFO:Declaring metric variables
2025-03-22 22:10:11,901:INFO:Importing untrained model
2025-03-22 22:10:11,901:INFO:Declaring custom model
2025-03-22 22:10:11,902:INFO:Random Forest Classifier Imported successfully
2025-03-22 22:10:11,903:INFO:Cross validation set to False
2025-03-22 22:10:11,903:INFO:Fitting Model
2025-03-22 22:10:12,025:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 22:10:12,025:INFO:create_model() successfully completed......................................
2025-03-22 22:10:12,130:INFO:Creating Dashboard logs
2025-03-22 22:10:12,132:INFO:Model: Random Forest Classifier
2025-03-22 22:10:12,175:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 22:10:12,270:INFO:Initializing predict_model()
2025-03-22 22:10:12,270:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002B03813AC20>)
2025-03-22 22:10:12,270:INFO:Checking exceptions
2025-03-22 22:10:12,270:INFO:Preloading libraries
2025-03-22 22:10:13,760:INFO:Creating Dashboard logs
2025-03-22 22:10:13,762:INFO:Model: Light Gradient Boosting Machine
2025-03-22 22:10:13,798:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-22 22:10:14,036:INFO:Creating Dashboard logs
2025-03-22 22:10:14,039:INFO:Model: Gradient Boosting Classifier
2025-03-22 22:10:14,072:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 22:10:14,312:INFO:Creating Dashboard logs
2025-03-22 22:10:14,314:INFO:Model: Ada Boost Classifier
2025-03-22 22:10:14,347:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 123}
2025-03-22 22:10:14,571:INFO:Creating Dashboard logs
2025-03-22 22:10:14,574:INFO:Model: Extra Trees Classifier
2025-03-22 22:10:14,608:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 22:10:14,876:INFO:Creating Dashboard logs
2025-03-22 22:10:14,878:INFO:Model: Decision Tree Classifier
2025-03-22 22:10:14,913:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 123, 'splitter': 'best'}
2025-03-22 22:10:15,140:INFO:Creating Dashboard logs
2025-03-22 22:10:15,143:INFO:Model: Quadratic Discriminant Analysis
2025-03-22 22:10:15,179:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-03-22 22:10:15,408:INFO:Creating Dashboard logs
2025-03-22 22:10:15,410:INFO:Model: K Neighbors Classifier
2025-03-22 22:10:15,442:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-22 22:10:15,662:INFO:Creating Dashboard logs
2025-03-22 22:10:15,664:INFO:Model: Linear Discriminant Analysis
2025-03-22 22:10:15,697:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-03-22 22:10:15,918:INFO:Creating Dashboard logs
2025-03-22 22:10:15,921:INFO:Model: Ridge Classifier
2025-03-22 22:10:15,955:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2025-03-22 22:10:16,175:INFO:Creating Dashboard logs
2025-03-22 22:10:16,178:INFO:Model: Logistic Regression
2025-03-22 22:10:16,212:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 22:10:16,451:INFO:Creating Dashboard logs
2025-03-22 22:10:16,453:INFO:Model: Naive Bayes
2025-03-22 22:10:16,489:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-03-22 22:10:16,716:INFO:Creating Dashboard logs
2025-03-22 22:10:16,718:INFO:Model: SVM - Linear Kernel
2025-03-22 22:10:16,756:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 22:10:16,990:INFO:Creating Dashboard logs
2025-03-22 22:10:16,993:INFO:Model: Dummy Classifier
2025-03-22 22:10:17,033:INFO:Logged params: {'constant': None, 'random_state': 123, 'strategy': 'prior'}
2025-03-22 22:10:17,261:INFO:_master_model_container: 14
2025-03-22 22:10:17,262:INFO:_display_container: 2
2025-03-22 22:10:17,262:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 22:10:17,262:INFO:compare_models() successfully completed......................................
2025-03-22 22:12:29,900:INFO:Initializing create_model()
2025-03-22 22:12:29,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:12:29,900:INFO:Checking exceptions
2025-03-22 22:12:29,909:INFO:Importing libraries
2025-03-22 22:12:29,909:INFO:Copying training dataset
2025-03-22 22:12:29,955:INFO:Defining folds
2025-03-22 22:12:29,955:INFO:Declaring metric variables
2025-03-22 22:12:29,958:INFO:Importing untrained model
2025-03-22 22:12:29,960:INFO:Random Forest Classifier Imported successfully
2025-03-22 22:12:29,964:INFO:Starting cross validation
2025-03-22 22:12:29,965:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:12:30,503:INFO:Calculating mean and std
2025-03-22 22:12:30,503:INFO:Creating metrics dataframe
2025-03-22 22:12:30,506:INFO:Finalizing model
2025-03-22 22:12:30,657:INFO:Creating Dashboard logs
2025-03-22 22:12:30,660:INFO:Model: Random Forest Classifier
2025-03-22 22:12:30,699:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 22:12:30,811:INFO:Initializing predict_model()
2025-03-22 22:12:30,811:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002B03813A5F0>)
2025-03-22 22:12:30,811:INFO:Checking exceptions
2025-03-22 22:12:30,811:INFO:Preloading libraries
2025-03-22 22:12:31,594:INFO:Uploading results into container
2025-03-22 22:12:31,594:INFO:Uploading model into container now
2025-03-22 22:12:31,600:INFO:_master_model_container: 15
2025-03-22 22:12:31,601:INFO:_display_container: 3
2025-03-22 22:12:31,601:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 22:12:31,601:INFO:create_model() successfully completed......................................
2025-03-22 22:13:19,766:INFO:Initializing plot_model()
2025-03-22 22:13:19,766:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, system=True)
2025-03-22 22:13:19,766:INFO:Checking exceptions
2025-03-22 22:13:19,818:INFO:Preloading libraries
2025-03-22 22:13:19,823:INFO:Copying training dataset
2025-03-22 22:13:19,823:INFO:Plot type: confusion_matrix
2025-03-22 22:13:20,425:INFO:Fitting Model
2025-03-22 22:13:20,425:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-03-22 22:13:20,426:INFO:Scoring test/hold-out set
2025-03-22 22:13:20,555:INFO:Visual Rendered Successfully
2025-03-22 22:13:20,664:INFO:plot_model() successfully completed......................................
2025-03-22 22:13:42,302:INFO:Initializing evaluate_model()
2025-03-22 22:13:42,302:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-22 22:13:42,329:INFO:Initializing plot_model()
2025-03-22 22:13:42,329:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B0095C8A60>, system=True)
2025-03-22 22:13:42,330:INFO:Checking exceptions
2025-03-22 22:13:42,378:INFO:Preloading libraries
2025-03-22 22:13:42,382:INFO:Copying training dataset
2025-03-22 22:13:42,382:INFO:Plot type: pipeline
2025-03-22 22:13:42,436:INFO:Visual Rendered Successfully
2025-03-22 22:13:42,544:INFO:plot_model() successfully completed......................................
2025-03-22 22:13:51,714:INFO:Initializing save_model()
2025-03-22 22:13:51,714:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), model_name=rf_task1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 22:13:51,714:INFO:Adding model into prep_pipe
2025-03-22 22:13:51,741:INFO:rf_task1.pkl saved in current working directory
2025-03-22 22:13:51,745:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'feature_17', 'feature_18',
                                             'feature_19', 'feat...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-03-22 22:13:51,746:INFO:save_model() successfully completed......................................
2025-03-22 22:19:09,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:19:09,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:19:09,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:19:09,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-22 22:21:53,472:INFO:PyCaret ClassificationExperiment
2025-03-22 22:21:53,472:INFO:Logging name: Mentalrisk_task2
2025-03-22 22:21:53,472:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-22 22:21:53,472:INFO:version 3.3.2
2025-03-22 22:21:53,472:INFO:Initializing setup()
2025-03-22 22:21:53,472:INFO:self.USI: 9d12
2025-03-22 22:21:53,472:INFO:self._variable_keys: {'exp_name_log', 'exp_id', 'X_test', 'y', '_ml_usecase', 'y_train', 'y_test', 'USI', 'fix_imbalance', 'memory', 'pipeline', 'idx', 'seed', 'X', 'n_jobs_param', 'is_multiclass', 'logging_param', 'X_train', 'fold_generator', 'gpu_param', '_available_plots', 'fold_groups_param', 'gpu_n_jobs_param', 'html_param', 'data', 'fold_shuffle_param', 'log_plots_param', 'target_param'}
2025-03-22 22:21:53,472:INFO:Checking environment
2025-03-22 22:21:53,472:INFO:python_version: 3.10.11
2025-03-22 22:21:53,472:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2025-03-22 22:21:53,472:INFO:machine: AMD64
2025-03-22 22:21:53,472:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-22 22:21:53,476:INFO:Memory: svmem(total=34188517376, available=16697823232, percent=51.2, used=17490694144, free=16697823232)
2025-03-22 22:21:53,476:INFO:Physical Core: 12
2025-03-22 22:21:53,476:INFO:Logical Core: 20
2025-03-22 22:21:53,476:INFO:Checking libraries
2025-03-22 22:21:53,476:INFO:System:
2025-03-22 22:21:53,476:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2025-03-22 22:21:53,476:INFO:executable: C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\Scripts\python.exe
2025-03-22 22:21:53,476:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-22 22:21:53,476:INFO:PyCaret required dependencies:
2025-03-22 22:21:53,665:INFO:                 pip: 24.2
2025-03-22 22:21:53,665:INFO:          setuptools: 73.0.1
2025-03-22 22:21:53,665:INFO:             pycaret: 3.3.2
2025-03-22 22:21:53,665:INFO:             IPython: 8.34.0
2025-03-22 22:21:53,665:INFO:          ipywidgets: 8.1.5
2025-03-22 22:21:53,665:INFO:                tqdm: 4.67.1
2025-03-22 22:21:53,665:INFO:               numpy: 1.26.4
2025-03-22 22:21:53,665:INFO:              pandas: 2.1.4
2025-03-22 22:21:53,665:INFO:              jinja2: 3.1.6
2025-03-22 22:21:53,665:INFO:               scipy: 1.11.4
2025-03-22 22:21:53,665:INFO:              joblib: 1.3.2
2025-03-22 22:21:53,665:INFO:             sklearn: 1.4.2
2025-03-22 22:21:53,665:INFO:                pyod: 2.0.3
2025-03-22 22:21:53,665:INFO:            imblearn: 0.13.0
2025-03-22 22:21:53,665:INFO:   category_encoders: 2.7.0
2025-03-22 22:21:53,665:INFO:            lightgbm: 4.6.0
2025-03-22 22:21:53,665:INFO:               numba: 0.61.0
2025-03-22 22:21:53,665:INFO:            requests: 2.32.3
2025-03-22 22:21:53,665:INFO:          matplotlib: 3.7.5
2025-03-22 22:21:53,665:INFO:          scikitplot: 0.3.7
2025-03-22 22:21:53,665:INFO:         yellowbrick: 1.5
2025-03-22 22:21:53,665:INFO:              plotly: 5.24.1
2025-03-22 22:21:53,666:INFO:    plotly-resampler: Not installed
2025-03-22 22:21:53,666:INFO:             kaleido: 0.2.1
2025-03-22 22:21:53,666:INFO:           schemdraw: 0.15
2025-03-22 22:21:53,666:INFO:         statsmodels: 0.14.4
2025-03-22 22:21:53,666:INFO:              sktime: 0.26.0
2025-03-22 22:21:53,666:INFO:               tbats: 1.1.3
2025-03-22 22:21:53,666:INFO:            pmdarima: 2.0.4
2025-03-22 22:21:53,666:INFO:              psutil: 7.0.0
2025-03-22 22:21:53,666:INFO:          markupsafe: 3.0.2
2025-03-22 22:21:53,666:INFO:             pickle5: Not installed
2025-03-22 22:21:53,666:INFO:         cloudpickle: 3.1.1
2025-03-22 22:21:53,666:INFO:         deprecation: 2.1.0
2025-03-22 22:21:53,666:INFO:              xxhash: 3.5.0
2025-03-22 22:21:53,666:INFO:           wurlitzer: Not installed
2025-03-22 22:21:53,666:INFO:PyCaret optional dependencies:
2025-03-22 22:21:53,677:INFO:                shap: Not installed
2025-03-22 22:21:53,677:INFO:           interpret: Not installed
2025-03-22 22:21:53,677:INFO:                umap: Not installed
2025-03-22 22:21:53,677:INFO:     ydata_profiling: Not installed
2025-03-22 22:21:53,677:INFO:  explainerdashboard: Not installed
2025-03-22 22:21:53,677:INFO:             autoviz: Not installed
2025-03-22 22:21:53,677:INFO:           fairlearn: Not installed
2025-03-22 22:21:53,677:INFO:          deepchecks: Not installed
2025-03-22 22:21:53,677:INFO:             xgboost: Not installed
2025-03-22 22:21:53,677:INFO:            catboost: Not installed
2025-03-22 22:21:53,677:INFO:              kmodes: Not installed
2025-03-22 22:21:53,677:INFO:             mlxtend: Not installed
2025-03-22 22:21:53,677:INFO:       statsforecast: Not installed
2025-03-22 22:21:53,677:INFO:        tune_sklearn: Not installed
2025-03-22 22:21:53,677:INFO:                 ray: Not installed
2025-03-22 22:21:53,677:INFO:            hyperopt: Not installed
2025-03-22 22:21:53,677:INFO:              optuna: Not installed
2025-03-22 22:21:53,677:INFO:               skopt: Not installed
2025-03-22 22:21:53,677:INFO:              mlflow: 2.16.0
2025-03-22 22:21:53,677:INFO:              gradio: Not installed
2025-03-22 22:21:53,677:INFO:             fastapi: Not installed
2025-03-22 22:21:53,677:INFO:             uvicorn: Not installed
2025-03-22 22:21:53,677:INFO:              m2cgen: Not installed
2025-03-22 22:21:53,677:INFO:           evidently: Not installed
2025-03-22 22:21:53,677:INFO:               fugue: Not installed
2025-03-22 22:21:53,677:INFO:           streamlit: Not installed
2025-03-22 22:21:53,677:INFO:             prophet: Not installed
2025-03-22 22:21:53,677:INFO:None
2025-03-22 22:21:53,677:INFO:Set up data.
2025-03-22 22:21:53,737:INFO:Set up folding strategy.
2025-03-22 22:21:53,737:INFO:Set up train/test split.
2025-03-22 22:21:53,775:INFO:Set up index.
2025-03-22 22:21:53,776:INFO:Assigning column types.
2025-03-22 22:21:53,821:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-22 22:21:53,844:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 22:21:53,851:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:21:53,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:53,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:53,915:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-22 22:21:53,915:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:21:53,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:53,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:53,930:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-22 22:21:53,954:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:21:53,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:53,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:53,992:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-22 22:21:54,006:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:54,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:54,006:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-22 22:21:54,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:54,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:54,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:54,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:54,089:INFO:Preparing preprocessing pipeline...
2025-03-22 22:21:54,096:INFO:Set up simple imputation.
2025-03-22 22:21:54,394:INFO:Finished creating preprocessing pipeline.
2025-03-22 22:21:54,398:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 22:21:54,398:INFO:Creating final display dataframe.
2025-03-22 22:21:55,085:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type        Multiclass
3           Original data shape        (540, 769)
4        Transformed data shape        (540, 769)
5   Transformed train set shape        (432, 769)
6    Transformed test set shape        (108, 769)
7              Numeric features               768
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment      MlflowLogger
17              Experiment Name  Mentalrisk_task2
18                          USI              9d12
2025-03-22 22:21:55,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:55,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:55,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:55,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-22 22:21:55,164:INFO:Logging experiment in loggers
2025-03-22 22:21:55,569:INFO:SubProcess save_model() called ==================================
2025-03-22 22:21:55,577:INFO:Initializing save_model()
2025-03-22 22:21:55,577:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), model_name=C:\Users\jeiso\AppData\Local\Temp\tmp24etkf80\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 22:21:55,577:INFO:Adding model into prep_pipe
2025-03-22 22:21:55,577:WARNING:Only Model saved as it was a pipeline.
2025-03-22 22:21:55,582:INFO:C:\Users\jeiso\AppData\Local\Temp\tmp24etkf80\Transformation Pipeline.pkl saved in current working directory
2025-03-22 22:21:55,585:INFO:Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-22 22:21:55,586:INFO:save_model() successfully completed......................................
2025-03-22 22:21:55,684:INFO:SubProcess save_model() end ==================================
2025-03-22 22:21:55,731:INFO:setup() successfully completed in 1.69s...............
2025-03-22 22:22:04,551:INFO:Initializing compare_models()
2025-03-22 22:22:04,551:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, include=None, fold=10, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, 'include': None, 'exclude': None, 'fold': 10, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-22 22:22:04,551:INFO:Checking exceptions
2025-03-22 22:22:04,580:INFO:Preparing display monitor
2025-03-22 22:22:04,595:INFO:Initializing Logistic Regression
2025-03-22 22:22:04,595:INFO:Total runtime is 0.0 minutes
2025-03-22 22:22:04,597:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:04,597:INFO:Initializing create_model()
2025-03-22 22:22:04,598:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:04,598:INFO:Checking exceptions
2025-03-22 22:22:04,598:INFO:Importing libraries
2025-03-22 22:22:04,598:INFO:Copying training dataset
2025-03-22 22:22:04,643:INFO:Defining folds
2025-03-22 22:22:04,644:INFO:Declaring metric variables
2025-03-22 22:22:04,646:INFO:Importing untrained model
2025-03-22 22:22:04,648:INFO:Logistic Regression Imported successfully
2025-03-22 22:22:04,652:INFO:Starting cross validation
2025-03-22 22:22:04,654:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:07,250:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:07,250:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:07,250:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:07,290:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:07,299:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:07,300:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:07,323:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:07,346:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:07,356:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:07,376:INFO:Calculating mean and std
2025-03-22 22:22:07,377:INFO:Creating metrics dataframe
2025-03-22 22:22:07,379:INFO:Uploading results into container
2025-03-22 22:22:07,379:INFO:Uploading model into container now
2025-03-22 22:22:07,379:INFO:_master_model_container: 1
2025-03-22 22:22:07,379:INFO:_display_container: 2
2025-03-22 22:22:07,380:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-22 22:22:07,380:INFO:create_model() successfully completed......................................
2025-03-22 22:22:07,481:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:07,481:INFO:Creating metrics dataframe
2025-03-22 22:22:07,485:INFO:Initializing K Neighbors Classifier
2025-03-22 22:22:07,485:INFO:Total runtime is 0.04815971851348877 minutes
2025-03-22 22:22:07,487:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:07,487:INFO:Initializing create_model()
2025-03-22 22:22:07,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:07,487:INFO:Checking exceptions
2025-03-22 22:22:07,487:INFO:Importing libraries
2025-03-22 22:22:07,487:INFO:Copying training dataset
2025-03-22 22:22:07,535:INFO:Defining folds
2025-03-22 22:22:07,535:INFO:Declaring metric variables
2025-03-22 22:22:07,537:INFO:Importing untrained model
2025-03-22 22:22:07,540:INFO:K Neighbors Classifier Imported successfully
2025-03-22 22:22:07,543:INFO:Starting cross validation
2025-03-22 22:22:07,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:09,487:INFO:Calculating mean and std
2025-03-22 22:22:09,488:INFO:Creating metrics dataframe
2025-03-22 22:22:09,490:INFO:Uploading results into container
2025-03-22 22:22:09,490:INFO:Uploading model into container now
2025-03-22 22:22:09,490:INFO:_master_model_container: 2
2025-03-22 22:22:09,490:INFO:_display_container: 2
2025-03-22 22:22:09,491:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-22 22:22:09,491:INFO:create_model() successfully completed......................................
2025-03-22 22:22:09,593:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:09,593:INFO:Creating metrics dataframe
2025-03-22 22:22:09,597:INFO:Initializing Naive Bayes
2025-03-22 22:22:09,597:INFO:Total runtime is 0.08336378335952759 minutes
2025-03-22 22:22:09,599:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:09,600:INFO:Initializing create_model()
2025-03-22 22:22:09,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:09,600:INFO:Checking exceptions
2025-03-22 22:22:09,600:INFO:Importing libraries
2025-03-22 22:22:09,600:INFO:Copying training dataset
2025-03-22 22:22:09,650:INFO:Defining folds
2025-03-22 22:22:09,650:INFO:Declaring metric variables
2025-03-22 22:22:09,652:INFO:Importing untrained model
2025-03-22 22:22:09,655:INFO:Naive Bayes Imported successfully
2025-03-22 22:22:09,658:INFO:Starting cross validation
2025-03-22 22:22:09,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:09,850:INFO:Calculating mean and std
2025-03-22 22:22:09,851:INFO:Creating metrics dataframe
2025-03-22 22:22:09,852:INFO:Uploading results into container
2025-03-22 22:22:09,853:INFO:Uploading model into container now
2025-03-22 22:22:09,853:INFO:_master_model_container: 3
2025-03-22 22:22:09,853:INFO:_display_container: 2
2025-03-22 22:22:09,853:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-22 22:22:09,854:INFO:create_model() successfully completed......................................
2025-03-22 22:22:09,963:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:09,963:INFO:Creating metrics dataframe
2025-03-22 22:22:09,967:INFO:Initializing Decision Tree Classifier
2025-03-22 22:22:09,967:INFO:Total runtime is 0.08952445983886718 minutes
2025-03-22 22:22:09,969:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:09,970:INFO:Initializing create_model()
2025-03-22 22:22:09,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:09,970:INFO:Checking exceptions
2025-03-22 22:22:09,970:INFO:Importing libraries
2025-03-22 22:22:09,970:INFO:Copying training dataset
2025-03-22 22:22:10,017:INFO:Defining folds
2025-03-22 22:22:10,017:INFO:Declaring metric variables
2025-03-22 22:22:10,019:INFO:Importing untrained model
2025-03-22 22:22:10,023:INFO:Decision Tree Classifier Imported successfully
2025-03-22 22:22:10,028:INFO:Starting cross validation
2025-03-22 22:22:10,030:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:10,278:INFO:Calculating mean and std
2025-03-22 22:22:10,279:INFO:Creating metrics dataframe
2025-03-22 22:22:10,280:INFO:Uploading results into container
2025-03-22 22:22:10,280:INFO:Uploading model into container now
2025-03-22 22:22:10,281:INFO:_master_model_container: 4
2025-03-22 22:22:10,281:INFO:_display_container: 2
2025-03-22 22:22:10,281:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-03-22 22:22:10,281:INFO:create_model() successfully completed......................................
2025-03-22 22:22:10,384:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:10,384:INFO:Creating metrics dataframe
2025-03-22 22:22:10,388:INFO:Initializing SVM - Linear Kernel
2025-03-22 22:22:10,388:INFO:Total runtime is 0.0965419332186381 minutes
2025-03-22 22:22:10,391:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:10,391:INFO:Initializing create_model()
2025-03-22 22:22:10,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:10,391:INFO:Checking exceptions
2025-03-22 22:22:10,391:INFO:Importing libraries
2025-03-22 22:22:10,391:INFO:Copying training dataset
2025-03-22 22:22:10,438:INFO:Defining folds
2025-03-22 22:22:10,438:INFO:Declaring metric variables
2025-03-22 22:22:10,440:INFO:Importing untrained model
2025-03-22 22:22:10,443:INFO:SVM - Linear Kernel Imported successfully
2025-03-22 22:22:10,447:INFO:Starting cross validation
2025-03-22 22:22:10,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:10,566:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,578:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,587:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,593:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,595:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,602:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:10,602:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:10,602:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:10,613:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,623:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,638:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,639:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,654:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,673:INFO:Calculating mean and std
2025-03-22 22:22:10,674:INFO:Creating metrics dataframe
2025-03-22 22:22:10,675:INFO:Uploading results into container
2025-03-22 22:22:10,675:INFO:Uploading model into container now
2025-03-22 22:22:10,676:INFO:_master_model_container: 5
2025-03-22 22:22:10,676:INFO:_display_container: 2
2025-03-22 22:22:10,676:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-22 22:22:10,676:INFO:create_model() successfully completed......................................
2025-03-22 22:22:10,781:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:10,781:INFO:Creating metrics dataframe
2025-03-22 22:22:10,785:INFO:Initializing Ridge Classifier
2025-03-22 22:22:10,786:INFO:Total runtime is 0.10317296584447225 minutes
2025-03-22 22:22:10,788:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:10,788:INFO:Initializing create_model()
2025-03-22 22:22:10,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:10,788:INFO:Checking exceptions
2025-03-22 22:22:10,788:INFO:Importing libraries
2025-03-22 22:22:10,788:INFO:Copying training dataset
2025-03-22 22:22:10,836:INFO:Defining folds
2025-03-22 22:22:10,836:INFO:Declaring metric variables
2025-03-22 22:22:10,838:INFO:Importing untrained model
2025-03-22 22:22:10,840:INFO:Ridge Classifier Imported successfully
2025-03-22 22:22:10,844:INFO:Starting cross validation
2025-03-22 22:22:10,845:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:10,928:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,940:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,951:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,960:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,966:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,972:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,986:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:10,990:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:11,001:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:11,013:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:11,021:INFO:Calculating mean and std
2025-03-22 22:22:11,027:INFO:Creating metrics dataframe
2025-03-22 22:22:11,028:INFO:Uploading results into container
2025-03-22 22:22:11,028:INFO:Uploading model into container now
2025-03-22 22:22:11,029:INFO:_master_model_container: 6
2025-03-22 22:22:11,029:INFO:_display_container: 2
2025-03-22 22:22:11,029:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-03-22 22:22:11,029:INFO:create_model() successfully completed......................................
2025-03-22 22:22:11,133:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:11,133:INFO:Creating metrics dataframe
2025-03-22 22:22:11,138:INFO:Initializing Random Forest Classifier
2025-03-22 22:22:11,138:INFO:Total runtime is 0.10904405117034911 minutes
2025-03-22 22:22:11,140:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:11,140:INFO:Initializing create_model()
2025-03-22 22:22:11,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:11,140:INFO:Checking exceptions
2025-03-22 22:22:11,140:INFO:Importing libraries
2025-03-22 22:22:11,140:INFO:Copying training dataset
2025-03-22 22:22:11,185:INFO:Defining folds
2025-03-22 22:22:11,185:INFO:Declaring metric variables
2025-03-22 22:22:11,187:INFO:Importing untrained model
2025-03-22 22:22:11,190:INFO:Random Forest Classifier Imported successfully
2025-03-22 22:22:11,193:INFO:Starting cross validation
2025-03-22 22:22:11,195:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:11,698:INFO:Calculating mean and std
2025-03-22 22:22:11,699:INFO:Creating metrics dataframe
2025-03-22 22:22:11,700:INFO:Uploading results into container
2025-03-22 22:22:11,700:INFO:Uploading model into container now
2025-03-22 22:22:11,701:INFO:_master_model_container: 7
2025-03-22 22:22:11,701:INFO:_display_container: 2
2025-03-22 22:22:11,701:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 22:22:11,701:INFO:create_model() successfully completed......................................
2025-03-22 22:22:11,802:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:11,802:INFO:Creating metrics dataframe
2025-03-22 22:22:11,807:INFO:Initializing Quadratic Discriminant Analysis
2025-03-22 22:22:11,807:INFO:Total runtime is 0.12019906838734944 minutes
2025-03-22 22:22:11,809:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:11,809:INFO:Initializing create_model()
2025-03-22 22:22:11,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:11,809:INFO:Checking exceptions
2025-03-22 22:22:11,809:INFO:Importing libraries
2025-03-22 22:22:11,809:INFO:Copying training dataset
2025-03-22 22:22:11,859:INFO:Defining folds
2025-03-22 22:22:11,859:INFO:Declaring metric variables
2025-03-22 22:22:11,861:INFO:Importing untrained model
2025-03-22 22:22:11,864:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-22 22:22:11,867:INFO:Starting cross validation
2025-03-22 22:22:11,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:12,003:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:22:12,018:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:22:12,019:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:22:12,036:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:22:12,037:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:22:12,045:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:12,049:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:12,049:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:12,051:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:12,054:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:12,055:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:22:12,068:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:12,069:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:22:12,070:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:12,071:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:12,073:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:12,074:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:22:12,078:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:22:12,085:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:12,088:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:12,094:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:12,095:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-22 22:22:12,097:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:12,100:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:12,102:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:12,103:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:12,106:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:12,120:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:12,123:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:12,126:INFO:Calculating mean and std
2025-03-22 22:22:12,127:INFO:Creating metrics dataframe
2025-03-22 22:22:12,128:INFO:Uploading results into container
2025-03-22 22:22:12,128:INFO:Uploading model into container now
2025-03-22 22:22:12,129:INFO:_master_model_container: 8
2025-03-22 22:22:12,129:INFO:_display_container: 2
2025-03-22 22:22:12,129:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-22 22:22:12,129:INFO:create_model() successfully completed......................................
2025-03-22 22:22:12,234:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:12,234:INFO:Creating metrics dataframe
2025-03-22 22:22:12,239:INFO:Initializing Ada Boost Classifier
2025-03-22 22:22:12,239:INFO:Total runtime is 0.12738810777664183 minutes
2025-03-22 22:22:12,241:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:12,241:INFO:Initializing create_model()
2025-03-22 22:22:12,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:12,241:INFO:Checking exceptions
2025-03-22 22:22:12,242:INFO:Importing libraries
2025-03-22 22:22:12,242:INFO:Copying training dataset
2025-03-22 22:22:12,292:INFO:Defining folds
2025-03-22 22:22:12,292:INFO:Declaring metric variables
2025-03-22 22:22:12,294:INFO:Importing untrained model
2025-03-22 22:22:12,296:INFO:Ada Boost Classifier Imported successfully
2025-03-22 22:22:12,300:INFO:Starting cross validation
2025-03-22 22:22:12,301:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:12,378:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:22:12,378:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:22:12,390:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:22:12,393:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:22:12,405:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:22:12,417:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:22:12,437:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:22:12,444:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:22:12,445:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:22:12,464:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-22 22:22:13,626:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:13,644:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:13,652:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:13,655:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:13,670:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:13,693:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:13,695:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:13,695:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:13,707:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:13,713:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:13,714:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:13,716:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:13,721:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:13,724:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:13,730:INFO:Calculating mean and std
2025-03-22 22:22:13,731:INFO:Creating metrics dataframe
2025-03-22 22:22:13,732:INFO:Uploading results into container
2025-03-22 22:22:13,732:INFO:Uploading model into container now
2025-03-22 22:22:13,733:INFO:_master_model_container: 9
2025-03-22 22:22:13,733:INFO:_display_container: 2
2025-03-22 22:22:13,733:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-03-22 22:22:13,733:INFO:create_model() successfully completed......................................
2025-03-22 22:22:13,835:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:13,835:INFO:Creating metrics dataframe
2025-03-22 22:22:13,840:INFO:Initializing Gradient Boosting Classifier
2025-03-22 22:22:13,841:INFO:Total runtime is 0.15410109758377075 minutes
2025-03-22 22:22:13,843:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:13,843:INFO:Initializing create_model()
2025-03-22 22:22:13,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:13,843:INFO:Checking exceptions
2025-03-22 22:22:13,843:INFO:Importing libraries
2025-03-22 22:22:13,843:INFO:Copying training dataset
2025-03-22 22:22:13,893:INFO:Defining folds
2025-03-22 22:22:13,893:INFO:Declaring metric variables
2025-03-22 22:22:13,896:INFO:Importing untrained model
2025-03-22 22:22:13,899:INFO:Gradient Boosting Classifier Imported successfully
2025-03-22 22:22:13,902:INFO:Starting cross validation
2025-03-22 22:22:13,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:40,752:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:40,771:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:40,920:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:40,958:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:40,980:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:40,999:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,050:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,051:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,099:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,281:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,299:INFO:Calculating mean and std
2025-03-22 22:22:41,300:INFO:Creating metrics dataframe
2025-03-22 22:22:41,301:INFO:Uploading results into container
2025-03-22 22:22:41,302:INFO:Uploading model into container now
2025-03-22 22:22:41,302:INFO:_master_model_container: 10
2025-03-22 22:22:41,302:INFO:_display_container: 2
2025-03-22 22:22:41,303:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-22 22:22:41,303:INFO:create_model() successfully completed......................................
2025-03-22 22:22:41,405:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:41,405:INFO:Creating metrics dataframe
2025-03-22 22:22:41,410:INFO:Initializing Linear Discriminant Analysis
2025-03-22 22:22:41,410:INFO:Total runtime is 0.6135815143585205 minutes
2025-03-22 22:22:41,412:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:41,412:INFO:Initializing create_model()
2025-03-22 22:22:41,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:41,413:INFO:Checking exceptions
2025-03-22 22:22:41,413:INFO:Importing libraries
2025-03-22 22:22:41,413:INFO:Copying training dataset
2025-03-22 22:22:41,462:INFO:Defining folds
2025-03-22 22:22:41,462:INFO:Declaring metric variables
2025-03-22 22:22:41,464:INFO:Importing untrained model
2025-03-22 22:22:41,466:INFO:Linear Discriminant Analysis Imported successfully
2025-03-22 22:22:41,470:INFO:Starting cross validation
2025-03-22 22:22:41,471:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:41,584:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,607:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,612:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,633:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,634:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,656:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,663:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,676:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,677:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,684:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-03-22 22:22:41,692:INFO:Calculating mean and std
2025-03-22 22:22:41,693:INFO:Creating metrics dataframe
2025-03-22 22:22:41,694:INFO:Uploading results into container
2025-03-22 22:22:41,694:INFO:Uploading model into container now
2025-03-22 22:22:41,695:INFO:_master_model_container: 11
2025-03-22 22:22:41,695:INFO:_display_container: 2
2025-03-22 22:22:41,695:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-22 22:22:41,695:INFO:create_model() successfully completed......................................
2025-03-22 22:22:41,798:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:41,798:INFO:Creating metrics dataframe
2025-03-22 22:22:41,803:INFO:Initializing Extra Trees Classifier
2025-03-22 22:22:41,804:INFO:Total runtime is 0.6201517383257548 minutes
2025-03-22 22:22:41,806:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:41,806:INFO:Initializing create_model()
2025-03-22 22:22:41,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:41,806:INFO:Checking exceptions
2025-03-22 22:22:41,806:INFO:Importing libraries
2025-03-22 22:22:41,806:INFO:Copying training dataset
2025-03-22 22:22:41,857:INFO:Defining folds
2025-03-22 22:22:41,857:INFO:Declaring metric variables
2025-03-22 22:22:41,860:INFO:Importing untrained model
2025-03-22 22:22:41,862:INFO:Extra Trees Classifier Imported successfully
2025-03-22 22:22:41,866:INFO:Starting cross validation
2025-03-22 22:22:41,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:42,258:INFO:Calculating mean and std
2025-03-22 22:22:42,259:INFO:Creating metrics dataframe
2025-03-22 22:22:42,260:INFO:Uploading results into container
2025-03-22 22:22:42,260:INFO:Uploading model into container now
2025-03-22 22:22:42,261:INFO:_master_model_container: 12
2025-03-22 22:22:42,261:INFO:_display_container: 2
2025-03-22 22:22:42,261:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-03-22 22:22:42,261:INFO:create_model() successfully completed......................................
2025-03-22 22:22:42,364:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:42,364:INFO:Creating metrics dataframe
2025-03-22 22:22:42,369:INFO:Initializing Light Gradient Boosting Machine
2025-03-22 22:22:42,369:INFO:Total runtime is 0.6295620640118916 minutes
2025-03-22 22:22:42,371:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:42,372:INFO:Initializing create_model()
2025-03-22 22:22:42,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:42,372:INFO:Checking exceptions
2025-03-22 22:22:42,372:INFO:Importing libraries
2025-03-22 22:22:42,372:INFO:Copying training dataset
2025-03-22 22:22:42,420:INFO:Defining folds
2025-03-22 22:22:42,420:INFO:Declaring metric variables
2025-03-22 22:22:42,422:INFO:Importing untrained model
2025-03-22 22:22:42,425:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-22 22:22:42,429:INFO:Starting cross validation
2025-03-22 22:22:42,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:47,765:INFO:Calculating mean and std
2025-03-22 22:22:47,767:INFO:Creating metrics dataframe
2025-03-22 22:22:47,769:INFO:Uploading results into container
2025-03-22 22:22:47,769:INFO:Uploading model into container now
2025-03-22 22:22:47,770:INFO:_master_model_container: 13
2025-03-22 22:22:47,770:INFO:_display_container: 2
2025-03-22 22:22:47,771:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-22 22:22:47,771:INFO:create_model() successfully completed......................................
2025-03-22 22:22:47,909:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:47,909:INFO:Creating metrics dataframe
2025-03-22 22:22:47,915:INFO:Initializing Dummy Classifier
2025-03-22 22:22:47,915:INFO:Total runtime is 0.7219881375630696 minutes
2025-03-22 22:22:47,917:INFO:SubProcess create_model() called ==================================
2025-03-22 22:22:47,917:INFO:Initializing create_model()
2025-03-22 22:22:47,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000200757CAB00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:47,917:INFO:Checking exceptions
2025-03-22 22:22:47,917:INFO:Importing libraries
2025-03-22 22:22:47,917:INFO:Copying training dataset
2025-03-22 22:22:47,965:INFO:Defining folds
2025-03-22 22:22:47,966:INFO:Declaring metric variables
2025-03-22 22:22:47,968:INFO:Importing untrained model
2025-03-22 22:22:47,970:INFO:Dummy Classifier Imported successfully
2025-03-22 22:22:47,974:INFO:Starting cross validation
2025-03-22 22:22:47,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:22:48,112:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:48,125:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:48,136:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:48,141:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:48,154:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:48,167:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:48,170:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:48,195:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:48,220:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:48,224:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-22 22:22:48,235:INFO:Calculating mean and std
2025-03-22 22:22:48,237:INFO:Creating metrics dataframe
2025-03-22 22:22:48,240:INFO:Uploading results into container
2025-03-22 22:22:48,241:INFO:Uploading model into container now
2025-03-22 22:22:48,241:INFO:_master_model_container: 14
2025-03-22 22:22:48,241:INFO:_display_container: 2
2025-03-22 22:22:48,241:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-03-22 22:22:48,241:INFO:create_model() successfully completed......................................
2025-03-22 22:22:48,346:INFO:SubProcess create_model() end ==================================
2025-03-22 22:22:48,346:INFO:Creating metrics dataframe
2025-03-22 22:22:48,372:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-22 22:22:48,377:INFO:Initializing create_model()
2025-03-22 22:22:48,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:22:48,377:INFO:Checking exceptions
2025-03-22 22:22:48,379:INFO:Importing libraries
2025-03-22 22:22:48,379:INFO:Copying training dataset
2025-03-22 22:22:48,427:INFO:Defining folds
2025-03-22 22:22:48,427:INFO:Declaring metric variables
2025-03-22 22:22:48,427:INFO:Importing untrained model
2025-03-22 22:22:48,427:INFO:Declaring custom model
2025-03-22 22:22:48,428:INFO:Random Forest Classifier Imported successfully
2025-03-22 22:22:48,430:INFO:Cross validation set to False
2025-03-22 22:22:48,430:INFO:Fitting Model
2025-03-22 22:22:48,564:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 22:22:48,565:INFO:create_model() successfully completed......................................
2025-03-22 22:22:48,672:INFO:Creating Dashboard logs
2025-03-22 22:22:48,675:INFO:Model: Random Forest Classifier
2025-03-22 22:22:48,728:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 22:22:48,826:INFO:Initializing predict_model()
2025-03-22 22:22:48,826:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002000B9D2C20>)
2025-03-22 22:22:48,826:INFO:Checking exceptions
2025-03-22 22:22:48,826:INFO:Preloading libraries
2025-03-22 22:22:51,335:INFO:Creating Dashboard logs
2025-03-22 22:22:51,337:INFO:Model: Extra Trees Classifier
2025-03-22 22:22:51,371:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 22:22:51,601:INFO:Creating Dashboard logs
2025-03-22 22:22:51,603:INFO:Model: Logistic Regression
2025-03-22 22:22:51,637:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-03-22 22:22:51,874:INFO:Creating Dashboard logs
2025-03-22 22:22:51,876:INFO:Model: Gradient Boosting Classifier
2025-03-22 22:22:51,911:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 22:22:52,149:INFO:Creating Dashboard logs
2025-03-22 22:22:52,152:INFO:Model: Light Gradient Boosting Machine
2025-03-22 22:22:52,186:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-03-22 22:22:52,422:INFO:Creating Dashboard logs
2025-03-22 22:22:52,424:INFO:Model: Decision Tree Classifier
2025-03-22 22:22:52,463:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 123, 'splitter': 'best'}
2025-03-22 22:22:52,692:INFO:Creating Dashboard logs
2025-03-22 22:22:52,694:INFO:Model: K Neighbors Classifier
2025-03-22 22:22:52,729:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-03-22 22:22:52,958:INFO:Creating Dashboard logs
2025-03-22 22:22:52,960:INFO:Model: Ridge Classifier
2025-03-22 22:22:52,995:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2025-03-22 22:22:53,217:INFO:Creating Dashboard logs
2025-03-22 22:22:53,219:INFO:Model: Naive Bayes
2025-03-22 22:22:53,254:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-03-22 22:22:53,469:INFO:Creating Dashboard logs
2025-03-22 22:22:53,471:INFO:Model: SVM - Linear Kernel
2025-03-22 22:22:53,509:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-03-22 22:22:53,739:INFO:Creating Dashboard logs
2025-03-22 22:22:53,741:INFO:Model: Linear Discriminant Analysis
2025-03-22 22:22:53,780:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-03-22 22:22:54,000:INFO:Creating Dashboard logs
2025-03-22 22:22:54,002:INFO:Model: Ada Boost Classifier
2025-03-22 22:22:54,047:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 123}
2025-03-22 22:22:54,271:INFO:Creating Dashboard logs
2025-03-22 22:22:54,274:INFO:Model: Quadratic Discriminant Analysis
2025-03-22 22:22:54,308:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-03-22 22:22:54,520:INFO:Creating Dashboard logs
2025-03-22 22:22:54,523:INFO:Model: Dummy Classifier
2025-03-22 22:22:54,560:INFO:Logged params: {'constant': None, 'random_state': 123, 'strategy': 'prior'}
2025-03-22 22:22:54,789:INFO:_master_model_container: 14
2025-03-22 22:22:54,789:INFO:_display_container: 2
2025-03-22 22:22:54,789:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 22:22:54,789:INFO:compare_models() successfully completed......................................
2025-03-22 22:23:16,245:INFO:Initializing create_model()
2025-03-22 22:23:16,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-22 22:23:16,245:INFO:Checking exceptions
2025-03-22 22:23:16,255:INFO:Importing libraries
2025-03-22 22:23:16,255:INFO:Copying training dataset
2025-03-22 22:23:16,300:INFO:Defining folds
2025-03-22 22:23:16,300:INFO:Declaring metric variables
2025-03-22 22:23:16,303:INFO:Importing untrained model
2025-03-22 22:23:16,305:INFO:Random Forest Classifier Imported successfully
2025-03-22 22:23:16,309:INFO:Starting cross validation
2025-03-22 22:23:16,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-22 22:23:16,761:INFO:Calculating mean and std
2025-03-22 22:23:16,761:INFO:Creating metrics dataframe
2025-03-22 22:23:16,764:INFO:Finalizing model
2025-03-22 22:23:16,901:INFO:Creating Dashboard logs
2025-03-22 22:23:16,903:INFO:Model: Random Forest Classifier
2025-03-22 22:23:16,946:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2025-03-22 22:23:17,046:INFO:Initializing predict_model()
2025-03-22 22:23:17,046:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002000B9D1AB0>)
2025-03-22 22:23:17,046:INFO:Checking exceptions
2025-03-22 22:23:17,046:INFO:Preloading libraries
2025-03-22 22:23:17,803:INFO:Uploading results into container
2025-03-22 22:23:17,803:INFO:Uploading model into container now
2025-03-22 22:23:17,809:INFO:_master_model_container: 15
2025-03-22 22:23:17,809:INFO:_display_container: 3
2025-03-22 22:23:17,809:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-03-22 22:23:17,809:INFO:create_model() successfully completed......................................
2025-03-22 22:23:23,554:INFO:Initializing plot_model()
2025-03-22 22:23:23,554:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, system=True)
2025-03-22 22:23:23,554:INFO:Checking exceptions
2025-03-22 22:23:23,602:INFO:Preloading libraries
2025-03-22 22:23:23,606:INFO:Copying training dataset
2025-03-22 22:23:23,606:INFO:Plot type: confusion_matrix
2025-03-22 22:23:24,367:INFO:Fitting Model
2025-03-22 22:23:24,375:WARNING:C:\Users\jeiso\Documents\Maestria\Semestre #1\Reto\MentalRiskES-2025\.venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-03-22 22:23:24,375:INFO:Scoring test/hold-out set
2025-03-22 22:23:24,567:INFO:Visual Rendered Successfully
2025-03-22 22:23:24,670:INFO:plot_model() successfully completed......................................
2025-03-22 22:23:32,584:INFO:Initializing evaluate_model()
2025-03-22 22:23:32,584:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-22 22:23:32,620:INFO:Initializing plot_model()
2025-03-22 22:23:32,620:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020011EEF550>, system=True)
2025-03-22 22:23:32,620:INFO:Checking exceptions
2025-03-22 22:23:32,661:INFO:Preloading libraries
2025-03-22 22:23:32,664:INFO:Copying training dataset
2025-03-22 22:23:32,664:INFO:Plot type: pipeline
2025-03-22 22:23:32,845:INFO:Visual Rendered Successfully
2025-03-22 22:23:32,959:INFO:plot_model() successfully completed......................................
2025-03-22 22:23:38,444:INFO:Initializing save_model()
2025-03-22 22:23:38,444:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), model_name=rf_task2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jeiso\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'fea...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-22 22:23:38,444:INFO:Adding model into prep_pipe
2025-03-22 22:23:38,469:INFO:rf_task2.pkl saved in current working directory
2025-03-22 22:23:38,473:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['feature_1', 'feature_2',
                                             'feature_3', 'feature_4',
                                             'feature_5', 'feature_6',
                                             'feature_7', 'feature_8',
                                             'feature_9', 'feature_10',
                                             'feature_11', 'feature_12',
                                             'feature_13', 'feature_14',
                                             'feature_15', 'feature_16',
                                             'feature_17', 'feature_18',
                                             'feature_19', 'feat...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=123, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-03-22 22:23:38,473:INFO:save_model() successfully completed......................................
