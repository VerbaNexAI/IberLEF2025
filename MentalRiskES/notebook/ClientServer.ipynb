{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Access the MentalRiskEs data and interact with the server\n",
    "\n",
    "This notebook has been developed by the [SINAI](https://sinai.ujaen.es/) research group for its usage in the [MentalRiskES](https://sites.google.com/view/mentalriskes2025/) evaluation campaign at IberLEF 2025.\n",
    "\n",
    "**NOTE 1**: Please visit the [MentalRiskES competition website](https://sites.google.com/view/mentalriskes2025/evaluation) to read the instructions about how to download the data and interact with the server to send the predictions of your system.\n",
    "\n",
    "**NOTE 2**: Along the code, please replace \"URL\" by the URL server and \"TOKEN\" by your personal token.\n",
    "\n",
    "Remember this is a support to help you to develop your own system of communication with our server. We recommend you to download it as a Python script instead of working directly on colab and adapt the code to your needs."
   ],
   "metadata": {
    "id": "ttODwCFd8K0Q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Install CodeCarbon package\n",
    "Read the [documentation](https://mlco2.github.io/codecarbon/) about the library if necessary. Remember that we provide a [CodeCarbon notebook](https://colab.research.google.com/drive/1boavnGOir0urui8qktbZaOmOV2pS5cn6?usp=sharing) with the example in its specific use in our competition.\n"
   ],
   "metadata": {
    "id": "2DJN0pXx8W3-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install codecarbon"
   ],
   "metadata": {
    "id": "wdvPWyc6x9cV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b1375b19-54b2-4877-88b4-0da7a7e5bbb2",
    "ExecuteTime": {
     "end_time": "2025-03-21T03:31:36.076157Z",
     "start_time": "2025-03-21T03:31:27.322113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting codecarbon"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "googletrans 4.0.0rc1 requires httpx==0.13.3, but you have httpx 0.27.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading codecarbon-2.8.3-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: arrow in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from codecarbon) (1.3.0)\n",
      "Requirement already satisfied: click in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from codecarbon) (8.1.8)\n",
      "Collecting fief-client[cli] (from codecarbon)\n",
      "  Downloading fief_client-0.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from codecarbon) (2.1.4)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from codecarbon) (0.21.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from codecarbon) (7.0.0)\n",
      "Collecting py-cpuinfo (from codecarbon)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pynvml (from codecarbon)\n",
      "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting questionary (from codecarbon)\n",
      "  Downloading questionary-2.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting rapidfuzz (from codecarbon)\n",
      "  Downloading rapidfuzz-3.12.2-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from codecarbon) (2.32.3)\n",
      "Requirement already satisfied: rich in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from codecarbon) (13.9.4)\n",
      "Requirement already satisfied: typer in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from codecarbon) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from arrow->codecarbon) (2.9.0.post0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from arrow->codecarbon) (2.9.0.20241206)\n",
      "Requirement already satisfied: colorama in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from click->codecarbon) (0.4.6)\n",
      "Collecting httpx<0.28.0,>=0.21.3 (from fief-client[cli]->codecarbon)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jwcrypto<2.0.0,>=1.4 (from fief-client[cli]->codecarbon)\n",
      "  Downloading jwcrypto-1.5.6-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting yaspin (from fief-client[cli]->codecarbon)\n",
      "  Downloading yaspin-3.1.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from pandas->codecarbon) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from pandas->codecarbon) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from pandas->codecarbon) (2025.1)\n",
      "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml->codecarbon)\n",
      "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from questionary->codecarbon) (3.0.50)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from requests->codecarbon) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from requests->codecarbon) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from requests->codecarbon) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from requests->codecarbon) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from rich->codecarbon) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from rich->codecarbon) (2.19.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from rich->codecarbon) (4.12.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from typer->codecarbon) (1.5.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (4.8.0)\n",
      "Collecting httpcore==1.* (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting cryptography>=3.4 (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon)\n",
      "  Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from prompt_toolkit<4.0,>=2.0->questionary->codecarbon) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.17.0)\n",
      "Collecting termcolor<2.4.0,>=2.2.0 (from yaspin->fief-client[cli]->codecarbon)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from anyio->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jeiso\\documents\\maestria\\semestre #1\\reto\\mentalriskes-2025\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\n",
      "Downloading codecarbon-2.8.3-py3-none-any.whl (516 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
      "Downloading questionary-2.1.0-py3-none-any.whl (36 kB)\n",
      "Downloading rapidfuzz-3.12.2-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 17.5 MB/s eta 0:00:00\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jwcrypto-1.5.6-py3-none-any.whl (92 kB)\n",
      "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
      "Downloading fief_client-0.20.0-py3-none-any.whl (20 kB)\n",
      "Downloading yaspin-3.1.0-py3-none-any.whl (18 kB)\n",
      "Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.2/3.2 MB 27.1 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: py-cpuinfo, nvidia-ml-py, termcolor, rapidfuzz, pynvml, h11, yaspin, questionary, httpcore, cryptography, jwcrypto, httpx, fief-client, codecarbon\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.9.0\n",
      "    Uninstalling h11-0.9.0:\n",
      "      Successfully uninstalled h11-0.9.0\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 0.9.1\n",
      "    Uninstalling httpcore-0.9.1:\n",
      "      Successfully uninstalled httpcore-0.9.1\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.13.3\n",
      "    Uninstalling httpx-0.13.3:\n",
      "      Successfully uninstalled httpx-0.13.3\n",
      "Successfully installed codecarbon-2.8.3 cryptography-44.0.2 fief-client-0.20.0 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 jwcrypto-1.5.6 nvidia-ml-py-12.570.86 py-cpuinfo-9.0.0 pynvml-12.0.0 questionary-2.1.0 rapidfuzz-3.12.2 termcolor-2.3.0 yaspin-3.1.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import libraries"
   ],
   "metadata": {
    "id": "dqyN-7TcXbL8"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Sqih7m6tN4MT",
    "ExecuteTime": {
     "end_time": "2025-03-21T03:31:58.800011Z",
     "start_time": "2025-03-21T03:31:56.760107Z"
    }
   },
   "source": [
    "import requests, zipfile, io\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from typing import List, Dict\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from codecarbon import EmissionsTracker"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Endpoints\n",
    "These URL addresses are necessary for the connection to the server.\n",
    "\n",
    "**IMPORTANT:** Replace \"URL\" by the URL server and \"TOKEN\" by your user token."
   ],
   "metadata": {
    "id": "CHGGrr3GXdIb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "URL = \"http://s3-ceatic.ujaen.es:8036\"\n",
    "TOKEN = \"258d7e20e4b175baeba402128baa9155\"\n",
    "\n",
    "# Download endpoints\n",
    "ENDPOINT_DOWNLOAD_TRIAL = URL+\"/{TASK}/download_trial/{TOKEN}\"\n",
    "ENDPOINT_DOWNLOAD_TRAIN = URL+\"/{TASK}/download_train/{TOKEN}\"\n",
    "\n",
    "# Trial endpoints\n",
    "ENDPOINT_GET_MESSAGES_TRIAL = URL+\"/{TASK}/getmessages_trial/{TOKEN}\"\n",
    "ENDPOINT_SUBMIT_DECISIONS_TRIAL = URL+\"/{TASK}/submit_trial/{TOKEN}/{RUN}\"\n",
    "\n",
    "# Test endpoints\n",
    "ENDPOINT_GET_MESSAGES = URL+\"/{TASK}/getmessages/{TOKEN}\"\n",
    "ENDPOINT_SUBMIT_DECISIONS = URL+\"/{TASK}/submit/{TOKEN}/{RUN}\""
   ],
   "metadata": {
    "id": "AdQPl8lbOKsg",
    "ExecuteTime": {
     "end_time": "2025-03-21T03:32:02.111170Z",
     "start_time": "2025-03-21T03:32:02.101167Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download Data\n",
    "To download the data, you can make use of the **function defined in the following**.\n",
    "\n",
    "The following function download the trial data. To adapt it to download the train and test data, follow the instructions given in the [website of the competition](https://sites.google.com/view/mentalriskes2024/evaluation)."
   ],
   "metadata": {
    "id": "WgHNiyxHR5AJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def download_messages_trial(task: str, token: str):\n",
    "    \"\"\" Allows you to download the trial data of the task.\n",
    "        Args:\n",
    "          task (str): task from which the data is to be retrieved\n",
    "          token (str): authentication token\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(ENDPOINT_DOWNLOAD_TRIAL.format(TASK=task, TOKEN=token))\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Trial - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "    else:\n",
    "      z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "      os.makedirs(\"./data/{task}/trial/\".format(task=task))\n",
    "      z.extractall(\"./data/{task}/trial/\".format(task=task))"
   ],
   "metadata": {
    "id": "Uaeh23C5R1lG",
    "ExecuteTime": {
     "end_time": "2025-03-21T03:32:04.675274Z",
     "start_time": "2025-03-21T03:32:04.656279Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "def download_messages_train(task: str, token: str):\n",
    "    \"\"\" Allows you to download the train data of the task.\n",
    "        Args:\n",
    "          task (str): task from which the data is to be retrieved\n",
    "          token (str): authentication token\n",
    "    \"\"\"\n",
    "    response = requests.get(ENDPOINT_DOWNLOAD_TRAIN.format(TASK=task, TOKEN=token))\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Train - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n",
    "    else:\n",
    "      z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "      os.makedirs(\"./data/{task}/train/\".format(task=task),exist_ok=True)\n",
    "      z.extractall(\"./data/{task}/train/\".format(task=task))"
   ],
   "metadata": {
    "id": "v09j7ChSD6c-",
    "ExecuteTime": {
     "end_time": "2025-03-21T03:32:07.818179Z",
     "start_time": "2025-03-21T03:32:07.806179Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Client Server\n",
    "This class simulates communication with our server. The following code established the conection with the server client and simulate the GET and POST requests.\n",
    "\n",
    "**IMPORTANT NOTE:** Please pay attention to the basic functions and remember that it is only a base for your system."
   ],
   "metadata": {
    "id": "VIqRCv3OS3Bn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Client_task1_2:\n",
    "    \"\"\" Client communicating with the official server.\n",
    "        Attributes:\n",
    "            token (str): authentication token\n",
    "            number_of_runs (int): number of systems. Must be 3 in order to advance to the next round.\n",
    "            tracker (EmissionsTracker): object to calculate the carbon footprint in prediction\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, task:str, token: str, number_of_runs: int, tracker: EmissionsTracker):\n",
    "        self.task = task\n",
    "        self.token = token\n",
    "        self.number_of_runs = number_of_runs\n",
    "        self.tracker = tracker\n",
    "        self.relevant_cols = ['duration', 'emissions', 'cpu_energy', 'gpu_energy',\n",
    "                              'ram_energy','energy_consumed', 'cpu_count', 'gpu_count',\n",
    "                              'cpu_model', 'gpu_model', 'ram_total_size','country_iso_code']\n",
    "\n",
    "\n",
    "    def get_messages(self, retries: int, backoff: float) -> Dict:\n",
    "        \"\"\" Allows you to download the test data of the task by rounds.\n",
    "            Here a GET request is sent to the server to extract the data.\n",
    "            Args:\n",
    "              retries (int): number of calls on the server connection\n",
    "              backoff (float): time between retries\n",
    "        \"\"\"\n",
    "        session = requests.Session()\n",
    "        retries = Retry(\n",
    "                        total = retries,\n",
    "                        backoff_factor = backoff,\n",
    "                        status_forcelist = [500, 502, 503, 504]\n",
    "                        )\n",
    "        session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "        response = session.get(ENDPOINT_GET_MESSAGES_TRIAL.format(TASK=self.task, TOKEN=self.token)) # ENDPOINT\n",
    "\n",
    "        if response.status_code != 200:\n",
    "          print(\"GET - Task {} - Status Code {} - Error: {}\".format(self.task, str(response.status_code), str(response.text)))\n",
    "          return []\n",
    "        else:\n",
    "          return json.loads(response.content)\n",
    "\n",
    "    def submit_decission(self, messages: List[Dict], emissions: Dict, retries: int, backoff: float):\n",
    "        \"\"\" Allows you to submit the decisions of the task by rounds.\n",
    "            The POST requests are sent to the server to send predictions and carbon emission data\n",
    "            Args:\n",
    "              messages (List[Dict]): Message set of the current round\n",
    "              emissions (Dict): carbon footprint generated in the prediction\n",
    "              retries (int): number of calls on the server connection\n",
    "              backoff (float): time between retries\n",
    "        \"\"\"\n",
    "        decisions_run0 = {}\n",
    "        decisions_run1 = {}\n",
    "        decisions_run2 = {}\n",
    "        type_addiction_list = [\"betting\", \"onlinegaming\", \"betting\", \"trading\"]\n",
    "        type_addiction_decision = {}\n",
    "\n",
    "        # You must create the appropriate structure to send the predictions according to each task\n",
    "        for message in messages:\n",
    "            decisions_run0[message[\"nick\"]] = random.choice([0,1])\n",
    "            decisions_run1[message[\"nick\"]] = random.choice([0,1])\n",
    "            decisions_run2[message[\"nick\"]] = random.choice([0,1])\n",
    "            type_addiction_decision[message[\"nick\"]] = random.choice(type_addiction_list)\n",
    "\n",
    "        data1_run0 = {\n",
    "            \"predictions\": decisions_run0,\n",
    "            \"emissions\": emissions\n",
    "        }\n",
    "        data1_run1 = {\n",
    "            \"predictions\": decisions_run1,\n",
    "            \"emissions\": emissions\n",
    "        }\n",
    "        data1_run2 = {\n",
    "            \"predictions\": decisions_run2,\n",
    "            \"emissions\": emissions\n",
    "        }\n",
    "        data2_run0 = {\n",
    "            \"predictions\": decisions_run0,\n",
    "            \"types\":type_addiction_decision,\n",
    "            \"emissions\": emissions\n",
    "        }\n",
    "        data2_run1 = {\n",
    "            \"predictions\": decisions_run1,\n",
    "            \"types\":type_addiction_decision,\n",
    "            \"emissions\": emissions\n",
    "        }\n",
    "        data2_run2 = {\n",
    "            \"predictions\": decisions_run2,\n",
    "            \"types\":type_addiction_decision,\n",
    "            \"emissions\": emissions\n",
    "        }\n",
    "\n",
    "        data1 = []\n",
    "        data1.append(json.dumps(data1_run0))\n",
    "        data1.append(json.dumps(data1_run1))\n",
    "        data1.append(json.dumps(data1_run2))\n",
    "\n",
    "        data2 = []\n",
    "        data2.append(json.dumps(data2_run0))\n",
    "        data2.append(json.dumps(data2_run1))\n",
    "        data2.append(json.dumps(data2_run2))\n",
    "\n",
    "        # Session to POST request\n",
    "        session = requests.Session()\n",
    "        retries = Retry(\n",
    "                        total = retries,\n",
    "                        backoff_factor = backoff,\n",
    "                        status_forcelist = [500, 502, 503, 504]\n",
    "                        )\n",
    "        session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "        for run in range(0, self.number_of_runs):\n",
    "            # For each run, new decisions\n",
    "            response1 = session.post(ENDPOINT_SUBMIT_DECISIONS_TRIAL.format(TASK='task1', TOKEN=self.token, RUN=run), json=[data1[run]]) # ENDPOINT\n",
    "            if response1.status_code != 200:\n",
    "                print(\"POST - Task1 - Status Code {} - Error: {}\".format(str(response1.status_code), str(response1.text)))\n",
    "                return\n",
    "            else:\n",
    "                print(\"POST - Task1 - run {} - Message: {}\".format(run, str(response1.text)))\n",
    "\n",
    "            response2 = session.post(ENDPOINT_SUBMIT_DECISIONS_TRIAL.format(TASK='task2', TOKEN=self.token, RUN=run), json=[data2[run]]) # ENDPOINT\n",
    "            if response2.status_code != 200:\n",
    "                print(\"POST - Task2 - Status Code {} - Error: {}\".format(str(response2.status_code), str(response2.text)))\n",
    "                return\n",
    "            else:\n",
    "                print(\"POST - Task2 - run {} - Message: {}\".format(run, str(response2.text)))\n",
    "\n",
    "            with open('./data/preds/task1/round{}_run{}.json'.format(messages[0][\"round\"], run), 'w+', encoding='utf8') as json_file:\n",
    "                json.dump(data1[run], json_file, ensure_ascii=False)\n",
    "            with open('./data/preds/task2/round{}_run{}.json'.format(messages[0][\"round\"], run), 'w+', encoding='utf8') as json_file:\n",
    "                json.dump(data2[run], json_file, ensure_ascii=False)\n",
    "\n",
    "\n",
    "    def run_task1_2(self, retries: int, backoff: float):\n",
    "        \"\"\" Main thread\n",
    "            Args:\n",
    "              retries (int): number of calls on the server connection\n",
    "              backoff (float): time between retries\n",
    "        \"\"\"\n",
    "        # Get messages for task1_2\n",
    "        messages = self.get_messages(retries, backoff)\n",
    "\n",
    "        # If there are no messages\n",
    "        if len(messages) == 0:\n",
    "            print(\"All rounds processed\")\n",
    "            return\n",
    "\n",
    "        while len(messages) > 0:\n",
    "            print(messages)\n",
    "            print(\"----------------------- Processing round {}\".format(messages[0][\"round\"]))\n",
    "            # Save subjects\n",
    "            with open('./data/rounds/round{}.json'.format(messages[0][\"round\"]), 'w+', encoding='utf8') as json_file:\n",
    "                json.dump(messages, json_file, ensure_ascii=False)\n",
    "\n",
    "            # Calculate emissions for each prediction\n",
    "            self.tracker.start()\n",
    "\n",
    "            # Your code\n",
    "\n",
    "            emissions = self.tracker.stop()\n",
    "            df = pd.read_csv(\"emissions.csv\")\n",
    "            measurements = df.iloc[-1][self.relevant_cols].to_dict()\n",
    "\n",
    "            self.submit_decission(messages, measurements, retries, backoff)\n",
    "\n",
    "            # One GET request for each round\n",
    "            messages = self.get_messages(retries, backoff)\n",
    "\n",
    "        print(\"All rounds processed\")"
   ],
   "metadata": {
    "id": "l0kONpltS2R9",
    "ExecuteTime": {
     "end_time": "2025-03-21T03:32:10.204846Z",
     "start_time": "2025-03-21T03:32:10.184339Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main"
   ],
   "metadata": {
    "id": "gMXuHLciXIO3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def download_data(task: str, token: str):\n",
    "    download_messages_train(task, token)\n",
    "\n",
    "def get_post_data(task: str, token: str):\n",
    "    # Emissions Tracker Config\n",
    "    config = {\n",
    "        \"save_to_file\": True,\n",
    "        \"log_level\": \"WARNING\",\n",
    "        \"tracking_mode\": \"process\",\n",
    "        \"output_dir\": \".\",\n",
    "        \"allow_multiple_runs\": True\n",
    "    }\n",
    "    tracker = EmissionsTracker(**config)\n",
    "\n",
    "    number_runs = 3 # Max: 3\n",
    "\n",
    "    # Prediction period\n",
    "    client_task1_2 = Client_task1_2(task, token, number_runs, tracker)\n",
    "    client_task1_2.run_task1_2(5, 0.1)"
   ],
   "metadata": {
    "id": "GZrDpxNAS6-3",
    "ExecuteTime": {
     "end_time": "2025-03-21T03:32:47.731225Z",
     "start_time": "2025-03-21T03:32:47.722226Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Be careful! In this specific example we use the name of the task1 to do the get, knowing that it is the same data for both task 1 and task 2. In addition, the data upload is performed for both tasks."
   ],
   "metadata": {
    "id": "Ff6QgM3gErMm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    download_data(\"task2\", TOKEN)\n",
    "    # get_post_data(\"task1\",TOKEN)"
   ],
   "metadata": {
    "id": "aKMWQ5buS8OK",
    "ExecuteTime": {
     "end_time": "2025-03-21T03:35:54.361990Z",
     "start_time": "2025-03-21T03:35:52.485658Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  }
 ]
}
