{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Librerias",
   "id": "1d48c07eda4925d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_recall_fscore_support\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from datasets import Dataset\n",
    "from google.colab import files"
   ],
   "id": "8e6baac6c359b85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ PREDICCIONES PARA COMPETENCIA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Definir la ruta donde se encuentran los archivos del modelo y tokenizador\n",
    "model_path = \"/ruta/a/tu/carpeta/modelo\"\n",
    "tokenizer_path = \"/ruta/a/tu/carpeta/tokenizer\"\n",
    "\n",
    "# Cargar el tokenizador y el modelo desde las carpetas locales\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Mover el modelo a un dispositivo (GPU si est√° disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Cargar dataset de competencia\n",
    "dataset_path = \"/content/TA1C_dataset_detection_test.csv\"\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"‚ùå Error: No se encuentra {dataset_path}\")\n",
    "    print(\"üì• Sube el archivo de competencia a Colab\")\n",
    "    print(\"   El archivo debe tener columnas: 'Tweet ID', 'Teaser Text'\")\n",
    "else:\n",
    "    print(\"üìÇ Cargando dataset de competencia...\")\n",
    "    dat_competencia = pd.read_csv(dataset_path)\n",
    "    print(f\"‚úÖ Dataset cargado: {len(dat_competencia)} ejemplos\")\n",
    "    print(f\"üìã Columnas: {list(dat_competencia.columns)}\")\n",
    "\n",
    "    # Funci√≥n para reemplazar URLs (mismo preprocesamiento que entrenamiento)\n",
    "    def reemplazar_urls(df, columna_texto):\n",
    "        \"\"\"Reemplazar URLs por token [URL]\"\"\"\n",
    "        patron_url = r'https?://\\S+|www\\.\\S+'\n",
    "        df = df.copy()\n",
    "        df[columna_texto] = df[columna_texto].apply(\n",
    "            lambda texto: re.sub(patron_url, '[URL]', str(texto))\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    # Aplicar preprocesamiento\n",
    "    print(\"üîÑ Aplicando preprocesamiento...\")\n",
    "    dat_test = reemplazar_urls(dat_competencia, \"Teaser Text\")\n",
    "    dat_test[\"Teaser Text\"] = dat_test[\"Teaser Text\"].apply(limpiar_texto)\n",
    "\n",
    "    print(\"üìã Ejemplos de preprocesamiento:\")\n",
    "    for i in range(min(3, len(dat_test))):\n",
    "        original = dat_competencia.iloc[i][\"Teaser Text\"]\n",
    "        procesado = dat_test.iloc[i][\"Teaser Text\"]\n",
    "        print(f\"   Original: {original[:60]}...\")\n",
    "        print(f\"   Procesado: {procesado[:60]}...\")\n",
    "        print()\n",
    "\n",
    "    # Funci√≥n de predicci√≥n optimizada para competencia\n",
    "    def predecir_competencia(textos, batch_size=8):\n",
    "        \"\"\"Predecir textos para competencia por lotes\"\"\"\n",
    "        model.eval()\n",
    "        todas_predicciones = []\n",
    "\n",
    "        print(f\"üîÑ Procesando {len(textos)} textos en lotes de {batch_size}...\")\n",
    "\n",
    "        for i in tqdm(range(0, len(textos), batch_size), desc=\"Prediciendo para competencia\"):\n",
    "            batch_textos = textos[i:i+batch_size]\n",
    "\n",
    "            try:\n",
    "                # Tokenizar lote\n",
    "                inputs = tokenizer(\n",
    "                    batch_textos,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=512\n",
    "                )\n",
    "\n",
    "                # Mover a dispositivo\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "                # Predicci√≥n\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    pred_classes = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "                todas_predicciones.extend(pred_classes)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error en lote {i//batch_size}: {e}\")\n",
    "                # En caso de error, predecir \"No\" para el lote\n",
    "                todas_predicciones.extend([0] * len(batch_textos))\n",
    "\n",
    "        return todas_predicciones\n",
    "\n",
    "    # Realizar predicciones para competencia\n",
    "    print(\"üöÄ Realizando predicciones para competencia...\")\n",
    "    textos = dat_test[\"Teaser Text\"].tolist()\n",
    "    tweet_ids = dat_test[\"Tweet ID\"].tolist()\n",
    "\n",
    "    predicciones_numericas = predecir_competencia(textos, batch_size=8)\n",
    "    predicciones_texto = [\"Clickbait\" if pred == 1 else \"No\" for pred in predicciones_numericas]\n",
    "\n",
    "    print(\"‚úÖ Predicciones completadas!\")\n",
    "\n",
    "    # Crear DataFrame de resultados\n",
    "    df_resultados = pd.DataFrame({\n",
    "        \"Tweet ID\": tweet_ids,\n",
    "        \"Tag Value\": predicciones_texto\n",
    "    })\n",
    "\n",
    "    # Verificaciones de calidad\n",
    "    print(f\"\\nüîç VERIFICACIONES DE CALIDAD:\")\n",
    "    print(f\"   Total predicciones: {len(df_resultados)}\")\n",
    "    print(f\"   Distribuci√≥n:\")\n",
    "    distribucion = df_resultados['Tag Value'].value_counts()\n",
    "    for valor, cantidad in distribucion.items():\n",
    "        porcentaje = (cantidad / len(df_resultados)) * 100\n",
    "        print(f\"     {valor}: {cantidad} ({porcentaje:.1f}%)\")\n",
    "\n",
    "    # Verificar formato\n",
    "    print(f\"   Valores √∫nicos: {df_resultados['Tag Value'].unique()}\")\n",
    "    print(f\"   Valores nulos: {df_resultados.isnull().sum().sum()}\")\n",
    "\n",
    "    if df_resultados.isnull().sum().sum() == 0:\n",
    "        print(\"   ‚úÖ Sin valores nulos\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Hay valores nulos\")\n",
    "\n",
    "    if set(df_resultados['Tag Value'].unique()) == {\"No\", \"Clickbait\"}:\n",
    "        print(\"   ‚úÖ Formato correcto\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Formato incorrecto\")\n",
    "\n",
    "    # Guardar archivo\n",
    "    ruta_salida = \"/content/detection2.csv\"\n",
    "    df_resultados.to_csv(ruta_salida, index=False)\n",
    "\n",
    "    print(f\"\\nüíæ Archivo guardado: {ruta_salida}\")\n",
    "\n",
    "    # Verificar archivo guardado\n",
    "    if os.path.exists(ruta_salida):\n",
    "        size_mb = os.path.getsize(ruta_salida) / (1024 * 1024)\n",
    "        print(f\"   Tama√±o: {size_mb:.2f} MB\")\n",
    "\n",
    "        # Mostrar muestra del archivo\n",
    "        print(f\"\\nüìã Muestra del archivo generado:\")\n",
    "        print(df_resultados.head(10))\n",
    "\n",
    "    # Descargar archivo\n",
    "    print(f\"\\nüì• Descargando archivo...\")\n",
    "    try:\n",
    "        files.download(ruta_salida)\n",
    "        print(\"‚úÖ ¬°Archivo descargado exitosamente!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error al descargar: {e}\")\n",
    "        print(f\"El archivo est√° guardado en: {ruta_salida}\")\n",
    "\n",
    "    # Resumen final\n",
    "    total_clickbait = (df_resultados['Tag Value'] == 'Clickbait').sum()\n",
    "    porcentaje_clickbait = (total_clickbait / len(df_resultados)) * 100\n",
    "\n",
    "    print(f\"\\nüéØ RESUMEN FINAL:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"üèÜ Modelo usado: Llama\")\n",
    "    print(f\"üìÅ Archivo: detection_checkpoint2760.csv\")\n",
    "    print(f\"üìä Total predicciones: {len(df_resultados)}\")\n",
    "    print(f\"üéØ Clickbait detectado: {total_clickbait} ({porcentaje_clickbait:.1f}%)\")\n",
    "    print(f\"‚úÖ Mejor modelo (menos sobreajuste)\")\n",
    "    print(f\"üìà M√©tricas en test: Acc={accuracy:.3f}, F1={f1:.3f}\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"üèÜ ¬°Listo para enviar a la competencia!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
