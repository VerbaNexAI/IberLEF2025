{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91db86ab1b694704ac57b1b72714e3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_873835d30b8c4139af1c5b335111352f",
              "IPY_MODEL_e24c2d4f752f4c509c0f09dcf1001076",
              "IPY_MODEL_7b5a29c496f44a6a8ef3fb5b8e90faf4"
            ],
            "layout": "IPY_MODEL_cd229b1bed754fea872e59e513eef903"
          }
        },
        "873835d30b8c4139af1c5b335111352f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8228dbdf93d24bbd800c0f6e68eba1bc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3cdcf31a6414433590e31b5caa86b7a2",
            "value": "Map:‚Äá100%"
          }
        },
        "e24c2d4f752f4c509c0f09dcf1001076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23f56fb510fe4cf096fc9f38ce26d9c4",
            "max": 2308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49107a2c4dea4d4288f8dc2233df820d",
            "value": 2308
          }
        },
        "7b5a29c496f44a6a8ef3fb5b8e90faf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58aa6bb2aa2e460f93da4a5796ef9efc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_78fe21afdbad49fab5d2c1abc13428e3",
            "value": "‚Äá2308/2308‚Äá[00:04&lt;00:00,‚Äá584.43‚Äáexamples/s]"
          }
        },
        "cd229b1bed754fea872e59e513eef903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8228dbdf93d24bbd800c0f6e68eba1bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cdcf31a6414433590e31b5caa86b7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23f56fb510fe4cf096fc9f38ce26d9c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49107a2c4dea4d4288f8dc2233df820d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58aa6bb2aa2e460f93da4a5796ef9efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78fe21afdbad49fab5d2c1abc13428e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX4QWUELVBz5",
        "outputId": "982fa13b-710b-46c2-b56d-c091bfbe2c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/DATA/ote_acd.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pht0-FehVdRN",
        "outputId": "85cd355e-9ed8-4f50-fe10-d175aaf30d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/DATA/ote_acd.csv': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09tieqolAYZs",
        "outputId": "3c641800-6609-4dd9-eaf7-252f1dcd3e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import ast\n",
        "import spacy\n",
        "\n",
        "# ===============================\n",
        "# Clase de limpieza de texto\n",
        "# ===============================\n",
        "class TextProcessing(object):\n",
        "    @staticmethod\n",
        "    def remove_patterns(text: str) -> str:\n",
        "        try:\n",
        "            text = re.sub(r'\\¬©|\\√ó|\\‚áî|\\_|\\¬ª|\\¬´|\\~|\\#|\\$|\\‚Ç¨|\\√Ç|\\ÔøΩ|\\¬¨', '', text)\n",
        "            text = re.sub(r'\\,|\\;|\\:|\\!|\\¬°|\\‚Äô|\\‚Äò|\\‚Äù|\\‚Äú|\\\"|\\'|\\`', '', text)\n",
        "            text = re.sub(r'\\}|\\{|\\[|\\]|\\(|\\)|\\<|\\>|\\?|\\¬ø|\\¬∞|\\|', '', text)\n",
        "            text = re.sub(r'\\/|\\-|\\+|\\*|\\=|\\^|\\%|\\&|\\$', '', text)\n",
        "            text = re.sub(r'\\b\\d+(?:\\.\\d+)?\\s+', '', text)\n",
        "            return text.lower()\n",
        "        except Exception as e:\n",
        "            print('Error remove_patterns: {0}'.format(e))\n",
        "            return text\n",
        "\n",
        "# ===============================\n",
        "# Cargar el archivo completo\n",
        "# ===============================\n",
        "df = pd.read_csv('/content/drive/MyDrive/Datas_Notebooks/ote_acd.csv', sep=';', encoding='utf-8-sig', on_bad_lines='skip')\n",
        "df['aspect'] = df['aspect'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "df['text_clean'] = df['text'].apply(lambda x: TextProcessing.remove_patterns(str(x)))\n",
        "\n",
        "# ===============================\n",
        "# Seleccionar una muestra\n",
        "# ===============================\n",
        "df_sample = df.head(2886).copy()\n",
        "\n",
        "# ===============================\n",
        "# Procesar con spaCy para extraer noun chunks\n",
        "# ===============================\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "def extract_noun_chunks(text):\n",
        "    doc = nlp(text)\n",
        "    noun_chunks = [chunk.text for chunk in doc.noun_chunks]\n",
        "    return ' '.join(noun_chunks)\n",
        "\n",
        "# Crear una nueva columna con la rese√±a reconstruida basada en noun chunks\n",
        "df_sample['text_noun_chunks'] = df_sample['text_clean'].apply(extract_noun_chunks)\n",
        "\n",
        "# Mostrar resultados para verificar\n",
        "print(df_sample[['text','text_noun_chunks', 'aspect', 'target_opinion_terms']].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fzPTUiaxWVV",
        "outputId": "7aeaf06c-d948-44e0-b98e-dca815522b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  Hotel com condi√ß√µes gerais muito m√°s. Infraest...   \n",
            "1  Hotel com condi√ß√µes gerais muito m√°s. Infraest...   \n",
            "2  Hotel com condi√ß√µes gerais muito m√°s. Infraest...   \n",
            "3  Hotel com condi√ß√µes gerais muito m√°s. Infraest...   \n",
            "4  Hotel com condi√ß√µes gerais muito m√°s. Infraest...   \n",
            "5  Hotel com condi√ß√µes gerais muito m√°s. Infraest...   \n",
            "6  Hotel com condi√ß√µes gerais muito m√°s. Infraest...   \n",
            "7  Hotel com condi√ß√µes gerais muito m√°s. Infraest...   \n",
            "8  O hotel segue corretamente os padr√µes do Mercu...   \n",
            "9  O hotel segue corretamente os padr√µes do Mercu...   \n",
            "\n",
            "                                    text_noun_chunks  \\\n",
            "0  hotel condi√ß√µes gerais infraestruturas bastant...   \n",
            "1  hotel condi√ß√µes gerais infraestruturas bastant...   \n",
            "2  hotel condi√ß√µes gerais infraestruturas bastant...   \n",
            "3  hotel condi√ß√µes gerais infraestruturas bastant...   \n",
            "4  hotel condi√ß√µes gerais infraestruturas bastant...   \n",
            "5  hotel condi√ß√µes gerais infraestruturas bastant...   \n",
            "6  hotel condi√ß√µes gerais infraestruturas bastant...   \n",
            "7  hotel condi√ß√µes gerais infraestruturas bastant...   \n",
            "8  o hotel os padr√µes mercure o que excelente loc...   \n",
            "9  o hotel os padr√µes mercure o que excelente loc...   \n",
            "\n",
            "                                              aspect target_opinion_terms  \n",
            "0    {'term': 'Hotel', 'start_pos': 0, 'end_pos': 5}              ['m√°s']  \n",
            "1  {'term': 'Infraestruturas', 'start_pos': 38, '...       ['degradadas']  \n",
            "2  {'term': 'elevador', 'start_pos': 79, 'end_pos...              ['sem']  \n",
            "3  {'term': 'casa de banho', 'start_pos': 89, 'en...       ['partilhada']  \n",
            "4   {'term': 'tv', 'start_pos': 293, 'end_pos': 295}              ['sem']  \n",
            "5  {'term': 'cortina', 'start_pos': 335, 'end_pos...     ['transparente']  \n",
            "6  {'term': 'isolamento ac√∫stico', 'start_pos': 3...            ['fraco']  \n",
            "7  {'term': 'caro', 'start_pos': 642, 'end_pos': ...        ['demasiado']  \n",
            "8  {'term': 'localiza√ß√£o', 'start_pos': 84, 'end_...        ['Excelente']  \n",
            "9  {'term': 'isolamento ac√∫stico', 'start_pos': 9...              ['bom']  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aseg√∫rate de que todos los valores sean diccionarios v√°lidos\n",
        "df_sample['aspect'] = df_sample['aspect'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "df_sample['aspect'] = df_sample['aspect'].apply(lambda x: x if isinstance(x, dict) else {})\n",
        "\n",
        "# Extraer campos del diccionario\n",
        "df_sample['term'] = df_sample['aspect'].apply(lambda x: x.get('term'))\n",
        "df_sample['start_pos'] = df_sample['aspect'].apply(lambda x: x.get('start_pos'))\n",
        "df_sample['end_pos'] = df_sample['aspect'].apply(lambda x: x.get('end_pos'))\n",
        "\n",
        "import ast\n",
        "\n",
        "# Asegurarse de que cada entrada sea una lista real\n",
        "df_sample['target_opinion_terms'] = df_sample['target_opinion_terms'].apply(\n",
        "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        ")\n",
        "\n",
        "# Unir todos los t√©rminos con comas\n",
        "df_sample['opinion_term'] = df_sample['target_opinion_terms'].apply(\n",
        "    lambda x: ', '.join(x) if isinstance(x, list) and len(x) > 0 else None\n",
        ")\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(df_sample[['text', 'term', 'start_pos', 'end_pos', 'opinion_term']].head(10))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-NliGNfYf4y",
        "outputId": "e8675483-5bbb-476d-cffe-a6905fdb307e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text                 term  \\\n",
            "0  Hotel com condi√ß√µes gerais muito m√°s. Infraest...                Hotel   \n",
            "1  Hotel com condi√ß√µes gerais muito m√°s. Infraest...      Infraestruturas   \n",
            "2  Hotel com condi√ß√µes gerais muito m√°s. Infraest...             elevador   \n",
            "3  Hotel com condi√ß√µes gerais muito m√°s. Infraest...        casa de banho   \n",
            "4  Hotel com condi√ß√µes gerais muito m√°s. Infraest...                   tv   \n",
            "5  Hotel com condi√ß√µes gerais muito m√°s. Infraest...              cortina   \n",
            "6  Hotel com condi√ß√µes gerais muito m√°s. Infraest...  isolamento ac√∫stico   \n",
            "7  Hotel com condi√ß√µes gerais muito m√°s. Infraest...                 caro   \n",
            "8  O hotel segue corretamente os padr√µes do Mercu...          localiza√ß√£o   \n",
            "9  O hotel segue corretamente os padr√µes do Mercu...  isolamento ac√∫stico   \n",
            "\n",
            "   start_pos  end_pos  opinion_term  \n",
            "0          0        5           m√°s  \n",
            "1         38       53    degradadas  \n",
            "2         79       87           sem  \n",
            "3         89      102    partilhada  \n",
            "4        293      295           sem  \n",
            "5        335      342  transparente  \n",
            "6        361      380         fraco  \n",
            "7        642      646     demasiado  \n",
            "8         84       95     Excelente  \n",
            "9         97      116           bom  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Cargar modelo en portugu√©s (el mismo que usaste antes)\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "def apply_bio_tagging(text, term, start_pos, end_pos):\n",
        "    doc = nlp(text)\n",
        "    bio_tags = []\n",
        "    tokens = [token.text for token in doc]\n",
        "\n",
        "    # Si no hay t√©rmino v√°lido, todo es O\n",
        "    if not isinstance(term, str) or start_pos is None or end_pos is None:\n",
        "        return tokens, ['O'] * len(tokens)\n",
        "\n",
        "    for token in doc:\n",
        "        token_start = token.idx\n",
        "        token_end = token.idx + len(token)\n",
        "\n",
        "        if token_start >= start_pos and token_end <= end_pos:\n",
        "            # B-TERM si es el primer token del t√©rmino, I-TERM si es continuaci√≥n\n",
        "            if token_start == start_pos:\n",
        "                bio_tags.append('B-TERM')\n",
        "            else:\n",
        "                bio_tags.append('I-TERM')\n",
        "        else:\n",
        "            bio_tags.append('O')\n",
        "\n",
        "    return tokens, bio_tags\n"
      ],
      "metadata": {
        "id": "kvSgGESx6L0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar funci√≥n a cada fila\n",
        "df_sample[['text_tokens', 'text_bio']] = df_sample.apply(\n",
        "    lambda row: pd.Series(apply_bio_tagging(row['text'], row['term'], row['start_pos'], row['end_pos'])),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Ver ejemplo\n",
        "df_sample[[ 'text_tokens', 'text_bio']].head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gLeK5fNp-P7-",
        "outputId": "2e18e80c-9dfa-4ebd-8783-c951b0561580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         text_tokens  \\\n",
              "0  [Hotel, com, condi√ß√µes, gerais, muito, m√°s, .,...   \n",
              "1  [Hotel, com, condi√ß√µes, gerais, muito, m√°s, .,...   \n",
              "2  [Hotel, com, condi√ß√µes, gerais, muito, m√°s, .,...   \n",
              "3  [Hotel, com, condi√ß√µes, gerais, muito, m√°s, .,...   \n",
              "4  [Hotel, com, condi√ß√µes, gerais, muito, m√°s, .,...   \n",
              "\n",
              "                                            text_bio  \n",
              "0  [B-TERM, O, O, O, O, O, O, O, O, O, O, O, O, O...  \n",
              "1  [O, O, O, O, O, O, O, B-TERM, O, O, O, O, O, O...  \n",
              "2  [O, O, O, O, O, O, O, O, O, O, O, O, B-TERM, O...  \n",
              "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-T...  \n",
              "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23531eb9-5307-4b49-a337-794d1b34b256\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_tokens</th>\n",
              "      <th>text_bio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Hotel, com, condi√ß√µes, gerais, muito, m√°s, .,...</td>\n",
              "      <td>[B-TERM, O, O, O, O, O, O, O, O, O, O, O, O, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Hotel, com, condi√ß√µes, gerais, muito, m√°s, .,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-TERM, O, O, O, O, O, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Hotel, com, condi√ß√µes, gerais, muito, m√°s, .,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-TERM, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Hotel, com, condi√ß√µes, gerais, muito, m√°s, .,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Hotel, com, condi√ß√µes, gerais, muito, m√°s, .,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23531eb9-5307-4b49-a337-794d1b34b256')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23531eb9-5307-4b49-a337-794d1b34b256 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23531eb9-5307-4b49-a337-794d1b34b256');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7f1be648-0a57-40b7-b55e-363faf2be972\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7f1be648-0a57-40b7-b55e-363faf2be972')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7f1be648-0a57-40b7-b55e-363faf2be972 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_sample[[ 'text_tokens', 'text_bio']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_bio\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "label_list = ['O', 'B-TERM', 'I-TERM']\n",
        "label_to_id = {label: idx for idx, label in enumerate(label_list)}\n",
        "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
        "\n",
        "# Dividir antes de calcular pesos\n",
        "train_df, test_df = train_test_split(df_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extraer etiquetas solo del train\n",
        "all_train_labels = [tag for seq in train_df['text_bio'] for tag in seq]\n",
        "train_label_ids = [label_to_id[tag] for tag in all_train_labels]\n",
        "\n",
        "# Calcular pesos solo sobre etiquetas del entrenamiento\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_label_ids), y=train_label_ids)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Mostrar resultado\n",
        "print(\"üìä Pesos de clase (calculados sobre entrenamiento):\", dict(zip(label_list, class_weights)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdLeHEBOsAgN",
        "outputId": "e4b69871-f3fd-4554-8f4d-f27e3d343e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Pesos de clase (calculados sobre entrenamiento): {'O': np.float64(0.3377534833237563), 'B-TERM': np.float64(29.9917139119058), 'I-TERM': np.float64(168.97051597051598)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5a6PmPSmROe",
        "outputId": "a94ae60e-13c6-49f9-c53c-6e9239f5070e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Using cached transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Using cached transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-4.52.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "def tokenize_and_align_labels(example):\n",
        "    encoding = tokenizer(\n",
        "        example['text_tokens'],\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    )\n",
        "    word_ids = encoding.word_ids()\n",
        "    labels = []\n",
        "    previous_word_idx = None\n",
        "    for word_idx in word_ids:\n",
        "        if word_idx is None:\n",
        "            labels.append(-100)\n",
        "        elif word_idx != previous_word_idx:\n",
        "            labels.append(label_to_id[example['text_bio'][word_idx]])\n",
        "        else:\n",
        "            label = example['text_bio'][word_idx]\n",
        "            labels.append(label_to_id['I-TERM'] if label == 'B-TERM' else label_to_id[label])\n",
        "        previous_word_idx = word_idx\n",
        "    encoding[\"labels\"] = labels\n",
        "    return encoding\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0_dsduFeyor",
        "outputId": "2b0045a5-960e-4791-cc9e-5d2adf62f8bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzqwxzKFfd7p",
        "outputId": "42cac617-1dfb-4415-ea49-fd466d052b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "dataset = Dataset.from_pandas(train_df)\n",
        "dataset = dataset.map(tokenize_and_align_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "91db86ab1b694704ac57b1b72714e3a6",
            "873835d30b8c4139af1c5b335111352f",
            "e24c2d4f752f4c509c0f09dcf1001076",
            "7b5a29c496f44a6a8ef3fb5b8e90faf4",
            "cd229b1bed754fea872e59e513eef903",
            "8228dbdf93d24bbd800c0f6e68eba1bc",
            "3cdcf31a6414433590e31b5caa86b7a2",
            "23f56fb510fe4cf096fc9f38ce26d9c4",
            "49107a2c4dea4d4288f8dc2233df820d",
            "58aa6bb2aa2e460f93da4a5796ef9efc",
            "78fe21afdbad49fab5d2c1abc13428e3"
          ]
        },
        "id": "Utbb_yH5e8ms",
        "outputId": "0c3aecbb-4f64-4def-c09d-72448eb7aeee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2308 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91db86ab1b694704ac57b1b72714e3a6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoModelForTokenClassification\n",
        "from transformers import EarlyStoppingCallback\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Define Trainer personalizado con pesos de clase y m√©tricas\n",
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, class_weights_tensor=None, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights_tensor = class_weights_tensor\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):  # <- Aceptar kwargs\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        weight = self.class_weights_tensor.to(logits.device)\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=weight)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n",
        "# M√©tricas personalizadas\n",
        "label_list = ['O', 'B-TERM', 'I-TERM']\n",
        "label_to_id = {label: idx for idx, label in enumerate(label_list)}\n",
        "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    preds = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Ignorar tokens con -100\n",
        "    true_labels = []\n",
        "    true_preds = []\n",
        "\n",
        "    for pred, label in zip(preds, labels):\n",
        "        for p_i, l_i in zip(pred, label):\n",
        "            if l_i != -100:\n",
        "                true_preds.append(p_i)\n",
        "                true_labels.append(l_i)\n",
        "\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(true_labels, true_preds, average='macro')\n",
        "    acc = accuracy_score(true_labels, true_preds)\n",
        "\n",
        "    # M√©tricas por etiqueta\n",
        "    report = classification_report(true_labels, true_preds, target_names=label_list, output_dict=True)\n",
        "    detailed_metrics = {}\n",
        "    for label in label_list:\n",
        "        detailed_metrics[f'{label}_precision'] = report[label]['precision']\n",
        "        detailed_metrics[f'{label}_recall'] = report[label]['recall']\n",
        "        detailed_metrics[f'{label}_f1'] = report[label]['f1-score']\n",
        "        detailed_metrics[f'{label}_support'] = report[label]['support']\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        **detailed_metrics\n",
        "    }\n",
        "\n",
        "\n",
        "early_stopping = EarlyStoppingCallback(\n",
        "    early_stopping_patience=3,  # Detener si no mejora en 3 √©pocas\n",
        "    early_stopping_threshold=0.0\n",
        ")\n",
        "\n",
        "# K-Fold Training\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "    print(f\"\\nüîÅ Fold {fold + 1}\")\n",
        "    train_split = dataset.select(train_idx)\n",
        "    val_split = dataset.select(val_idx)\n",
        "\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        \"neuralmind/bert-base-portuguese-cased\",\n",
        "        num_labels=len(label_list),\n",
        "        id2label=id_to_label,\n",
        "        label2id=label_to_id\n",
        "    )\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_fold_{fold}\",\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        num_train_epochs=5,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=10,\n",
        "        learning_rate=2e-5,\n",
        "        weight_decay=0.01,\n",
        "        warmup_steps=200,\n",
        "        logging_dir=f\"./logs_fold_{fold}\",\n",
        "        logging_steps=50,\n",
        "        report_to=\"none\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True\n",
        "    )\n",
        "\n",
        "    trainer = CustomTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_split,\n",
        "        eval_dataset=val_split,\n",
        "        tokenizer=tokenizer,\n",
        "        class_weights_tensor=class_weights_tensor,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    print(f\"\\nüìä M√©tricas Fold {fold+1}: {eval_metrics}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "uTFgUQ2IuFvU",
        "outputId": "c059161f-571e-43d5-b6cd-89ee6ca78e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÅ Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9c4af9a12ef5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"./results_fold_{fold}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZSyRj5JzbFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df = test_df.reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "5gN1roEA3AkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_df)):\n",
        "    tokens = test_df.loc[i, 'text_tokens']  # o test_df.iloc[i]['text_tokens']\n"
      ],
      "metadata": {
        "id": "SFeSgVVo3EFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Convertir test_df a Dataset y tokenizar\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "test_dataset = test_dataset.map(tokenize_and_align_labels)\n"
      ],
      "metadata": {
        "id": "DfaeSTiz9A_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(test_dataset)\n",
        "logits = predictions.predictions\n",
        "labels = predictions.label_ids\n",
        "pred_ids = np.argmax(logits, axis=-1)\n",
        "true_ids = labels\n"
      ],
      "metadata": {
        "id": "T4l5HQeS9CY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_start_end_positions(tokens, pred_tags, original_text):\n",
        "    \"\"\"\n",
        "    Dado un conjunto de tokens y etiquetas BIO, extrae los t√©rminos y sus posiciones en el texto original.\n",
        "    \"\"\"\n",
        "    terms = []\n",
        "    current_term = \"\"\n",
        "    current_start = -1\n",
        "    current_end = -1\n",
        "    pointer = 0\n",
        "\n",
        "    for token, tag in zip(tokens, pred_tags):\n",
        "        norm_token = token.strip()\n",
        "\n",
        "        # Avanzar el puntero hasta encontrar el token en el texto\n",
        "        while pointer < len(original_text) and original_text[pointer].isspace():\n",
        "            pointer += 1\n",
        "\n",
        "        idx = original_text.find(norm_token, pointer)\n",
        "        if idx == -1:\n",
        "            continue  # token no encontrado\n",
        "\n",
        "        if tag == \"B-TERM\":\n",
        "            if current_term:\n",
        "                terms.append((current_term.strip(), current_start, current_end))\n",
        "            current_term = norm_token\n",
        "            current_start = idx\n",
        "            current_end = idx + len(norm_token)\n",
        "        elif tag == \"I-TERM\" and current_term:\n",
        "            current_term += \" \" + norm_token\n",
        "            current_end = idx + len(norm_token)\n",
        "        else:\n",
        "            if current_term:\n",
        "                terms.append((current_term.strip(), current_start, current_end))\n",
        "                current_term = \"\"\n",
        "                current_start = -1\n",
        "                current_end = -1\n",
        "        pointer = idx + len(norm_token)\n",
        "\n",
        "    if current_term:\n",
        "        terms.append((current_term.strip(), current_start, current_end))\n",
        "\n",
        "    return terms\n"
      ],
      "metadata": {
        "id": "3wQ-vZJ_UWnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_results = []\n",
        "\n",
        "for i in range(len(test_df)):\n",
        "    tokens = test_df.loc[i, 'text_tokens']\n",
        "    text = test_df.loc[i, 'text']\n",
        "    true_bio = test_df.loc[i, 'text_bio']\n",
        "\n",
        "    encoding = tokenizer(tokens, is_split_into_words=True, truncation=True, padding='max_length', max_length=128)\n",
        "    word_ids = encoding.word_ids()\n",
        "\n",
        "    pred_bio = []\n",
        "    token_output = []\n",
        "\n",
        "    for j, word_idx in enumerate(word_ids):\n",
        "        if word_idx is None or true_ids[i][j] == -100:\n",
        "            continue\n",
        "        pred_tag = id_to_label[pred_ids[i][j]]\n",
        "        token = tokens[word_idx]\n",
        "        pred_bio.append(pred_tag)\n",
        "        token_output.append(token)\n",
        "\n",
        "    term_spans = infer_start_end_positions(token_output, pred_bio, text)\n",
        "\n",
        "    decoded_results.append({\n",
        "        'text': text,\n",
        "        'text_tokens': token_output,\n",
        "        'text_bio': true_bio[:len(token_output)],\n",
        "        'text_bio_prediction': pred_bio,\n",
        "        'terms_extracted': [t[0] for t in term_spans],\n",
        "        'start_positions': [t[1] for t in term_spans],\n",
        "        'end_positions': [t[2] for t in term_spans]\n",
        "    })\n"
      ],
      "metadata": {
        "id": "NDmxJlK_UdcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(decoded_results)\n",
        "df_results.to_excel(\"resultados_test_con_posiciones.xlsx\", index=False)\n",
        "print(\"‚úÖ Resultados guardados con posiciones en 'resultados_test_con_posiciones.xlsx'\")\n"
      ],
      "metadata": {
        "id": "RTsr7RWS8t-d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}